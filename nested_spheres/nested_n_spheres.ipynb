{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nested_n_spheres.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1vPtFbIFmBWlqILVP51LEfGSyLn99AuKw","authorship_tag":"ABX9TyOf92pKb8RS4U7VZbrBf+7y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Q0ucFGRjvWzv","executionInfo":{"status":"ok","timestamp":1616755331218,"user_tz":0,"elapsed":509,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","------------------------------------------------------------------------------------------------------------------------\n","Code used to perform the nested N-spheres experiment with NODEs and ANODEs. This was taken from Alex's GitHub:\n","https://github.com/a-norcliffe/sonode/blob/master/experiments/nested-n-spheres/nested-n-spheres_anode.py\n","\n","I have also made some small modifications that save the model at given iterations, which can then be used for\n","Hessian analysis.\n","------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"cs8sH0JjwGam","executionInfo":{"status":"ok","timestamp":1616755335281,"user_tz":0,"elapsed":4564,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","pip install torchdiffeq"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"qMe4eo_4vptM","executionInfo":{"status":"ok","timestamp":1616755861667,"user_tz":0,"elapsed":394,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import time\n","import os\n","import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--tol', type=float, default=1e-3)\n","parser.add_argument('--adjoint', type=eval, default=False)\n","parser.add_argument('--visualise', type=eval, default=True)\n","parser.add_argument('--niters', type=int, default=600)\n","parser.add_argument('--lr', type=float, default=0.01)\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--extra_dim', type=int, default=1)\n","parser.add_argument('--data_dimension', type=int, default=2)\n","parser.add_argument('--npoints', type=int, default=50)\n","parser.add_argument('--ntest', type=int, default=10)\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","args = parser.parse_args(args=[])\n","\n","args.hessian_freq = 5\n","args.extra_dim = 1\n","args.visualise = False\n","\n","if args.adjoint:\n","    from torchdiffeq import odeint_adjoint as odeint\n","else:\n","    from torchdiffeq import odeint"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"NT18Ots9v6Tj","executionInfo":{"status":"ok","timestamp":1616755338220,"user_tz":0,"elapsed":7495,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEfunc(nn.Module):\n","    \"\"\"\n","    Neural network to parametrise the derivative of the state vector. Maps from [dim] to [dim] dimensions.\n","    \"\"\"\n","    def __init__(self, dim, nhidden):\n","        super(ODEfunc, self).__init__()\n","        self.elu = nn.ELU(inplace=True)\n","        self.fc1 = nn.Linear(dim, nhidden)\n","        self.fc2 = nn.Linear(nhidden, nhidden)\n","        self.fc3 = nn.Linear(nhidden, dim)\n","        self.nfe = 0\n","\n","    def forward(self, t, x):\n","        self.nfe += 1\n","        out = self.fc1(x)\n","        out = self.elu(out)\n","        out = self.fc2(out)\n","        out = self.elu(out)\n","        out = self.fc3(out)\n","        return out\n","    \n","\n","class ODEBlock(nn.Module):\n","    \"\"\"\n","    Defines the entire ODE block that acts on the state vector, i.e. it perfoms integration on the state vector\n","    with the derivative given by an ODEFunc() object, and interval given by [t0, tN].\n","    \"\"\"\n","    def __init__(self, odefunc, t0_, tN_):\n","        super(ODEBlock, self).__init__()\n","        self.odefunc = odefunc\n","        self.integration_times = torch.tensor([t0_, tN_]).float()\n","        \n","    def forward(self, x):\n","        out = odeint(self.odefunc, x, self.integration_times, rtol=args.tol, atol=args.tol)\n","        out = out[1]\n","        return out\n","\n","    @property\n","    def nfe(self):\n","        return self.odefunc.nfe\n","\n","    @nfe.setter\n","    def nfe(self, value):\n","        self.odefunc.nfe = value"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9x36nN_v-3M","executionInfo":{"status":"ok","timestamp":1616755338221,"user_tz":0,"elapsed":7492,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Function that maps 2D output to a scalar (i.e. 1D vector). The output is then compared to the desired value\n","    (either 1 or -1).\n","    \"\"\"\n","    def __init__(self, in_dim, out_dim):          #out_dim = 1.\n","        super(Decoder, self).__init__()\n","        self.tanh = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n","        self.fc = nn.Linear(in_dim, out_dim)\n","\n","    def forward(self, z):\n","        out = self.fc(z)\n","        out = self.tanh(out)\n","        return out\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSqPmS8Av_s0"},"source":["if __name__ == '__main__':\n","    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","    if args.extra_dim == 0:\n","        filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/node/'\n","        models_filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/node/models/'\n","    else:\n","        filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/anode('+str(args.extra_dim)+')/'\n","        models_filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/anode('+str(args.extra_dim)+')/models/'\n","    try:\n","        os.makedirs(filename)\n","        \n","    except FileExistsError:\n","        pass\n","\n","    try:\n","        os.makedirs(models_filename)\n","        \n","    except FileExistsError:\n","        pass\n","\n","    dim = args.data_dimension + args.extra_dim\n","    \n","    #Download data\n","    name_in = str(args.data_dimension)+'din_'+str(args.npoints)+'_train.npy'        #Only use the training data.\n","    name_out = str(args.data_dimension)+'dout_'+str(args.npoints)+'_train.npy'\n","    folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/data/'\n","    z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","    zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","    \n","    #Augment z0\n","    zeros = torch.zeros(args.npoints, args.extra_dim).float()\n","    z0 = torch.cat((z0, zeros), dim=1).to(device)\n","\n","    # model\n","    t0, tN = 0, 1\n","    nhidden = 20\n","    feature_layers = [ODEBlock(ODEfunc(dim, nhidden), t0, tN), Decoder(dim, 1)]\n","    model = nn.Sequential(*feature_layers).to(device)         #the * bit means that only the elements of the list are taken.\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","    loss_func = nn.MSELoss()\n","    \n","    itr_arr = np.empty(args.niters)\n","    loss_arr = np.empty(args.niters)\n","    nfe_arr = np.empty(args.niters)\n","    time_arr = np.empty(args.niters)\n","\n","    # training\n","    start_time = time.time()\n","    torch.save(model, models_filename + 'model_0.pt')\n","    for itr in range(1, args.niters + 1):\n","        feature_layers[0].nfe = 0\n","        iter_start_time = time.time()\n","        optimizer.zero_grad()\n","\n","        # forward in time and solve ode\n","        pred_z = model(z0)\n","        # compute loss\n","        loss = loss_func(pred_z, zN)\n","        loss.backward()\n","        optimizer.step()\n","        iter_end_time = time.time()\n","        #make arrays\n","        itr_arr[itr-1] = itr\n","        loss_arr[itr-1] = loss\n","        nfe_arr[itr-1] = feature_layers[0].nfe\n","        time_arr[itr-1] = iter_end_time-iter_start_time \n","\n","        if itr % args.hessian_freq == 0:\n","          torch.save(model, models_filename + 'model_' + str(itr) + '.pt')\n","        else:\n","          pass\n","\n","        print('Iter: {}, running MSE: {:.4f}'.format(itr, loss))\n","            \n","\n","    end_time = time.time()\n","    print('\\n')\n","    print('Training complete after {} iters.'.format(itr))\n","    print('Time = ' + str(end_time-start_time))\n","    loss = loss_func(pred_z, zN).detach().numpy()\n","    print('Train MSE = ' +str(loss))\n","    print('NFE = ' +str(feature_layers[0].nfe))\n","    print('Parameters = '+str(count_parameters(model)))\n","    \n","    np.save(filename+'itr_arr.npy', itr_arr)\n","    np.save(filename+'nfe_arr.npy', nfe_arr)\n","    np.save(filename+'loss_arr.npy', loss_arr)\n","    np.save(filename+'time_arr.npy', time_arr)\n","    torch.save(model, filename+'model.pth')\n","    \n","    # make test data\n","    name_in = str(args.data_dimension)+'din_'+str(args.ntest)+'_test.npy'\n","    name_out = str(args.data_dimension)+'dout_'+str(args.ntest)+'_test.npy'\n","    folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/data/'\n","    z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","    zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","    # augment z0\n","    zeros = torch.zeros(args.ntest, args.extra_dim).float()\n","    z0 = torch.cat((z0, zeros), dim=1).to(device)\n","    \n","    # run test data through network\n","    pred_z = model(z0)\n","\n","    # compute loss\n","    loss = loss_func(pred_z, zN).detach().numpy()\n","    print('Test MSE = ' +str(loss))\n","    \n","    \"\"\"\n","    if args.visualise:\n","        try:\n","            os.makedirs('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/figure_data/')\n","        except FileExistsError:\n","            pass\n","        #Generate a sequence of timepoints, such that the model can be evaluated at intermediate times during integration.   \n","        samp_ts = torch.linspace(t0, tN, 30)\n","        if args.data_dimension == 1:\n","            z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/data'\n","                                      + '/vis_data/1d_vis_data.npy')).float()\n","            ntotal = len(z0)\n","            #Augment z0\n","            zeros = torch.zeros(ntotal, args.extra_dim).float()\n","            z0 = torch.cat((z0, zeros), dim=1).to(device)\n","            pred_z = odeint(feature_layers[0].odefunc, z0, samp_ts)\n","            pred_z = pred_z.detach().numpy()\n","            if args.extra_dim == 0:\n","                name =  ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/figure_data'\n","                        + '/node_film_1d.npy')\n","            else:\n","                name =  ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3'\n","                        + '/figure_data/anode_film_(1+'+str(args.extra_dim)+')d.npy')\n","            np.save(name, pred_z)\n","        elif args.data_dimension == 2:\n","            z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/data'\n","                                      + '/vis_data/2d_vis_data.npy')).float()\n","            ntotal = len(z0)\n","            #Augment z0\n","            zeros = torch.zeros(ntotal, args.extra_dim).float()\n","            z0 = torch.cat((z0, zeros), dim=1).to(device)\n","            pred_z = odeint(feature_layers[0].odefunc, z0, samp_ts)\n","            pred_z = pred_z.detach().numpy()\n","            if args.extra_dim == 0:\n","                name = ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/figure_data'\n","                        + '/node_film_2d.npy')\n","            else:\n","                name = ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/figure_data'\n","                        + '/anode_film_(2+'+str(args.extra_dim)+')d.npy')\n","            np.save(name, pred_z)\n","        elif args.data_dimension == 3:\n","            z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/data'\n","                                      + '/vis_data./3d_vis_data.npy')).float()\n","            ntotal = len(z0)\n","            #Augment z0\n","            zeros = torch.zeros(ntotal, args.extra_dim).float()\n","            z0 = torch.cat((z0, zeros), dim=1).to(device)\n","            pred_z = odeint(feature_layers[0].odefunc, z0, samp_ts)\n","            pred_z = pred_z.detach().numpy()\n","            if args.extra_dim == 0:\n","                name = ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_3/figure_data'\n","                        + '/node_film_3d.npy')\n","            else:\n","                pass\n","            np.save(name, pred_z)\n","        else:\n","            pass\n","        \"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zCAM75wLjYr"},"source":["#Generate loss curve plot.\n","experiment_name = 'experiment_3'\n","\n","loss_data = np.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' \n","                    + experiment_name + '/anode(1)/loss_arr.npy')\n","\n","iters = np.linspace(1,600,600)\n","\n","plt.figure(figsize=[10,10])\n","plt.plot(iters, loss_data)\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Loss Curve for Nested Spheres Experiment\\nANODE, Hardtanh()')\n","plt.savefig('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' \n","                    + experiment_name + '/anode(1)/loss_curve.pdf')\n","plt.show()"],"execution_count":null,"outputs":[]}]}