{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nested_spheres_hessian_calculation_cross.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1pSvkWZ3_dGSRd4V0td-ZXi8nTKHvVQLs","authorship_tag":"ABX9TyPUPSZhZPB8mCqn85JgMWE2"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"SQBS7KTR83Bw","executionInfo":{"status":"ok","timestamp":1617354798403,"user_tz":-60,"elapsed":588,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","This file is used to calculate Hessian information for a model during training for the nested N-spheres task, with cross entropy loss.\n","The analysis of these results is executed using the file nested_spheres_hessian_analysis.ipynb.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqZsIwjwmG2p","executionInfo":{"status":"ok","timestamp":1617354803159,"user_tz":-60,"elapsed":5338,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","%%bash \n","pip install torchdiffeq"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iqOcAXt2wMy","executionInfo":{"status":"ok","timestamp":1617354805849,"user_tz":-60,"elapsed":8024,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import os\n","import argparse\n","import time\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4O95yfu3BLY","executionInfo":{"status":"ok","timestamp":1617354806543,"user_tz":-60,"elapsed":8714,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--tol', type=float, default=1e-3)\n","parser.add_argument('--adjoint', type=eval, default=False)\n","parser.add_argument('--visualise', type=eval, default=True)\n","parser.add_argument('--niters', type=int, default=600)\n","parser.add_argument('--lr', type=float, default=0.01)\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--extra_dim', type=int, default=0)\n","parser.add_argument('--data_dimension', type=int, default=2)\n","parser.add_argument('--npoints', type=int, default=50)\n","parser.add_argument('--ntest', type=int, default=10)\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","parser.add_argument('--library_hessian', type=eval, default = False)\n","parser.add_argument('--manual_hessian', type=eval, default = False)\n","parser.add_argument('--mofd_hessian', type=eval, default = False)\n","args = parser.parse_args(args=[])\n","\n","args.hessian_freq = 5\n","if args.adjoint:\n","    from torchdiffeq import odeint_adjoint as odeint\n","else:\n","    from torchdiffeq import odeint\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2TQOgZL-ncp","executionInfo":{"status":"ok","timestamp":1617354806544,"user_tz":-60,"elapsed":8712,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEfunc(nn.Module):\n","    \"\"\"\n","    Neural network to parametrise the derivative of the state vector. Maps from [dim] to [dim] dimensions.\n","    \"\"\"\n","    def __init__(self, dim, nhidden):\n","        super(ODEfunc, self).__init__()\n","        self.elu = nn.ELU(inplace=True)\n","        self.fc1 = nn.Linear(dim, nhidden)\n","        self.fc2 = nn.Linear(nhidden, nhidden)\n","        self.fc3 = nn.Linear(nhidden, dim)\n","        self.nfe = 0\n","\n","    def forward(self, t, x):\n","        self.nfe += 1\n","        out = self.fc1(x)\n","        out = self.elu(out)\n","        out = self.fc2(out)\n","        out = self.elu(out)\n","        out = self.fc3(out)\n","        return out\n","    \n","\n","class ODEBlock(nn.Module):\n","    \"\"\"\n","    Defines the entire ODE block that acts on the state vector, i.e. it perfoms integration on the state vector\n","    with the derivative given by an ODEFunc() object, and interval given by [t0, tN].\n","    \"\"\"\n","    def __init__(self, odefunc, t0_, tN_):\n","        super(ODEBlock, self).__init__()\n","        self.odefunc = odefunc\n","        self.integration_times = torch.tensor([t0_, tN_]).float()\n","        \n","    def forward(self, x):\n","        out = odeint(self.odefunc, x, self.integration_times, rtol=args.tol, atol=args.tol)\n","        out = out[1]\n","        return out\n","\n","    @property\n","    def nfe(self):\n","        return self.odefunc.nfe\n","\n","    @nfe.setter\n","    def nfe(self, value):\n","        self.odefunc.nfe = value"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2sAPLRp7qBG","executionInfo":{"status":"ok","timestamp":1617354806787,"user_tz":-60,"elapsed":8951,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Function that maps 2D output to another vector. \n","    \"\"\"\n","    def __init__(self, in_dim, out_dim):          #out_dim = 2.\n","        super(Decoder, self).__init__()\n","        self.fc = nn.Linear(in_dim, out_dim)\n","\n","    def forward(self, z):\n","        out = self.fc(z)\n","        return out\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RAmyxWJF4lo","executionInfo":{"status":"ok","timestamp":1617354806788,"user_tz":-60,"elapsed":8948,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","Hessian calculation techniques. These are designed to work with any data dimension and augmentation.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-T8RK37Iv2Q","executionInfo":{"status":"ok","timestamp":1617354806789,"user_tz":-60,"elapsed":8946,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Network(nn.Module):\n","  \"\"\"\n","  Neural network that is used for Hessian calculation with library-function and MOFD approaches.\n","  \"\"\"\n","\n","  def __init__(self, a, b, c, d, e, f):\n","    super(Network, self).__init__()\n","    self.a = a\n","    self.b = b\n","    self.c = c\n","    self.d = d\n","    self.e = e\n","    self.f = f\n","\n","  def forward(self, t, y):\n","    m = nn.ELU(inplace=True)\n","    x = F.linear(y, self.a, self.b)\n","    x = m(x)\n","    x = F.linear(x, self.c, self.d)\n","    x = m(x)\n","    x = F.linear(x, self.e, self.f)\n","\n","    return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6FEuA8HdDML","executionInfo":{"status":"ok","timestamp":1617354806790,"user_tz":-60,"elapsed":8943,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Integrator(nn.Module):\n","  \"\"\"\n","  ODE block that is used to calculate the Hessian via the library and MOFD approaches.\n","  \"\"\"\n","  def __init__(self, g, h, odefunc, t0, tN):\n","    super(Integrator, self).__init__()\n","    self.g = g\n","    self.h = h\n","    self.odefunc = odefunc\n","    self.integration_times = torch.tensor([t0, tN]).float()\n","\n","  def forward(self, y):\n","    x = odeint(self.odefunc, y, self.integration_times, rtol=args.tol, atol=args.tol)\n","    x = x[1]\n","    x = F.linear(x, self.g, self.h)\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"owLk1ZZtIyAV","executionInfo":{"status":"ok","timestamp":1617354806791,"user_tz":-60,"elapsed":8940,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_loss(params_vector):\n","\n","  a = params_vector[:nhidden*dim].reshape([nhidden, dim])\n","  b = params_vector[nhidden*dim:nhidden*(dim+1)].reshape([nhidden])\n","  c = params_vector[nhidden*(dim+1):nhidden*(dim+1)+nhidden**2].reshape([nhidden, nhidden])\n","  d = params_vector[nhidden*(dim+1)+nhidden**2:nhidden*(dim+2)+nhidden**2].reshape([nhidden])\n","  e = params_vector[nhidden*(dim+2)+nhidden**2:nhidden*(2*dim+2)+nhidden**2].reshape([dim,nhidden])\n","  f = params_vector[nhidden*(2*dim+2)+nhidden**2:nhidden*(2*dim+2)+nhidden**2+dim].reshape([dim])\n","  g = params_vector[nhidden*(2*dim+2)+nhidden**2+dim:nhidden*(2*dim+2)+nhidden**2+3*dim].reshape([2,dim])\n","  h = params_vector[nhidden*(2*dim+2)+nhidden**2+3*dim:nhidden*(2*dim+2)+nhidden**2+3*dim+2].reshape([2])\n","  \n","  neural_net = Network(a, b, c, d, e, f).to(device)\n","  full_block = Integrator(g, h, neural_net, t0, tN)\n","  pred_z = full_block(z0)\n","  loss_func = nn.CrossEntropyLoss()\n","\n","  target = torch.zeros(len(zN))\n","  for i in range(len(zN)):\n","    if zN[i]==0:\n","      target[i] = 0\n","    else:\n","      target[i] = 1\n","  target = target.long()\n","\n","  loss = loss_func(pred_z, target)\n","  return loss\n","\n","def get_library_hessian(net):\n","  \"\"\"\n","  Obtains the Hessian of the NODE using the autograd.functional.hessian() function.\n","  Inputs: \n","        - net: the network for which the Hessian is to be calculated.\n","  NB: Each individual NODE architecture must be specified in the function get_loss(), such that\n","  the Hessian is calculated correctly.\n","  \"\"\"\n","\n","  param_tensors = net.parameters()\n","  params_vector = torch.tensor([]).to(device)\n","  for param in param_tensors:\n","    vec = torch.reshape(param, (-1,)).to(device)\n","    params_vector = torch.cat((params_vector, vec))\n","  hessian = torch.autograd.functional.hessian(get_loss, params_vector)\n","  return hessian"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y77p15C1G7Sa","executionInfo":{"status":"ok","timestamp":1617354807322,"user_tz":-60,"elapsed":523,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_manual_hessian(grads, parameters, show_iters=True):\n","  \"\"\"\n","  Calculation of the Hessian using nested for loops.\n","  Inputs:   - grads:        tuple of gradient tensors. Created using something \n","                            like grads = torch.autograd.grad(loss, parameters, create_graph=True).\n","            - parameters:   List of parameter objects. Created using something \n","                            like parameters = optimizer.param_groups[0]['params'].\n","            - show_iters:   True or False, depending on if the iteration number is to be shown during training. \n","                            Note that the iteration updates are not provided every row, but instead periodically \n","                            (roughly according to the number of parameters in the system).\n","  \"\"\"\n","  start = time.time()        \n","\n","  n_params = 0\n","  for param in parameters:\n","    n_params += torch.numel(param)\n","  grads2 = torch.zeros(n_params,n_params)            #Create an matrix of zeros thas has the same shape as the Hessian.\n","\n","  y_counter = 0                             #y_direction refers to row number in the Hessian.\n","\n","  for grad in grads:\n","      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \n","\n","      for j, g in enumerate(grad):\n","        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\n","\n","        for l, param in enumerate(parameters):\n","          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\n","          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\n","          len = g2.shape[0]                       \n","          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\n","          x_counter += len\n","\n","      grads2 = grads2.to(device)\n","      y_counter += grad.shape[0]\n","\n","      if show_iters:\n","        print(\"Gradients calculated for row number \" + str(y_counter) + \".\")\n","  \n","  print('Time used was ', time.time() - start)\n","\n","  return grads2"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCHdK1WeI1Lv","executionInfo":{"status":"ok","timestamp":1617354807788,"user_tz":-60,"elapsed":985,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_mofd_hessian_element(p_vec, shapes, base_loss, i, k, h=1e-4):\n","  \"\"\"\n","  Calculates an individual element of the Hessian via the MOFD.\n","  Inputs: - p_vec:        the parameters of the network organized into a vector.\n","          - shapes:       a list of torch.Size() objects describing the shapes of each parameter group.\n","          - base_loss:    loss of the unperturbed system. Used in calculating diagonal Hessian elements.\n","          - h:            the size of the pertubation applied to each parameter.\n","          - i and k:      the indices of the element to be calculated.\n","          - show_iters:   True or False according to whether iteration number is to be displayed during calculation.\n","\n","  Returns: - 'grad2':     torch.tensor() object containing the Hessian element H[i,k] = H[k,i].\n","  \n","  NB: This function adapts to network architecture automatically.\n","  The code is designed to convert all floats to 64-bit automatically.\n","  \"\"\"\n","  loss_func = nn.CrossEntropyLoss()\n","\n","  target = torch.zeros(len(zN))\n","  for m in range(len(zN)):\n","    if zN[m]==0:\n","      target[m] = 0\n","    else:\n","      target[m] = 1\n","  target = target.long()\n","\n","  #List of integers detailing the number of elements in each parameter group.\n","  nels = [int(torch.prod(torch.tensor(shape))) for shape in shapes]\n","  nels = torch.tensor(nels)\n","  nels = torch.cumsum(nels, dim=0)\n","  nels = nels.tolist()\n","\n","  #Empty tensors to store mofd info and perturbed parameters.\n","  up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_pert_p_vec = torch.zeros_like(p_vec).double()\n","\n","  up_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  up_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","    \n","  #Versions of the parameter vector to be perturbed.\n","  for j in range(len(p_vec)):\n","    up_pert_p_vec[j] = p_vec[j]\n","    low_pert_p_vec[j] = p_vec[j]\n","    \n","  #Calculate the diagonal elements.\n","  if k == i:\n","    up_pert_p_vec[k] += h\n","    low_pert_p_vec[k] -= h\n","\n","    a_up = up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up = up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up = up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up = up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up = up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up = up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up = up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up = up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low = low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low = low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low = low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low = low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low = low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low = low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low = low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low = low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    neural_net_up = Network(a_up, b_up, c_up, d_up, e_up, f_up).to(device)\n","    full_block = Integrator(g_up, h_up, neural_net_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    pert_loss_up = loss_func(pred_z, target)\n","\n","    neural_net_low = Network(a_low, b_low, c_low, d_low, e_low, f_low).to(device)\n","    full_block = Integrator(g_low, h_low, neural_net_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    pert_loss_low = loss_func(pred_z, target)\n","    \n","    grad2 = ((pert_loss_up - 2*base_loss + pert_loss_low)/(h**2)).double()\n","\n","  #Calculate the off-diagonal elements.\n","  if k > i:\n","    \n","    #Vectors to be perturbed (there are 4 of these).\n","    #They must be created individually for each k so that previous iterations do not affect the parameter values.\n","    for l in range(len(p_vec)):\n","      up_up_pert_p_vec[l] = p_vec[l]\n","      up_low_pert_p_vec[l] = p_vec[l]\n","      low_up_pert_p_vec[l] = p_vec[l]\n","      low_low_pert_p_vec[l] = p_vec[l]\n","\n","    up_up_pert_p_vec[i] += h\n","    up_up_pert_p_vec[k] += h\n","\n","    up_low_pert_p_vec[i] += h\n","    up_low_pert_p_vec[k] -= h\n","\n","    low_up_pert_p_vec[i] -= h\n","    low_up_pert_p_vec[k] += h\n","\n","    low_low_pert_p_vec[i] -= h\n","    low_low_pert_p_vec[k] -= h\n","\n","    a_up_up = up_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_up = up_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_up = up_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_up = up_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up_up = up_up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up_up = up_up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up_up = up_up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up_up = up_up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_up_low = up_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_low = up_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_low = up_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_low = up_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up_low = up_low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up_low = up_low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up_low = up_low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up_low = up_low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low_up = low_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_up = low_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_up = low_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_up = low_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low_up = low_up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low_up = low_up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low_up = low_up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low_up = low_up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low_low = low_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_low = low_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_low = low_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_low = low_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low_low = low_low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low_low = low_low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low_low = low_low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low_low = low_low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    neural_net_up_up = Network(a_up_up, b_up_up, c_up_up, d_up_up, e_up_up, f_up_up).to(device)\n","    full_block = Integrator(g_up_up, h_up_up, neural_net_up_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    pert_loss_up_up = loss_func(pred_z, target)\n","\n","    neural_net_up_low = Network(a_up_low, b_up_low, c_up_low, d_up_low, e_up_low, f_up_low).to(device)\n","    full_block = Integrator(g_up_low, h_up_low, neural_net_up_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    pert_loss_up_low = loss_func(pred_z, target)\n","\n","    neural_net_low_up = Network(a_low_up, b_low_up, c_low_up, d_low_up, e_low_up, f_low_up).to(device)\n","    full_block = Integrator(g_low_up, h_low_up, neural_net_low_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    pert_loss_low_up = loss_func(pred_z, target)\n","\n","    neural_net_low_low = Network(a_low_low, b_low_low, c_low_low, d_low_low, e_low_low, f_low_low).to(device)\n","    full_block = Integrator(g_low_low, h_low_low, neural_net_low_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    pert_loss_low_low = loss_func(pred_z, target)\n","    \n","    #MOFD formula to estimate second order gradient.\n","    grad2 = ((pert_loss_up_up - pert_loss_up_low - pert_loss_low_up + pert_loss_low_low)/(4*h**2)).double()\n","\n","  return grad2"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldCX1BeNF8Q5","executionInfo":{"status":"ok","timestamp":1617354807792,"user_tz":-60,"elapsed":985,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","Hessian calculation execution.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFWhEVUmeNOL","executionInfo":{"status":"ok","timestamp":1617354807793,"user_tz":-60,"elapsed":983,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_random_indices(max, num):\n","  \"\"\"\n","  Produces two lists of random numbers.\n","  Inputs:   - max: The maximum index to be produced.\n","            - num: The length of the lists to be produced.\n","\n","  random_k[j] > random_i[j] for all j. Failing to do so yields UnboundLocalError since local variable, grad2, is referenced before assignment.\n","  \"\"\"\n","  random_i = random.sample(range(0, max), num)\n","  random_k = []\n","\n","  for k in range(num):\n","    randint = np.random.randint(0,max)\n","    while randint < random_i[k]:\n","      randint =  np.random.randint(0,max)\n","    random_k.append(randint)\n","\n","  return random_i, random_k"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"PedBgBcvZDGo","executionInfo":{"status":"ok","timestamp":1617364029050,"user_tz":-60,"elapsed":467,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["#Download data\n","args.extra_dim = 0\n","exp_name = 'experiment_3'\n","name_in = str(args.data_dimension)+'din_'+str(args.npoints)+'_train.npy'        #Only use the training data.\n","name_out = str(args.data_dimension)+'dout_'+str(args.npoints)+'_train.npy'\n","folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data/'\n","z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","\n","#Augment z0\n","zeros = torch.zeros(args.npoints, args.extra_dim).float()\n","z0 = torch.cat((z0, zeros), dim=1).to(device)\n","\n","dim = args.data_dimension + args.extra_dim\n","t0, tN = 0.0, 1.0\n","nhidden = 20\n","\n","#This code generates a model. Can be used instead of loading a pre-trained version.\n","#feature_layers = [ODEBlock(ODEfunc(dim, nhidden), t0, tN), Decoder(dim, 2)]\n","#net = nn.Sequential(*feature_layers).to(device)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1NzurBCvKWJ"},"source":["#Get manual and library Hessians for an individual iteration.\n","\n","itr = 500      #Iteration to examine.\n","print('Iteration: ' + str(itr))\n","\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/node/models/model_'\n","                  + str(itr) + '.pt')\n","  node_type = 'node'\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')\n","  node_type = 'anode(' + str(args.extra_dim) + ')'\n","\n","#Get manual Hessian.\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","pred_y = model(z0)\n","base_loss_func = nn.CrossEntropyLoss()\n","\n","target = torch.zeros(len(zN))\n","for i in range(len(zN)):\n","  if zN[i]==0:\n","    target[i] = 0\n","  else:\n","    target[i] = 1\n","target = target.long()\n","\n","base_loss = base_loss_func(pred_y, target)\n","grads = torch.autograd.grad(base_loss, model.parameters(), create_graph=True)\n","parameters = optimizer.param_groups[0]['params']\n","\n","print('Obtaining manual hessian...')\n","#manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\n","\n","#Get library hessian.\n","print('Obtaining library hessian...')\n","library_hessian = get_library_hessian(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SC1NpaW3Gtw"},"source":["print(base_loss.item())\n","losses = np.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres'\n","                  + '/cross_entropy/' + exp_name + '/node/loss_arr.npy')\n","print(losses[500])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8OPJaB79BzI"},"source":["#Create eigenvalue density plots for an individual iteration.\n","try:\n","  e, v = torch.symeig(library_hessian)\n","  plt.figure(figsize=[7,7])\n","  plt.hist(e, bins=150, color='Orange')\n","  plt.xlabel('Eigenvalue')\n","  plt.ylabel('Density')\n","  plt.title('Eigenvalue density for library hessian\\nIteration: ' + str(itr))\n","  plt.yscale('log')\n","  plt.show()\n","\n","except NameError:\n","  pass\n","  \n","try:\n","  e, v = torch.symeig(manual_hessian)\n","  plt.figure(figsize=[7,7])\n","  plt.hist(e, bins=150)\n","  plt.xlabel('Eigenvalue')\n","  plt.ylabel('Density')\n","  plt.title('Eigenvalue density for manual hessian\\nIteration: ' + str(itr))\n","  plt.yscale('log')\n","  plt.show()\n","\n","except NameError:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"lEKdhG_ElPVQ","outputId":"e635d763-8c9b-48d2-e2d7-ba6d1b75bd87"},"source":["#The code in this cell is used to calculate a random selection of elements with the MOFD for a range of pertubation parameters.\n","#This can then be used in comparison with library approach.\n","\n","max, num = library_hessian.shape[0], 300\n","random_i, random_k = get_random_indices(max, num)\n","\n","#MOFD Hessian for various h.\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/node/models/model_'\n","                  + str(itr) + '.pt')\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')\n","  \n","double_model = model.double()\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","#Prepare loss for MOFD.\n","pred_y = model(z0.double()).double()\n","base_loss_func = nn.CrossEntropyLoss()\n","target = torch.zeros(len(zN))\n","for i in range(len(zN)):\n","  if zN[i]==0:\n","    target[i] = 0\n","  else:\n","    target[i] = 1\n","target = target.long()\n","base_loss = base_loss_func(pred_y, target).double()\n","\n","#Prepare shape information for MOFD.\n","shapes = []\n","for param in model.parameters():\n","  shapes.append(param.shape)\n","\n","#Create vector of parameters.\n","param_tensors = double_model.parameters()\n","params_vec = torch.tensor([]).to(device)\n","for param in param_tensors:\n","  vec = torch.reshape(param, (-1,)).to(device)\n","  params_vec = torch.cat((params_vec, vec))\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-2 for iteration ' + str(itr) + '...')\n","mofd_hessian_2 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","                   \n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-2)\n","  mofd_hessian_2[i,k] = element.item()\n","  mofd_hessian_2[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-3 for iteration ' + str(itr) + '...')\n","mofd_hessian_3 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","\n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-3)\n","  mofd_hessian_3[i,k] = element.item() \n","  mofd_hessian_3[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-4 for iteration ' + str(itr) + '...')\n","mofd_hessian_4 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","                \n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-4)\n","  mofd_hessian_4[i,k] = element.item() \n","  mofd_hessian_4[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-5 for iteration ' + str(itr) + '...')\n","mofd_hessian_5 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]          \n","\n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-5)\n","  mofd_hessian_5[i,k] = element.item()   \n","  mofd_hessian_5[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-6 for iteration ' + str(itr) + '...')\n","mofd_hessian_6 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","\n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-6)\n","  mofd_hessian_6[i,k] = element.item()  \n","  mofd_hessian_6[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-7 for iteration ' + str(itr) + '...')\n","mofd_hessian_7 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","\n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-7)\n","  mofd_hessian_7[i,k] = element.item()   \n","  mofd_hessian_7[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","w = len(params_vec)                 \n","print('Getting MOFD Hessian with h = 1e-8 for iteration ' + str(itr) + '...')\n","mofd_hessian_8 = torch.zeros((w,w)).double()\n","counter = num\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","\n","  element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-8)\n","  mofd_hessian_8[i,k] = element.item()   \n","  mofd_hessian_8[k,i] = element.item()\n","  counter -= 1\n","  print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting MOFD Hessian with h = 1e-2 for iteration 400...\n","Iterations remaining: 0, Element: 0.00016597477926144166\n","Getting MOFD Hessian with h = 1e-3 for iteration 400...\n","Iterations remaining: 0, Element: 0.00018297517468464797\n","Getting MOFD Hessian with h = 1e-4 for iteration 400...\n","Iterations remaining: 0, Element: 0.00018265409800974353\n","Getting MOFD Hessian with h = 1e-5 for iteration 400...\n","Iterations remaining: 0, Element: 0.00018255714865147985\n","Getting MOFD Hessian with h = 1e-6 for iteration 400...\n","Iterations remaining: 0, Element: 0.000311206681084808\n","Getting MOFD Hessian with h = 1e-7 for iteration 400...\n","Iterations remaining: 0, Element: 0.0018844789010513676\n","Getting MOFD Hessian with h = 1e-8 for iteration 400...\n","Iterations remaining: 0, Element: 1.8277615749032192\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"LYuCWEc-zmZL"},"source":["#Calculate summed difference between 2 Hessians.\n","\n","difference_2 = 0\n","differences_2 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_2 += torch.abs(mofd_hessian_2[i,k]-library_hessian[i,k]).item()\n","  differences_2.append((torch.abs(mofd_hessian_2[i,k]-library_hessian[i,k]).item()))\n","\n","difference_3 = 0\n","differences_3 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_3 += torch.abs(mofd_hessian_3[i,k]-library_hessian[i,k]).item()\n","  differences_3.append((torch.abs(mofd_hessian_3[i,k]-library_hessian[i,k]).item()))\n","\n","difference_4 = 0\n","differences_4 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_4 += torch.abs(mofd_hessian_4[i,k]-library_hessian[i,k]).item()\n","  differences_4.append((torch.abs(mofd_hessian_4[i,k]-library_hessian[i,k]).item()))\n","\n","difference_5 = 0\n","differences_5 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_5 += torch.abs(mofd_hessian_5[i,k]-library_hessian[i,k]).item()\n","  differences_5.append((torch.abs(mofd_hessian_5[i,k]-library_hessian[i,k]).item()))\n","\n","difference_6 = 0\n","differences_6 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_6 += torch.abs(mofd_hessian_6[i,k]-library_hessian[i,k]).item()\n","  differences_6.append((torch.abs(mofd_hessian_6[i,k]-library_hessian[i,k]).item()))\n","\n","difference_7 = 0\n","differences_7 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_7 += torch.abs(mofd_hessian_7[i,k]-library_hessian[i,k]).item()\n","  differences_7.append((torch.abs(mofd_hessian_7[i,k]-library_hessian[i,k]).item()))\n","\n","difference_8 = 0\n","differences_8 = []\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  difference_8 += torch.abs(mofd_hessian_8[i,k]-library_hessian[i,k]).item()\n","  differences_8.append((torch.abs(mofd_hessian_8[i,k]-library_hessian[i,k]).item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ts8qXQsymYAt"},"source":["#Create a plot of the difference between matrices as a function of pertubation parameter.\n","save = False\n","print('NODE Type: ' + str(node_type))\n","\n","xs = [2,3,4,5,6,7,8]\n","difference_list = [difference_2, difference_3, difference_4, difference_5, difference_6, difference_7, difference_8]\n","plt.figure(figsize=[10,10])\n","plt.plot(xs, difference_list, label='Differences')\n","plt.yscale('log')\n","plt.xlabel('-log(h)')\n","plt.ylabel('Summed difference')\n","plt.title('Summed difference between ' + str(num) + ' matrix elements\\nIteration: ' + str(itr))\n","plt.plot()\n","\n","elements_sum = 0\n","elements = []\n","\n","for j in range(num):\n","  i = random_i[j]\n","  k = random_k[j]\n","  elements_sum += torch.abs(library_hessian[i,k])\n","  elements.append(library_hessian[i,k])\n","\n","plt.plot([2, 8], [elements_sum, elements_sum], '--', color = 'Black', label='Summed Element Sizes')\n","plt.legend()\n","if save:\n","  plt.savefig('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name\n","              + '/' + node_type + '/eigenvalue_density_plots_comparisons/' + str(itr) + '_summed_differences_plot.pdf')\n","plt.show()\n","\n","#Print useful information.\n","mofd_ratios = []\n","for i in range(len(elements)):\n","  ratio = (differences_6[i])/(elements[i])    #Ratio calculated using difference values for the best-fitting h value.\n","  mofd_ratios.append(ratio)\n","\n","print('Sum = ' + str(elements_sum.item()))\n","print('Number of elements = ' + str(num))\n","print('Average Element Size =  ' + str((elements_sum/num).item()))\n","print('Summed Ratio = ' + str((difference_6/elements_sum).item()))\n","print('Max Ratio = ' + str(np.max(mofd_ratios)))\n","\n","if save:\n","  information = [elements_sum, num, elements_sum/num, difference_7/elements_sum, np.amax(mofd_ratios)]\n","  torch.save(difference_list, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name\n","                           + '/' + node_type + '/eigenvalue_density_plots_comparisons/' + str(itr) + \n","                          '_differences.pt')\n","  torch.save(mofd_ratios, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name\n","                          + '/' + node_type + '/eigenvalue_density_plots_comparisons/' + str(itr) + '_mofd_ratios.pt')\n","  torch.save(information, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name\n","                           + '/' + node_type + '/eigenvalue_density_plots_comparisons/' + str(itr) + \n","                          '_differences_information.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47MhGyuPzy0P","executionInfo":{"elapsed":6308043,"status":"ok","timestamp":1616949806534,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"},"user_tz":-60},"outputId":"82068567-c725-4fd0-916e-a432b8f0c9e7"},"source":["#MOFD Hessian.\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/node/models/model_'\n","                  + str(itr) + '.pt')\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')\n","  \n","double_model = model.double()\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","#Prepare loss for MOFD.\n","pred_y = model(z0.double()).double()\n","base_loss_func = nn.CrossEntropyLoss()\n","target = torch.zeros(len(zN))\n","for i in range(len(zN)):\n","  if zN[i]==0:\n","    target[i] = 0\n","  else:\n","    target[i] = 1\n","target = target.long()\n","base_loss = base_loss_func(pred_y, target).double()\n","\n","#Prepare shape information for MOFD.\n","shapes = []\n","for param in model.parameters():\n","  shapes.append(param.shape)\n","\n","#Create vector of parameters.\n","param_tensors = double_model.parameters()\n","params_vec = torch.tensor([]).to(device)\n","for param in param_tensors:\n","  vec = torch.reshape(param, (-1,)).to(device)\n","  params_vec = torch.cat((params_vec, vec))\n","\n","print(library_hessian[0,:10])\n","w = len(params_vec)                  #Range of elements to examine.\n","print('Getting MOFD Hessian for iteration ' + str(itr) + '...')\n","counter = w*(w+1)/2\n","mofd_hessian = torch.zeros((w,w)).double()\n","for i in range(w):\n","  for k in range(w):\n","\n","    #Only calculate for k >= i, in the same way as get_mofd_hessian_element().\n","    #Failing to do so yields UnboundLocalError since local variable, grad2, is referenced before assignment.\n","    if k >= i:                     \n","      element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-7)\n","      mofd_hessian[i,k] = element.item()    #.item() is required to prevent RAM growth.\n","      mofd_hessian[k,i] = element.item()\n","      counter -= 1\n","      print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","torch.save(mofd_hessian, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/node'\n","                        + '/hessian_data/' + str(itr) + '_mofd_hessian_7.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([ 0.7949,  0.6623, -9.2038, -2.5792, -5.2095, -2.9453,  1.1416,  0.6824,\n","        14.3879,  3.6964])\n","Getting MOFD Hessian for iteration 540...\n","Iterations remaining: 0, Element: -1.0842021724855046e-05\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcNlBxu6NNxH","outputId":"09c3a087-02a2-48b5-ed7b-6bcf3b072d62"},"source":["#Calculate library Hessian data for models every 5 iterations during training.\n","if args.extra_dim == 0:\n","  node_type = 'node'\n","else:\n","  node_type = 'anode(' + str(args.extra_dim) + ')'\n","  \n","print(exp_name.title(), node_type.title())\n","library_hessian_data = []\n","for itr in range(0, 605, 5):\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name \n","                      + '/' + node_type + '/models/model_' + str(itr) + '.pt')\n","  model = model.to(device)\n","\n","  print('Obtaining library hessian for iteration ' + str(itr) + '...')\n","  library_start = time.time()\n","  library_hessian = get_library_hessian(model)                       #get hessian with library functions   \n","  library_end = time.time()\n","  print(\"Time taken was \" + str(round(library_end-library_start,2)) + \"s.\")\n","\n","  library_hessian_data.append((itr, library_end-library_start, library_hessian))\n","\n","#Save this information.\n","torch.save(library_hessian_data, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' \n","                + exp_name + '/' + node_type + '/hessian_data/library_hessian_data.pt')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Experiment_3 Node\n","Obtaining library hessian for iteration 0...\n","Time taken was 5.64s.\n","Obtaining library hessian for iteration 5...\n","Time taken was 5.67s.\n","Obtaining library hessian for iteration 10...\n","Time taken was 5.57s.\n","Obtaining library hessian for iteration 15...\n","Time taken was 5.74s.\n","Obtaining library hessian for iteration 20...\n","Time taken was 8.23s.\n","Obtaining library hessian for iteration 25...\n","Time taken was 8.07s.\n","Obtaining library hessian for iteration 30...\n","Time taken was 10.19s.\n","Obtaining library hessian for iteration 35...\n","Time taken was 10.24s.\n","Obtaining library hessian for iteration 40...\n","Time taken was 10.4s.\n","Obtaining library hessian for iteration 45...\n","Time taken was 10.32s.\n","Obtaining library hessian for iteration 50...\n","Time taken was 8.32s.\n","Obtaining library hessian for iteration 55...\n","Time taken was 8.37s.\n","Obtaining library hessian for iteration 60...\n","Time taken was 8.23s.\n","Obtaining library hessian for iteration 65...\n","Time taken was 10.16s.\n","Obtaining library hessian for iteration 70...\n","Time taken was 10.32s.\n","Obtaining library hessian for iteration 75...\n","Time taken was 10.25s.\n","Obtaining library hessian for iteration 80...\n","Time taken was 10.29s.\n","Obtaining library hessian for iteration 85...\n","Time taken was 10.22s.\n","Obtaining library hessian for iteration 90...\n","Time taken was 12.27s.\n","Obtaining library hessian for iteration 95...\n","Time taken was 12.39s.\n","Obtaining library hessian for iteration 100...\n","Time taken was 12.19s.\n","Obtaining library hessian for iteration 105...\n","Time taken was 12.35s.\n","Obtaining library hessian for iteration 110...\n","Time taken was 12.56s.\n","Obtaining library hessian for iteration 115...\n","Time taken was 12.73s.\n","Obtaining library hessian for iteration 120...\n","Time taken was 13.08s.\n","Obtaining library hessian for iteration 125...\n","Time taken was 13.46s.\n","Obtaining library hessian for iteration 130...\n","Time taken was 13.74s.\n","Obtaining library hessian for iteration 135...\n","Time taken was 14.11s.\n","Obtaining library hessian for iteration 140...\n","Time taken was 14.02s.\n","Obtaining library hessian for iteration 145...\n","Time taken was 14.02s.\n","Obtaining library hessian for iteration 150...\n","Time taken was 14.01s.\n","Obtaining library hessian for iteration 155...\n","Time taken was 13.91s.\n","Obtaining library hessian for iteration 160...\n"],"name":"stdout"}]}]}