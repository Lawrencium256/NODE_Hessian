{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nested_n_spheres_cross.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qP29nTrzM_R3MZKa0gUzaljPc8A8NfH5","authorship_tag":"ABX9TyNjiPRHITi5U6pyfNwlm6hq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Q0ucFGRjvWzv","executionInfo":{"status":"ok","timestamp":1617353668398,"user_tz":-60,"elapsed":363,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","------------------------------------------------------------------------------------------------------------------------\n","Code used to perform the nested N-spheres experiment with NODEs and ANODEs. This was taken from Alex's GitHub:\n","https://github.com/a-norcliffe/sonode/blob/master/experiments/nested-n-spheres/nested-n-spheres_anode.py\n","\n","It was then adapted to calculate the output in a slightly different way, by using cross entropy loss.\n","I have also made some small modifications that save the model at given iterations, which can then be used for\n","Hessian analysis.\n","------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"cs8sH0JjwGam","executionInfo":{"status":"ok","timestamp":1617353671790,"user_tz":-60,"elapsed":3446,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","pip install torchdiffeq"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"qMe4eo_4vptM","executionInfo":{"status":"ok","timestamp":1617354406073,"user_tz":-60,"elapsed":387,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import time\n","import os\n","import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--tol', type=float, default=1e-3)\n","parser.add_argument('--adjoint', type=eval, default=False)\n","parser.add_argument('--visualise', type=eval, default=True)\n","parser.add_argument('--niters', type=int, default=600)\n","parser.add_argument('--lr', type=float, default=0.01)\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--extra_dim', type=int, default=1)\n","parser.add_argument('--data_dimension', type=int, default=2)\n","parser.add_argument('--npoints', type=int, default=50)\n","parser.add_argument('--ntest', type=int, default=10)\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","args = parser.parse_args(args=[])\n","\n","exp_name = 'experiment_3'\n","args.hessian_freq = 1\n","args.extra_dim = 1\n","args.visualise = True\n","\n","if args.adjoint:\n","    from torchdiffeq import odeint_adjoint as odeint\n","else:\n","    from torchdiffeq import odeint"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"NT18Ots9v6Tj","executionInfo":{"status":"ok","timestamp":1617353675257,"user_tz":-60,"elapsed":458,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEfunc(nn.Module):\n","    \"\"\"\n","    Neural network to parametrise the derivative of the state vector. Maps from [dim] to [dim] dimensions.\n","    \"\"\"\n","    def __init__(self, dim, nhidden):\n","        super(ODEfunc, self).__init__()\n","        self.elu = nn.ELU(inplace=True)\n","        self.fc1 = nn.Linear(dim, nhidden)\n","        self.fc2 = nn.Linear(nhidden, nhidden)\n","        self.fc3 = nn.Linear(nhidden, dim)\n","        self.nfe = 0\n","\n","    def forward(self, t, x):\n","        self.nfe += 1\n","        out = self.fc1(x)\n","        out = self.elu(out)\n","        out = self.fc2(out)\n","        out = self.elu(out)\n","        out = self.fc3(out)\n","        return out\n","    \n","\n","class ODEBlock(nn.Module):\n","    \"\"\"\n","    Defines the entire ODE block that acts on the state vector, i.e. it perfoms integration on the state vector\n","    with the derivative given by an ODEFunc() object, and interval given by [t0, tN].\n","    \"\"\"\n","    def __init__(self, odefunc, t0_, tN_):\n","        super(ODEBlock, self).__init__()\n","        self.odefunc = odefunc\n","        self.integration_times = torch.tensor([t0_, tN_]).float()\n","        \n","    def forward(self, x):\n","        out = odeint(self.odefunc, x, self.integration_times, rtol=args.tol, atol=args.tol)\n","        out = out[1]\n","        return out\n","\n","    @property\n","    def nfe(self):\n","        return self.odefunc.nfe\n","\n","    @nfe.setter\n","    def nfe(self, value):\n","        self.odefunc.nfe = value"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9x36nN_v-3M","executionInfo":{"status":"ok","timestamp":1617353675850,"user_tz":-60,"elapsed":338,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Function that maps 2D output to another vector. \n","    \"\"\"\n","    def __init__(self, in_dim, out_dim):          #out_dim = 1.\n","        super(Decoder, self).__init__()\n","        self.fc = nn.Linear(in_dim, out_dim)\n","\n","    def forward(self, z):\n","        out = self.fc(z)\n","        return out\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSqPmS8Av_s0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1617354433865,"user_tz":-60,"elapsed":21769,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"b7872f46-4fbb-4399-9152-8c14a421dd7d"},"source":["if __name__ == '__main__':\n","    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","    print(exp_name.title())\n","    if args.extra_dim == 0:\n","        print('NODE')\n","        filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/node/'\n","        models_filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/node/models/'\n","    else:\n","        print('ANODE(' + str(args.extra_dim) + ')')\n","        filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/anode('+str(args.extra_dim)+')/'\n","        models_filename = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/anode('+str(args.extra_dim)+')/models/'\n","    try:\n","        os.makedirs(filename)\n","        \n","    except FileExistsError:\n","        pass\n","\n","    try:\n","        os.makedirs(models_filename)\n","        \n","    except FileExistsError:\n","        pass\n","\n","    dim = args.data_dimension + args.extra_dim\n","    \n","    #Download data\n","    name_in = str(args.data_dimension)+'din_'+str(args.npoints)+'_train.npy'        #Only use the training data.\n","    name_out = str(args.data_dimension)+'dout_'+str(args.npoints)+'_train.npy'\n","    folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data/'\n","    z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","    zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","    target = torch.zeros(len(zN))\n","    for i in range(len(zN)):\n","      if zN[i]==0:\n","        target[i] = 0\n","      else:\n","        target[i] = 1\n","    target = target.long()\n","    \n","    #Augment z0\n","    zeros = torch.zeros(args.npoints, args.extra_dim).float()\n","    z0 = torch.cat((z0, zeros), dim=1).to(device)\n","\n","    # model\n","    t0, tN = 0, 1\n","    nhidden = 20\n","    feature_layers = [ODEBlock(ODEfunc(dim, nhidden), t0, tN), Decoder(dim, 2)]\n","    model = nn.Sequential(*feature_layers).to(device)         #the * bit means that only the elements of the list are taken.\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","    loss_func = nn.CrossEntropyLoss()\n","    \n","    itr_arr = np.empty(args.niters)\n","    loss_arr = np.empty(args.niters)\n","    nfe_arr = np.empty(args.niters)\n","    time_arr = np.empty(args.niters)\n","\n","    # training\n","    start_time = time.time()\n","    torch.save(model, models_filename + 'model_0.pt')\n","    for itr in range(1, args.niters + 1):\n","        feature_layers[0].nfe = 0\n","        iter_start_time = time.time()\n","        optimizer.zero_grad()\n","\n","        # forward in time and solve ode\n","        pred_z = model(z0)\n","        # compute loss\n","        loss = loss_func(pred_z, target)\n","        loss.backward()\n","        optimizer.step()\n","        iter_end_time = time.time()\n","        #make arrays\n","        itr_arr[itr-1] = itr\n","        loss_arr[itr-1] = loss\n","        nfe_arr[itr-1] = feature_layers[0].nfe\n","        time_arr[itr-1] = iter_end_time-iter_start_time \n","\n","        if itr % args.hessian_freq == 0:\n","          torch.save(model, models_filename + 'model_' + str(itr) + '.pt')\n","        else:\n","          pass\n","\n","        print('Iter: {}, running loss: {:.4f}'.format(itr, loss))\n","            \n","\n","    end_time = time.time()\n","    print('\\n')\n","    print('Training complete after {} iters.'.format(itr))\n","    print('Time = ' + str(end_time-start_time))\n","    loss = loss_func(pred_z, target).detach().numpy()\n","    print('Train Loss = ' +str(loss))\n","    print('NFE = ' +str(feature_layers[0].nfe))\n","    print('Parameters = '+str(count_parameters(model)))\n","    \n","    np.save(filename+'itr_arr.npy', itr_arr)\n","    np.save(filename+'nfe_arr.npy', nfe_arr)\n","    np.save(filename+'loss_arr.npy', loss_arr)\n","    np.save(filename+'time_arr.npy', time_arr)\n","    torch.save(model, filename+'model.pth')\n","    \n","    # make test data\n","    name_in = str(args.data_dimension)+'din_'+str(args.ntest)+'_test.npy'\n","    name_out = str(args.data_dimension)+'dout_'+str(args.ntest)+'_test.npy'\n","    folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data/'\n","    z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","    zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","    target = torch.zeros(len(zN))\n","    for i in range(len(zN)):\n","      if zN[i]==0:\n","        target[i] = 0\n","      else:\n","        target[i] = 1\n","    target = target.long()\n","\n","    # augment z0\n","    zeros = torch.zeros(args.ntest, args.extra_dim).float()\n","    z0 = torch.cat((z0, zeros), dim=1).to(device)\n","    \n","    # run test data through network\n","    pred_z = model(z0)\n","\n","    # compute loss\n","    loss = loss_func(pred_z, target).detach().numpy()\n","    print('Test Loss = ' +str(loss))\n","    \n","    if args.visualise:\n","        try:\n","            os.makedirs('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/figure_data/')\n","        except FileExistsError:\n","            pass\n","        #Generate a sequence of timepoints, such that the model can be evaluated at intermediate times during integration.   \n","        samp_ts = torch.linspace(t0, tN, 30)\n","        if args.data_dimension == 1:\n","            z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data'\n","                                      + '/vis_data/1d_vis_data.npy')).float()\n","            ntotal = len(z0)\n","            #Augment z0\n","            zeros = torch.zeros(ntotal, args.extra_dim).float()\n","            z0 = torch.cat((z0, zeros), dim=1).to(device)\n","            pred_z = odeint(feature_layers[0].odefunc, z0, samp_ts)\n","            pred_z = pred_z.detach().numpy()\n","            if args.extra_dim == 0:\n","                name =  ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/figure_data'\n","                        + '/node_film_1d.npy')\n","            else:\n","                name =  ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + ''\n","                        + '/figure_data/anode_film_(1+'+str(args.extra_dim)+')d.npy')\n","            np.save(name, pred_z)\n","        elif args.data_dimension == 2:\n","            z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data'\n","                                      + '/vis_data/2d_vis_data.npy')).float()\n","            ntotal = len(z0)\n","            #Augment z0\n","            zeros = torch.zeros(ntotal, args.extra_dim).float()\n","            z0 = torch.cat((z0, zeros), dim=1).to(device)\n","            pred_z = odeint(feature_layers[0].odefunc, z0, samp_ts)\n","            pred_z = pred_z.detach().numpy()\n","            if args.extra_dim == 0:\n","                name = ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/figure_data'\n","                        + '/node_film_2d.npy')\n","            else:\n","                name = ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/figure_data'\n","                        + '/anode_film_(2+'+str(args.extra_dim)+')d.npy')\n","            np.save(name, pred_z)\n","        elif args.data_dimension == 3:\n","            z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data'\n","                                      + '/vis_data./3d_vis_data.npy')).float()\n","            ntotal = len(z0)\n","            #Augment z0\n","            zeros = torch.zeros(ntotal, args.extra_dim).float()\n","            z0 = torch.cat((z0, zeros), dim=1).to(device)\n","            pred_z = odeint(feature_layers[0].odefunc, z0, samp_ts)\n","            pred_z = pred_z.detach().numpy()\n","            if args.extra_dim == 0:\n","                name = ('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/figure_data'\n","                        + '/node_film_3d.npy')\n","            else:\n","                pass\n","            np.save(name, pred_z)\n","        else:\n","            pass\n"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Experiment_3\n","ANODE(1)\n","Iter: 1, running loss: 0.7472\n","Iter: 2, running loss: 0.7350\n","Iter: 3, running loss: 0.7243\n","Iter: 4, running loss: 0.7139\n","Iter: 5, running loss: 0.7033\n","Iter: 6, running loss: 0.6920\n","Iter: 7, running loss: 0.6803\n","Iter: 8, running loss: 0.6684\n","Iter: 9, running loss: 0.6570\n","Iter: 10, running loss: 0.6467\n","Iter: 11, running loss: 0.6381\n","Iter: 12, running loss: 0.6309\n","Iter: 13, running loss: 0.6219\n","Iter: 14, running loss: 0.6076\n","Iter: 15, running loss: 0.5886\n","Iter: 16, running loss: 0.5675\n","Iter: 17, running loss: 0.5474\n","Iter: 18, running loss: 0.5313\n","Iter: 19, running loss: 0.5198\n","Iter: 20, running loss: 0.5089\n","Iter: 21, running loss: 0.4954\n","Iter: 22, running loss: 0.4817\n","Iter: 23, running loss: 0.4709\n","Iter: 24, running loss: 0.4557\n","Iter: 25, running loss: 0.4478\n","Iter: 26, running loss: 0.4393\n","Iter: 27, running loss: 0.4510\n","Iter: 28, running loss: 0.4858\n","Iter: 29, running loss: 0.4269\n","Iter: 30, running loss: 0.4448\n","Iter: 31, running loss: 0.4514\n","Iter: 32, running loss: 0.4795\n","Iter: 33, running loss: 0.4869\n","Iter: 34, running loss: 0.4887\n","Iter: 35, running loss: 0.4974\n","Iter: 36, running loss: 0.5063\n","Iter: 37, running loss: 0.5066\n","Iter: 38, running loss: 0.5078\n","Iter: 39, running loss: 0.5069\n","Iter: 40, running loss: 0.5262\n","Iter: 41, running loss: 0.4969\n","Iter: 42, running loss: 0.4906\n","Iter: 43, running loss: 0.4773\n","Iter: 44, running loss: 0.4599\n","Iter: 45, running loss: 0.4257\n","Iter: 46, running loss: 0.4198\n","Iter: 47, running loss: 0.4125\n","Iter: 48, running loss: 0.4056\n","Iter: 49, running loss: 0.3957\n","Iter: 50, running loss: 0.3828\n","Iter: 51, running loss: 0.3703\n","Iter: 52, running loss: 0.3589\n","Iter: 53, running loss: 0.3464\n","Iter: 54, running loss: 0.3329\n","Iter: 55, running loss: 0.3167\n","Iter: 56, running loss: 0.2974\n","Iter: 57, running loss: 0.2770\n","Iter: 58, running loss: 0.2539\n","Iter: 59, running loss: 0.2298\n","Iter: 60, running loss: 0.2099\n","Iter: 61, running loss: 0.1957\n","Iter: 62, running loss: 0.1789\n","Iter: 63, running loss: 0.1605\n","Iter: 64, running loss: 0.1501\n","Iter: 65, running loss: 0.1343\n","Iter: 66, running loss: 0.1042\n","Iter: 67, running loss: 0.0736\n","Iter: 68, running loss: 0.0678\n","Iter: 69, running loss: 0.0489\n","Iter: 70, running loss: 0.0331\n","Iter: 71, running loss: 0.0237\n","Iter: 72, running loss: 0.0195\n","Iter: 73, running loss: 0.0153\n","Iter: 74, running loss: 0.0116\n","Iter: 75, running loss: 0.0073\n","Iter: 76, running loss: 0.0045\n","Iter: 77, running loss: 0.0032\n","Iter: 78, running loss: 0.0023\n","Iter: 79, running loss: 0.0018\n","Iter: 80, running loss: 0.0014\n","Iter: 81, running loss: 0.0011\n","Iter: 82, running loss: 0.0008\n","Iter: 83, running loss: 0.0006\n","Iter: 84, running loss: 0.0004\n","Iter: 85, running loss: 0.0003\n","Iter: 86, running loss: 0.0002\n","Iter: 87, running loss: 0.0001\n","Iter: 88, running loss: 0.0001\n","Iter: 89, running loss: 0.0001\n","Iter: 90, running loss: 0.0000\n","Iter: 91, running loss: 0.0000\n","Iter: 92, running loss: 0.0000\n","Iter: 93, running loss: 0.0000\n","Iter: 94, running loss: 0.0000\n","Iter: 95, running loss: 0.0000\n","Iter: 96, running loss: 0.0000\n","Iter: 97, running loss: 0.0000\n","Iter: 98, running loss: 0.0000\n","Iter: 99, running loss: 0.0000\n","Iter: 100, running loss: 0.0000\n","Iter: 101, running loss: 0.0000\n","Iter: 102, running loss: 0.0000\n","Iter: 103, running loss: 0.0000\n","Iter: 104, running loss: 0.0000\n","Iter: 105, running loss: 0.0000\n","Iter: 106, running loss: 0.0000\n","Iter: 107, running loss: 0.0000\n","Iter: 108, running loss: 0.0000\n","Iter: 109, running loss: 0.0000\n","Iter: 110, running loss: 0.0000\n","Iter: 111, running loss: 0.0000\n","Iter: 112, running loss: 0.0000\n","Iter: 113, running loss: 0.0000\n","Iter: 114, running loss: 0.0000\n","Iter: 115, running loss: 0.0000\n","Iter: 116, running loss: 0.0000\n","Iter: 117, running loss: 0.0000\n","Iter: 118, running loss: 0.0000\n","Iter: 119, running loss: 0.0000\n","Iter: 120, running loss: 0.0000\n","Iter: 121, running loss: 0.0000\n","Iter: 122, running loss: 0.0000\n","Iter: 123, running loss: 0.0000\n","Iter: 124, running loss: 0.0000\n","Iter: 125, running loss: 0.0000\n","Iter: 126, running loss: 0.0000\n","Iter: 127, running loss: 0.0000\n","Iter: 128, running loss: 0.0000\n","Iter: 129, running loss: 0.0000\n","Iter: 130, running loss: 0.0000\n","Iter: 131, running loss: 0.0000\n","Iter: 132, running loss: 0.0000\n","Iter: 133, running loss: 0.0000\n","Iter: 134, running loss: 0.0000\n","Iter: 135, running loss: 0.0000\n","Iter: 136, running loss: 0.0000\n","Iter: 137, running loss: 0.0000\n","Iter: 138, running loss: 0.0000\n","Iter: 139, running loss: 0.0000\n","Iter: 140, running loss: 0.0000\n","Iter: 141, running loss: 0.0000\n","Iter: 142, running loss: 0.0000\n","Iter: 143, running loss: 0.0000\n","Iter: 144, running loss: 0.0000\n","Iter: 145, running loss: 0.0000\n","Iter: 146, running loss: 0.0000\n","Iter: 147, running loss: 0.0000\n","Iter: 148, running loss: 0.0000\n","Iter: 149, running loss: 0.0000\n","Iter: 150, running loss: 0.0000\n","Iter: 151, running loss: 0.0000\n","Iter: 152, running loss: 0.0000\n","Iter: 153, running loss: 0.0000\n","Iter: 154, running loss: 0.0000\n","Iter: 155, running loss: 0.0000\n","Iter: 156, running loss: 0.0000\n","Iter: 157, running loss: 0.0000\n","Iter: 158, running loss: 0.0000\n","Iter: 159, running loss: 0.0000\n","Iter: 160, running loss: 0.0000\n","Iter: 161, running loss: 0.0000\n","Iter: 162, running loss: 0.0000\n","Iter: 163, running loss: 0.0000\n","Iter: 164, running loss: 0.0000\n","Iter: 165, running loss: 0.0000\n","Iter: 166, running loss: 0.0000\n","Iter: 167, running loss: 0.0000\n","Iter: 168, running loss: 0.0000\n","Iter: 169, running loss: 0.0000\n","Iter: 170, running loss: 0.0000\n","Iter: 171, running loss: 0.0000\n","Iter: 172, running loss: 0.0000\n","Iter: 173, running loss: 0.0000\n","Iter: 174, running loss: 0.0000\n","Iter: 175, running loss: 0.0000\n","Iter: 176, running loss: 0.0000\n","Iter: 177, running loss: 0.0000\n","Iter: 178, running loss: 0.0000\n","Iter: 179, running loss: 0.0000\n","Iter: 180, running loss: 0.0000\n","Iter: 181, running loss: 0.0000\n","Iter: 182, running loss: 0.0000\n","Iter: 183, running loss: 0.0000\n","Iter: 184, running loss: 0.0000\n","Iter: 185, running loss: 0.0000\n","Iter: 186, running loss: 0.0000\n","Iter: 187, running loss: 0.0000\n","Iter: 188, running loss: 0.0000\n","Iter: 189, running loss: 0.0000\n","Iter: 190, running loss: 0.0000\n","Iter: 191, running loss: 0.0000\n","Iter: 192, running loss: 0.0000\n","Iter: 193, running loss: 0.0000\n","Iter: 194, running loss: 0.0000\n","Iter: 195, running loss: 0.0000\n","Iter: 196, running loss: 0.0000\n","Iter: 197, running loss: 0.0000\n","Iter: 198, running loss: 0.0000\n","Iter: 199, running loss: 0.0000\n","Iter: 200, running loss: 0.0000\n","Iter: 201, running loss: 0.0000\n","Iter: 202, running loss: 0.0000\n","Iter: 203, running loss: 0.0000\n","Iter: 204, running loss: 0.0000\n","Iter: 205, running loss: 0.0000\n","Iter: 206, running loss: 0.0000\n","Iter: 207, running loss: 0.0000\n","Iter: 208, running loss: 0.0000\n","Iter: 209, running loss: 0.0000\n","Iter: 210, running loss: 0.0000\n","Iter: 211, running loss: 0.0000\n","Iter: 212, running loss: 0.0000\n","Iter: 213, running loss: 0.0000\n","Iter: 214, running loss: 0.0000\n","Iter: 215, running loss: 0.0000\n","Iter: 216, running loss: 0.0000\n","Iter: 217, running loss: 0.0000\n","Iter: 218, running loss: 0.0000\n","Iter: 219, running loss: 0.0000\n","Iter: 220, running loss: 0.0000\n","Iter: 221, running loss: 0.0000\n","Iter: 222, running loss: 0.0000\n","Iter: 223, running loss: 0.0000\n","Iter: 224, running loss: 0.0000\n","Iter: 225, running loss: 0.0000\n","Iter: 226, running loss: 0.0000\n","Iter: 227, running loss: 0.0000\n","Iter: 228, running loss: 0.0000\n","Iter: 229, running loss: 0.0000\n","Iter: 230, running loss: 0.0000\n","Iter: 231, running loss: 0.0000\n","Iter: 232, running loss: 0.0000\n","Iter: 233, running loss: 0.0000\n","Iter: 234, running loss: 0.0000\n","Iter: 235, running loss: 0.0000\n","Iter: 236, running loss: 0.0000\n","Iter: 237, running loss: 0.0000\n","Iter: 238, running loss: 0.0000\n","Iter: 239, running loss: 0.0000\n","Iter: 240, running loss: 0.0000\n","Iter: 241, running loss: 0.0000\n","Iter: 242, running loss: 0.0000\n","Iter: 243, running loss: 0.0000\n","Iter: 244, running loss: 0.0000\n","Iter: 245, running loss: 0.0000\n","Iter: 246, running loss: 0.0000\n","Iter: 247, running loss: 0.0000\n","Iter: 248, running loss: 0.0000\n","Iter: 249, running loss: 0.0000\n","Iter: 250, running loss: 0.0000\n","Iter: 251, running loss: 0.0000\n","Iter: 252, running loss: 0.0000\n","Iter: 253, running loss: 0.0000\n","Iter: 254, running loss: 0.0000\n","Iter: 255, running loss: 0.0000\n","Iter: 256, running loss: 0.0000\n","Iter: 257, running loss: 0.0000\n","Iter: 258, running loss: 0.0000\n","Iter: 259, running loss: 0.0000\n","Iter: 260, running loss: 0.0000\n","Iter: 261, running loss: 0.0000\n","Iter: 262, running loss: 0.0000\n","Iter: 263, running loss: 0.0000\n","Iter: 264, running loss: 0.0000\n","Iter: 265, running loss: 0.0000\n","Iter: 266, running loss: 0.0000\n","Iter: 267, running loss: 0.0000\n","Iter: 268, running loss: 0.0000\n","Iter: 269, running loss: 0.0000\n","Iter: 270, running loss: 0.0000\n","Iter: 271, running loss: 0.0000\n","Iter: 272, running loss: 0.0000\n","Iter: 273, running loss: 0.0000\n","Iter: 274, running loss: 0.0000\n","Iter: 275, running loss: 0.0000\n","Iter: 276, running loss: 0.0000\n","Iter: 277, running loss: 0.0000\n","Iter: 278, running loss: 0.0000\n","Iter: 279, running loss: 0.0000\n","Iter: 280, running loss: 0.0000\n","Iter: 281, running loss: 0.0000\n","Iter: 282, running loss: 0.0000\n","Iter: 283, running loss: 0.0000\n","Iter: 284, running loss: 0.0000\n","Iter: 285, running loss: 0.0000\n","Iter: 286, running loss: 0.0000\n","Iter: 287, running loss: 0.0000\n","Iter: 288, running loss: 0.0000\n","Iter: 289, running loss: 0.0000\n","Iter: 290, running loss: 0.0000\n","Iter: 291, running loss: 0.0000\n","Iter: 292, running loss: 0.0000\n","Iter: 293, running loss: 0.0000\n","Iter: 294, running loss: 0.0000\n","Iter: 295, running loss: 0.0000\n","Iter: 296, running loss: 0.0000\n","Iter: 297, running loss: 0.0000\n","Iter: 298, running loss: 0.0000\n","Iter: 299, running loss: 0.0000\n","Iter: 300, running loss: 0.0000\n","Iter: 301, running loss: 0.0000\n","Iter: 302, running loss: 0.0000\n","Iter: 303, running loss: 0.0000\n","Iter: 304, running loss: 0.0000\n","Iter: 305, running loss: 0.0000\n","Iter: 306, running loss: 0.0000\n","Iter: 307, running loss: 0.0000\n","Iter: 308, running loss: 0.0000\n","Iter: 309, running loss: 0.0000\n","Iter: 310, running loss: 0.0000\n","Iter: 311, running loss: 0.0000\n","Iter: 312, running loss: 0.0000\n","Iter: 313, running loss: 0.0000\n","Iter: 314, running loss: 0.0000\n","Iter: 315, running loss: 0.0000\n","Iter: 316, running loss: 0.0000\n","Iter: 317, running loss: 0.0000\n","Iter: 318, running loss: 0.0000\n","Iter: 319, running loss: 0.0000\n","Iter: 320, running loss: 0.0000\n","Iter: 321, running loss: 0.0000\n","Iter: 322, running loss: 0.0000\n","Iter: 323, running loss: 0.0000\n","Iter: 324, running loss: 0.0000\n","Iter: 325, running loss: 0.0000\n","Iter: 326, running loss: 0.0000\n","Iter: 327, running loss: 0.0000\n","Iter: 328, running loss: 0.0000\n","Iter: 329, running loss: 0.0000\n","Iter: 330, running loss: 0.0000\n","Iter: 331, running loss: 0.0000\n","Iter: 332, running loss: 0.0000\n","Iter: 333, running loss: 0.0000\n","Iter: 334, running loss: 0.0000\n","Iter: 335, running loss: 0.0000\n","Iter: 336, running loss: 0.0000\n","Iter: 337, running loss: 0.0000\n","Iter: 338, running loss: 0.0000\n","Iter: 339, running loss: 0.0000\n","Iter: 340, running loss: 0.0000\n","Iter: 341, running loss: 0.0000\n","Iter: 342, running loss: 0.0000\n","Iter: 343, running loss: 0.0000\n","Iter: 344, running loss: 0.0000\n","Iter: 345, running loss: 0.0000\n","Iter: 346, running loss: 0.0000\n","Iter: 347, running loss: 0.0000\n","Iter: 348, running loss: 0.0000\n","Iter: 349, running loss: 0.0000\n","Iter: 350, running loss: 0.0000\n","Iter: 351, running loss: 0.0000\n","Iter: 352, running loss: 0.0000\n","Iter: 353, running loss: 0.0000\n","Iter: 354, running loss: 0.0000\n","Iter: 355, running loss: 0.0000\n","Iter: 356, running loss: 0.0000\n","Iter: 357, running loss: 0.0000\n","Iter: 358, running loss: 0.0000\n","Iter: 359, running loss: 0.0000\n","Iter: 360, running loss: 0.0000\n","Iter: 361, running loss: 0.0000\n","Iter: 362, running loss: 0.0000\n","Iter: 363, running loss: 0.0000\n","Iter: 364, running loss: 0.0000\n","Iter: 365, running loss: 0.0000\n","Iter: 366, running loss: 0.0000\n","Iter: 367, running loss: 0.0000\n","Iter: 368, running loss: 0.0000\n","Iter: 369, running loss: 0.0000\n","Iter: 370, running loss: 0.0000\n","Iter: 371, running loss: 0.0000\n","Iter: 372, running loss: 0.0000\n","Iter: 373, running loss: 0.0000\n","Iter: 374, running loss: 0.0000\n","Iter: 375, running loss: 0.0000\n","Iter: 376, running loss: 0.0000\n","Iter: 377, running loss: 0.0000\n","Iter: 378, running loss: 0.0000\n","Iter: 379, running loss: 0.0000\n","Iter: 380, running loss: 0.0000\n","Iter: 381, running loss: 0.0000\n","Iter: 382, running loss: 0.0000\n","Iter: 383, running loss: 0.0000\n","Iter: 384, running loss: 0.0000\n","Iter: 385, running loss: 0.0000\n","Iter: 386, running loss: 0.0000\n","Iter: 387, running loss: 0.0000\n","Iter: 388, running loss: 0.0000\n","Iter: 389, running loss: 0.0000\n","Iter: 390, running loss: 0.0000\n","Iter: 391, running loss: 0.0000\n","Iter: 392, running loss: 0.0000\n","Iter: 393, running loss: 0.0000\n","Iter: 394, running loss: 0.0000\n","Iter: 395, running loss: 0.0000\n","Iter: 396, running loss: 0.0000\n","Iter: 397, running loss: 0.0000\n","Iter: 398, running loss: 0.0000\n","Iter: 399, running loss: 0.0000\n","Iter: 400, running loss: 0.0000\n","Iter: 401, running loss: 0.0000\n","Iter: 402, running loss: 0.0000\n","Iter: 403, running loss: 0.0000\n","Iter: 404, running loss: 0.0000\n","Iter: 405, running loss: 0.0000\n","Iter: 406, running loss: 0.0000\n","Iter: 407, running loss: 0.0000\n","Iter: 408, running loss: 0.0000\n","Iter: 409, running loss: 0.0000\n","Iter: 410, running loss: 0.0000\n","Iter: 411, running loss: 0.0000\n","Iter: 412, running loss: 0.0000\n","Iter: 413, running loss: 0.0000\n","Iter: 414, running loss: 0.0000\n","Iter: 415, running loss: 0.0000\n","Iter: 416, running loss: 0.0000\n","Iter: 417, running loss: 0.0000\n","Iter: 418, running loss: 0.0000\n","Iter: 419, running loss: 0.0000\n","Iter: 420, running loss: 0.0000\n","Iter: 421, running loss: 0.0000\n","Iter: 422, running loss: 0.0000\n","Iter: 423, running loss: 0.0000\n","Iter: 424, running loss: 0.0000\n","Iter: 425, running loss: 0.0000\n","Iter: 426, running loss: 0.0000\n","Iter: 427, running loss: 0.0000\n","Iter: 428, running loss: 0.0000\n","Iter: 429, running loss: 0.0000\n","Iter: 430, running loss: 0.0000\n","Iter: 431, running loss: 0.0000\n","Iter: 432, running loss: 0.0000\n","Iter: 433, running loss: 0.0000\n","Iter: 434, running loss: 0.0000\n","Iter: 435, running loss: 0.0000\n","Iter: 436, running loss: 0.0000\n","Iter: 437, running loss: 0.0000\n","Iter: 438, running loss: 0.0000\n","Iter: 439, running loss: 0.0000\n","Iter: 440, running loss: 0.0000\n","Iter: 441, running loss: 0.0000\n","Iter: 442, running loss: 0.0000\n","Iter: 443, running loss: 0.0000\n","Iter: 444, running loss: 0.0000\n","Iter: 445, running loss: 0.0000\n","Iter: 446, running loss: 0.0000\n","Iter: 447, running loss: 0.0000\n","Iter: 448, running loss: 0.0000\n","Iter: 449, running loss: 0.0000\n","Iter: 450, running loss: 0.0000\n","Iter: 451, running loss: 0.0000\n","Iter: 452, running loss: 0.0000\n","Iter: 453, running loss: 0.0000\n","Iter: 454, running loss: 0.0000\n","Iter: 455, running loss: 0.0000\n","Iter: 456, running loss: 0.0000\n","Iter: 457, running loss: 0.0000\n","Iter: 458, running loss: 0.0000\n","Iter: 459, running loss: 0.0000\n","Iter: 460, running loss: 0.0000\n","Iter: 461, running loss: 0.0000\n","Iter: 462, running loss: 0.0000\n","Iter: 463, running loss: 0.0000\n","Iter: 464, running loss: 0.0000\n","Iter: 465, running loss: 0.0000\n","Iter: 466, running loss: 0.0000\n","Iter: 467, running loss: 0.0000\n","Iter: 468, running loss: 0.0000\n","Iter: 469, running loss: 0.0000\n","Iter: 470, running loss: 0.0000\n","Iter: 471, running loss: 0.0000\n","Iter: 472, running loss: 0.0000\n","Iter: 473, running loss: 0.0000\n","Iter: 474, running loss: 0.0000\n","Iter: 475, running loss: 0.0000\n","Iter: 476, running loss: 0.0000\n","Iter: 477, running loss: 0.0000\n","Iter: 478, running loss: 0.0000\n","Iter: 479, running loss: 0.0000\n","Iter: 480, running loss: 0.0000\n","Iter: 481, running loss: 0.0000\n","Iter: 482, running loss: 0.0000\n","Iter: 483, running loss: 0.0000\n","Iter: 484, running loss: 0.0000\n","Iter: 485, running loss: 0.0000\n","Iter: 486, running loss: 0.0000\n","Iter: 487, running loss: 0.0000\n","Iter: 488, running loss: 0.0000\n","Iter: 489, running loss: 0.0000\n","Iter: 490, running loss: 0.0000\n","Iter: 491, running loss: 0.0000\n","Iter: 492, running loss: 0.0000\n","Iter: 493, running loss: 0.0000\n","Iter: 494, running loss: 0.0000\n","Iter: 495, running loss: 0.0000\n","Iter: 496, running loss: 0.0000\n","Iter: 497, running loss: 0.0000\n","Iter: 498, running loss: 0.0000\n","Iter: 499, running loss: 0.0000\n","Iter: 500, running loss: 0.0000\n","Iter: 501, running loss: 0.0000\n","Iter: 502, running loss: 0.0000\n","Iter: 503, running loss: 0.0000\n","Iter: 504, running loss: 0.0000\n","Iter: 505, running loss: 0.0000\n","Iter: 506, running loss: 0.0000\n","Iter: 507, running loss: 0.0000\n","Iter: 508, running loss: 0.0000\n","Iter: 509, running loss: 0.0000\n","Iter: 510, running loss: 0.0000\n","Iter: 511, running loss: 0.0000\n","Iter: 512, running loss: 0.0000\n","Iter: 513, running loss: 0.0000\n","Iter: 514, running loss: 0.0000\n","Iter: 515, running loss: 0.0000\n","Iter: 516, running loss: 0.0000\n","Iter: 517, running loss: 0.0000\n","Iter: 518, running loss: 0.0000\n","Iter: 519, running loss: 0.0000\n","Iter: 520, running loss: 0.0000\n","Iter: 521, running loss: 0.0000\n","Iter: 522, running loss: 0.0000\n","Iter: 523, running loss: 0.0000\n","Iter: 524, running loss: 0.0000\n","Iter: 525, running loss: 0.0000\n","Iter: 526, running loss: 0.0000\n","Iter: 527, running loss: 0.0000\n","Iter: 528, running loss: 0.0000\n","Iter: 529, running loss: 0.0000\n","Iter: 530, running loss: 0.0000\n","Iter: 531, running loss: 0.0000\n","Iter: 532, running loss: 0.0000\n","Iter: 533, running loss: 0.0000\n","Iter: 534, running loss: 0.0000\n","Iter: 535, running loss: 0.0000\n","Iter: 536, running loss: 0.0000\n","Iter: 537, running loss: 0.0000\n","Iter: 538, running loss: 0.0000\n","Iter: 539, running loss: 0.0000\n","Iter: 540, running loss: 0.0000\n","Iter: 541, running loss: 0.0000\n","Iter: 542, running loss: 0.0000\n","Iter: 543, running loss: 0.0000\n","Iter: 544, running loss: 0.0000\n","Iter: 545, running loss: 0.0000\n","Iter: 546, running loss: 0.0000\n","Iter: 547, running loss: 0.0000\n","Iter: 548, running loss: 0.0000\n","Iter: 549, running loss: 0.0000\n","Iter: 550, running loss: 0.0000\n","Iter: 551, running loss: 0.0000\n","Iter: 552, running loss: 0.0000\n","Iter: 553, running loss: 0.0000\n","Iter: 554, running loss: 0.0000\n","Iter: 555, running loss: 0.0000\n","Iter: 556, running loss: 0.0000\n","Iter: 557, running loss: 0.0000\n","Iter: 558, running loss: 0.0000\n","Iter: 559, running loss: 0.0000\n","Iter: 560, running loss: 0.0000\n","Iter: 561, running loss: 0.0000\n","Iter: 562, running loss: 0.0000\n","Iter: 563, running loss: 0.0000\n","Iter: 564, running loss: 0.0000\n","Iter: 565, running loss: 0.0000\n","Iter: 566, running loss: 0.0000\n","Iter: 567, running loss: 0.0000\n","Iter: 568, running loss: 0.0000\n","Iter: 569, running loss: 0.0000\n","Iter: 570, running loss: 0.0000\n","Iter: 571, running loss: 0.0000\n","Iter: 572, running loss: 0.0000\n","Iter: 573, running loss: 0.0000\n","Iter: 574, running loss: 0.0000\n","Iter: 575, running loss: 0.0000\n","Iter: 576, running loss: 0.0000\n","Iter: 577, running loss: 0.0000\n","Iter: 578, running loss: 0.0000\n","Iter: 579, running loss: 0.0000\n","Iter: 580, running loss: 0.0000\n","Iter: 581, running loss: 0.0000\n","Iter: 582, running loss: 0.0000\n","Iter: 583, running loss: 0.0000\n","Iter: 584, running loss: 0.0000\n","Iter: 585, running loss: 0.0000\n","Iter: 586, running loss: 0.0000\n","Iter: 587, running loss: 0.0000\n","Iter: 588, running loss: 0.0000\n","Iter: 589, running loss: 0.0000\n","Iter: 590, running loss: 0.0000\n","Iter: 591, running loss: 0.0000\n","Iter: 592, running loss: 0.0000\n","Iter: 593, running loss: 0.0000\n","Iter: 594, running loss: 0.0000\n","Iter: 595, running loss: 0.0000\n","Iter: 596, running loss: 0.0000\n","Iter: 597, running loss: 0.0000\n","Iter: 598, running loss: 0.0000\n","Iter: 599, running loss: 0.0000\n","Iter: 600, running loss: 0.0000\n","\n","\n","Training complete after 600 iters.\n","Time = 20.23326802253723\n","Train Loss = 1.6570026e-06\n","NFE = 26\n","Parameters = 571\n","Test Loss = 1.0490396e-06\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-376c44433893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dimension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             z0 = torch.tensor(np.load(  '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' + exp_name + '/data'\n\u001b[0;32m--> 151\u001b[0;31m                                       + '/vis_data/2d_vis_data.npy')).float()\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mntotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m#Augment z0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/experiment_3/data/vis_data/2d_vis_data.npy'"]}]},{"cell_type":"code","metadata":{"id":"-zCAM75wLjYr","colab":{"base_uri":"https://localhost:8080/","height":637},"executionInfo":{"status":"ok","timestamp":1617354477551,"user_tz":-60,"elapsed":908,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"a468f4a7-53f9-481e-d241-4bd3ce1dbf93"},"source":["#Generate loss curve plot.\n","exp_name = 'experiment_3'\n","\n","loss_data = np.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' \n","                    + exp_name + '/anode(1)/loss_arr.npy')\n","\n","iters = np.linspace(1,600,600)\n","\n","plt.figure(figsize=[10,10])\n","plt.plot(iters, loss_data)\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Loss Curve for Nested Spheres Experiment\\nANODE, Cross Entropy')\n","plt.savefig('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/cross_entropy/' \n","                    + exp_name + '/anode(1)/loss_curve.pdf')\n","plt.show()"],"execution_count":48,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}