{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nested_spheres_hessian_calculation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HF15L8a7zFO8ZAJiO9zAl3U2919lFzsA","authorship_tag":"ABX9TyP9JjAxcWTtWOjfxBDx15Uf"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"SQBS7KTR83Bw","executionInfo":{"status":"ok","timestamp":1616756273258,"user_tz":0,"elapsed":574,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","This file is used to calculate Hessian information for a model during training for the nested N-spheres task.\n","The analysis of these results is executed using the file nested_spheres_hessian_analysis.ipynb.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqZsIwjwmG2p","executionInfo":{"status":"ok","timestamp":1616756277286,"user_tz":0,"elapsed":4593,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","%%bash \n","pip install torchdiffeq"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iqOcAXt2wMy","executionInfo":{"status":"ok","timestamp":1616756279642,"user_tz":0,"elapsed":6945,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import os\n","import argparse\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4O95yfu3BLY","executionInfo":{"status":"ok","timestamp":1616756280262,"user_tz":0,"elapsed":7561,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--tol', type=float, default=1e-3)\n","parser.add_argument('--adjoint', type=eval, default=False)\n","parser.add_argument('--visualise', type=eval, default=True)\n","parser.add_argument('--niters', type=int, default=600)\n","parser.add_argument('--lr', type=float, default=0.01)\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--extra_dim', type=int, default=0)\n","parser.add_argument('--data_dimension', type=int, default=2)\n","parser.add_argument('--npoints', type=int, default=50)\n","parser.add_argument('--ntest', type=int, default=10)\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","parser.add_argument('--library_hessian', type=eval, default = False)\n","parser.add_argument('--manual_hessian', type=eval, default = False)\n","parser.add_argument('--mofd_hessian', type=eval, default = False)\n","args = parser.parse_args(args=[])\n","\n","args.hessian_freq = 5\n","if args.adjoint:\n","    from torchdiffeq import odeint_adjoint as odeint\n","else:\n","    from torchdiffeq import odeint\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2TQOgZL-ncp","executionInfo":{"status":"ok","timestamp":1616756280263,"user_tz":0,"elapsed":7559,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEfunc(nn.Module):\n","    \"\"\"\n","    Neural network to parametrise the derivative of the state vector. Maps from [dim] to [dim] dimensions.\n","    \"\"\"\n","    def __init__(self, dim, nhidden):\n","        super(ODEfunc, self).__init__()\n","        self.elu = nn.ELU(inplace=True)\n","        self.fc1 = nn.Linear(dim, nhidden)\n","        self.fc2 = nn.Linear(nhidden, nhidden)\n","        self.fc3 = nn.Linear(nhidden, dim)\n","        self.nfe = 0\n","\n","    def forward(self, t, x):\n","        self.nfe += 1\n","        out = self.fc1(x)\n","        out = self.elu(out)\n","        out = self.fc2(out)\n","        out = self.elu(out)\n","        out = self.fc3(out)\n","        return out\n","    \n","\n","class ODEBlock(nn.Module):\n","    \"\"\"\n","    Defines the entire ODE block that acts on the state vector, i.e. it perfoms integration on the state vector\n","    with the derivative given by an ODEFunc() object, and interval given by [t0, tN].\n","    \"\"\"\n","    def __init__(self, odefunc, t0_, tN_):\n","        super(ODEBlock, self).__init__()\n","        self.odefunc = odefunc\n","        self.integration_times = torch.tensor([t0_, tN_]).float()\n","        \n","    def forward(self, x):\n","        out = odeint(self.odefunc, x, self.integration_times, rtol=args.tol, atol=args.tol)\n","        out = out[1]\n","        return out\n","\n","    @property\n","    def nfe(self):\n","        return self.odefunc.nfe\n","\n","    @nfe.setter\n","    def nfe(self, value):\n","        self.odefunc.nfe = value"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2sAPLRp7qBG","executionInfo":{"status":"ok","timestamp":1616756280264,"user_tz":0,"elapsed":7556,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Function that maps 2D output to a scalar (i.e. 1D vector). The output is then compared to the desired value\n","    (either 1 or -1).\n","    \"\"\"\n","    def __init__(self, in_dim, out_dim):          #out_dim = 1.\n","        super(Decoder, self).__init__()\n","        self.tanh = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n","        self.fc = nn.Linear(in_dim, out_dim)\n","\n","    def forward(self, z):\n","        out = self.fc(z)\n","        out = self.tanh(out)\n","        return out\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RAmyxWJF4lo","executionInfo":{"status":"ok","timestamp":1616756280265,"user_tz":0,"elapsed":7553,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","Hessian calculation techniques. These are designed to work with any data dimension and augmentation.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-T8RK37Iv2Q","executionInfo":{"status":"ok","timestamp":1616756280266,"user_tz":0,"elapsed":7550,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Network(nn.Module):\n","  \"\"\"\n","  Neural network that is used for Hessian calculation with library-function and MOFD approaches.\n","  \"\"\"\n","\n","  def __init__(self, a, b, c, d, e, f):\n","    super(Network, self).__init__()\n","    self.a = a\n","    self.b = b\n","    self.c = c\n","    self.d = d\n","    self.e = e\n","    self.f = f\n","\n","  def forward(self, t, y):\n","    m = nn.ELU(inplace=True)\n","    x = F.linear(y, self.a, self.b)\n","    x = m(x)\n","    x = F.linear(x, self.c, self.d)\n","    x = m(x)\n","    x = F.linear(x, self.e, self.f)\n","\n","    return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6FEuA8HdDML","executionInfo":{"status":"ok","timestamp":1616756280267,"user_tz":0,"elapsed":7547,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Integrator(nn.Module):\n","  \"\"\"\n","  ODE block that is used to calculate the Hessian via the library and MOFD approaches.\n","  \"\"\"\n","  def __init__(self, g, h, odefunc, t0, tN):\n","    super(Integrator, self).__init__()\n","    self.g = g\n","    self.h = h\n","    self.odefunc = odefunc\n","    self.integration_times = torch.tensor([t0, tN]).float()\n","\n","  def forward(self, y):\n","    m = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n","    x = odeint(self.odefunc, y, self.integration_times, rtol=args.tol, atol=args.tol)\n","    x = x[1]\n","    x = F.linear(x, self.g, self.h)\n","    x = m(x)\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"owLk1ZZtIyAV","executionInfo":{"status":"ok","timestamp":1616756280268,"user_tz":0,"elapsed":7544,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_loss(params_vector):\n","\n","  a = params_vector[:nhidden*dim].reshape([nhidden, dim])\n","  b = params_vector[nhidden*dim:nhidden*(dim+1)].reshape([nhidden])\n","  c = params_vector[nhidden*(dim+1):nhidden*(dim+1)+nhidden**2].reshape([nhidden, nhidden])\n","  d = params_vector[nhidden*(dim+1)+nhidden**2:nhidden*(dim+2)+nhidden**2].reshape([nhidden])\n","  e = params_vector[nhidden*(dim+2)+nhidden**2:nhidden*(2*dim+2)+nhidden**2].reshape([dim,nhidden])\n","  f = params_vector[nhidden*(2*dim+2)+nhidden**2:nhidden*(2*dim+2)+nhidden**2+dim].reshape([dim])\n","  g = params_vector[nhidden*(2*dim+2)+nhidden**2+dim:nhidden*(2*dim+2)+nhidden**2+2*dim].reshape([1,dim])\n","  h = params_vector[nhidden*(2*dim+2)+nhidden**2+2*dim:nhidden*(2*dim+2)+nhidden**2+2*dim+1].reshape([1])\n","  \n","  neural_net = Network(a, b, c, d, e, f).to(device)\n","  full_block = Integrator(g, h, neural_net, t0, tN)\n","  pred_z = full_block(z0)\n","  loss_func = nn.MSELoss()\n","  loss = loss_func(pred_z, zN)\n","  return loss\n","\n","def get_library_hessian(net):\n","  \"\"\"\n","  Obtains the Hessian of the NODE using the autograd.functional.hessian() function.\n","  Inputs: \n","        - net: the network for which the Hessian is to be calculated.\n","  NB: Each individual NODE architecture must be specified in the function get_loss(), such that\n","  the Hessian is calculated correctly.\n","  \"\"\"\n","\n","  param_tensors = net.parameters()\n","  params_vector = torch.tensor([]).to(device)\n","  for param in param_tensors:\n","    vec = torch.reshape(param, (-1,)).to(device)\n","    params_vector = torch.cat((params_vector, vec))\n","\n","  hessian = torch.autograd.functional.hessian(get_loss, params_vector)\n","  return hessian"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y77p15C1G7Sa","executionInfo":{"status":"ok","timestamp":1616756280524,"user_tz":0,"elapsed":7797,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_manual_hessian(grads, parameters, show_iters=True):\n","  \"\"\"\n","  Calculation of the Hessian using nested for loops.\n","  Inputs:   - grads:        tuple of gradient tensors. Created using something \n","                            like grads = torch.autograd.grad(loss, parameters, create_graph=True).\n","            - parameters:   List of parameter objects. Created using something \n","                            like parameters = optimizer.param_groups[0]['params'].\n","            - show_iters:   True or False, depending on if the iteration number is to be shown during training. \n","                            Note that the iteration updates are not provided every row, but instead periodically \n","                            (roughly according to the number of parameters in the system).\n","  \"\"\"\n","  start = time.time()        \n","\n","  n_params = 0\n","  for param in parameters:\n","    n_params += torch.numel(param)\n","  grads2 = torch.zeros(n_params,n_params)            #Create an matrix of zeros thas has the same shape as the Hessian.\n","\n","  y_counter = 0                             #y_direction refers to row number in the Hessian.\n","\n","  for grad in grads:\n","      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \n","\n","      for j, g in enumerate(grad):\n","        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\n","\n","        for l, param in enumerate(parameters):\n","          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\n","          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\n","          len = g2.shape[0]                       \n","          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\n","          x_counter += len\n","\n","      grads2 = grads2.to(device)\n","      y_counter += grad.shape[0]\n","\n","      if show_iters:\n","        print(\"Gradients calculated for row number \" + str(y_counter) + \".\")\n","  \n","  print('Time used was ', time.time() - start)\n","\n","  return grads2"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCHdK1WeI1Lv","executionInfo":{"status":"ok","timestamp":1616756280709,"user_tz":0,"elapsed":7977,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_mofd_hessian_element(p_vec, shapes, base_loss, i, k, h=1e-4):\n","  \"\"\"\n","  Calculates an individual element of the Hessian via the MOFD.\n","  Inputs: - p_vec:        the parameters of the network organized into a vector.\n","          - shapes:       a list of torch.Size() objects describing the shapes of each parameter group.\n","          - base_loss:    loss of the unperturbed system. Used in calculating diagonal Hessian elements.\n","          - h:            the size of the pertubation applied to each parameter.\n","          - i and k:      the indices of the element to be calculated.\n","          - show_iters:   True or False according to whether iteration number is to be displayed during calculation.\n","\n","  Returns: - 'grad2':     torch.tensor() object containing the Hessian element H[i,k] = H[k,i].\n","  \n","  NB: This function adapts to network architecture automatically.\n","  The code is designed to convert all floats to 64-bit automatically.\n","  \"\"\"\n","  loss_func = nn.MSELoss()\n","\n","  #List of integers detailing the number of elements in each parameter group.\n","  nels = [int(torch.prod(torch.tensor(shape))) for shape in shapes]\n","  nels = torch.tensor(nels)\n","  nels = torch.cumsum(nels, dim=0)\n","  nels = nels.tolist()\n","\n","  #Empty tensors to store mofd info and perturbed parameters.\n","  up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_pert_p_vec = torch.zeros_like(p_vec).double()\n","\n","  up_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  up_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","    \n","  #Versions of the parameter vector to be perturbed.\n","  for j in range(len(p_vec)):\n","    up_pert_p_vec[j] = p_vec[j]\n","    low_pert_p_vec[j] = p_vec[j]\n","    \n","  #Calculate the diagonal elements.\n","  if k == i:\n","    up_pert_p_vec[k] += h\n","    low_pert_p_vec[k] -= h\n","\n","    a_up = up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up = up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up = up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up = up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up = up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up = up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up = up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up = up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low = low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low = low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low = low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low = low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low = low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low = low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low = low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low = low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    neural_net_up = Network(a_up, b_up, c_up, d_up, e_up, f_up).to(device)\n","    full_block = Integrator(g_up, h_up, neural_net_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_up = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_low = Network(a_low, b_low, c_low, d_low, e_low, f_low).to(device)\n","    full_block = Integrator(g_low, h_low, neural_net_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_low = loss = loss_func(pred_z, zN.double())\n","    \n","    grad2 = ((pert_loss_up - 2*base_loss + pert_loss_low)/(h**2)).double()\n","\n","  #Calculate the off-diagonal elements.\n","  if k > i:\n","    \n","    #Vectors to be perturbed (there are 4 of these).\n","    #They must be created individually for each k so that previous iterations do not affect the parameter values.\n","    for l in range(len(p_vec)):\n","      up_up_pert_p_vec[l] = p_vec[l]\n","      up_low_pert_p_vec[l] = p_vec[l]\n","      low_up_pert_p_vec[l] = p_vec[l]\n","      low_low_pert_p_vec[l] = p_vec[l]\n","\n","    up_up_pert_p_vec[i] += h\n","    up_up_pert_p_vec[k] += h\n","\n","    up_low_pert_p_vec[i] += h\n","    up_low_pert_p_vec[k] -= h\n","\n","    low_up_pert_p_vec[i] -= h\n","    low_up_pert_p_vec[k] += h\n","\n","    low_low_pert_p_vec[i] -= h\n","    low_low_pert_p_vec[k] -= h\n","\n","    a_up_up = up_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_up = up_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_up = up_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_up = up_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up_up = up_up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up_up = up_up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up_up = up_up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up_up = up_up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_up_low = up_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_low = up_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_low = up_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_low = up_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up_low = up_low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up_low = up_low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up_low = up_low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up_low = up_low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low_up = low_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_up = low_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_up = low_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_up = low_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low_up = low_up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low_up = low_up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low_up = low_up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low_up = low_up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low_low = low_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_low = low_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_low = low_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_low = low_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low_low = low_low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low_low = low_low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low_low = low_low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low_low = low_low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    neural_net_up_up = Network(a_up_up, b_up_up, c_up_up, d_up_up, e_up_up, f_up_up).to(device)\n","    full_block = Integrator(g_up_up, h_up_up, neural_net_up_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_up_up = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_up_low = Network(a_up_low, b_up_low, c_up_low, d_up_low, e_up_low, f_up_low).to(device)\n","    full_block = Integrator(g_up_low, h_up_low, neural_net_up_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_up_low = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_low_up = Network(a_low_up, b_low_up, c_low_up, d_low_up, e_low_up, f_low_up).to(device)\n","    full_block = Integrator(g_low_up, h_low_up, neural_net_low_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_low_up = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_low_low = Network(a_low_low, b_low_low, c_low_low, d_low_low, e_low_low, f_low_low).to(device)\n","    full_block = Integrator(g_low_low, h_low_low, neural_net_low_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_low_low = loss = loss_func(pred_z, zN.double())\n","    \n","    #MOFD formula to estimate second order gradient.\n","    grad2 = ((pert_loss_up_up - pert_loss_up_low - pert_loss_low_up + pert_loss_low_low)/(4*h**2)).double()\n","\n","  return grad2"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldCX1BeNF8Q5","executionInfo":{"status":"ok","timestamp":1616756280710,"user_tz":0,"elapsed":7974,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","Hessian calculation execution.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PedBgBcvZDGo","executionInfo":{"status":"ok","timestamp":1616762312042,"user_tz":0,"elapsed":537,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["#Download data\n","args.extra_dim = 0\n","exp_name = 'experiment_2'\n","name_in = str(args.data_dimension)+'din_'+str(args.npoints)+'_train.npy'        #Only use the training data.\n","name_out = str(args.data_dimension)+'dout_'+str(args.npoints)+'_train.npy'\n","folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/data/'\n","z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","\n","#Augment z0\n","zeros = torch.zeros(args.npoints, args.extra_dim).float()\n","z0 = torch.cat((z0, zeros), dim=1).to(device)\n","\n","dim = args.data_dimension + args.extra_dim\n","t0, tN = 0.0, 1.0\n","nhidden = 20\n","\n","#This code generates a model. Can be used instead of loading a pre-trained version.\n","#feature_layers = [ODEBlock(ODEfunc(dim, nhidden), t0, tN), Decoder(dim, 1)]\n","#model = nn.Sequential(*feature_layers).to(device)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1NzurBCvKWJ"},"source":["#Get manual and library Hessians for an individual iteration.\n","\n","itr = 10      #Iteration to examine.\n","\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/node/models/model_'\n","                  + str(itr) + '.pt')\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')\n","\n","#Get manual Hessian.\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","pred_y = model(z0)\n","base_loss_func = nn.MSELoss()\n","base_loss = base_loss_func(pred_y, zN)\n","grads = torch.autograd.grad(base_loss, model.parameters(), create_graph=True)\n","parameters = optimizer.param_groups[0]['params']\n","\n","print('Obtaining manual hessian...')\n","#manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\n","\n","#Get library hessian.\n","print('Obtaining library hessian...')\n","library_hessian = get_library_hessian(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8OPJaB79BzI"},"source":["#Create eigenvalue density plots for an individual iteration.\n","e, v = torch.symeig(library_hessian)\n","plt.hist(e, bins=150, color='Orange')\n","plt.xlabel('Eigenvalue')\n","plt.ylabel('Density')\n","plt.title('Eigenvalue density for library hessian\\nIteration: ' + str(itr))\n","plt.yscale('log')\n","plt.show()\n","\n","try:\n","  e, v = torch.symeig(manual_hessian)\n","  plt.hist(e, bins=150)\n","  plt.xlabel('Eigenvalue')\n","  plt.ylabel('Density')\n","  plt.title('Eigenvalue density for library hessian')\n","  plt.yscale('log')\n","  plt.show()\n","\n","except NameError:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcNlBxu6NNxH","outputId":"21019712-40a8-415b-e5f2-4de52d1eb52e"},"source":["#Calculate library Hessian data for every model during training.\n","library_hessian_data = []\n","for itr in range(0, 605, 5):\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/node/models/model_'\n","                  + str(itr) + '.pt')\n","  model = model.to(device)\n","\n","  print('Obtaining library hessian for iteration ' + str(itr) + '...')\n","  library_start = time.time()\n","  library_hessian = get_library_hessian(model)                       #get hessian with library functions   \n","  library_end = time.time()\n","  print(\"Time taken was \" + str(round(library_end-library_start,2)) + \"s.\")\n","\n","  library_hessian_data.append((itr, library_end-library_start, library_hessian))\n","\n","torch.save(library_hessian_data, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name \n","                                  + '/node/hessian_data/library_hessian_data.pt')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Obtaining library hessian for iteration 0...\n","Time taken was 5.13s.\n","Obtaining library hessian for iteration 5...\n","Time taken was 4.93s.\n","Obtaining library hessian for iteration 10...\n","Time taken was 7.41s.\n","Obtaining library hessian for iteration 15...\n","Time taken was 7.72s.\n","Obtaining library hessian for iteration 20...\n","Time taken was 9.41s.\n","Obtaining library hessian for iteration 25...\n","Time taken was 9.4s.\n","Obtaining library hessian for iteration 30...\n","Time taken was 11.99s.\n","Obtaining library hessian for iteration 35...\n","Time taken was 11.14s.\n","Obtaining library hessian for iteration 40...\n","Time taken was 13.53s.\n","Obtaining library hessian for iteration 45...\n","Time taken was 13.76s.\n","Obtaining library hessian for iteration 50...\n","Time taken was 13.26s.\n","Obtaining library hessian for iteration 55...\n","Time taken was 13.47s.\n","Obtaining library hessian for iteration 60...\n","Time taken was 15.66s.\n","Obtaining library hessian for iteration 65...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KWDNQfBiNafY"},"source":["#Plot the eigenvalue density plot for a given iteration from the library Hessian data file. \n","itr = 90\n","for item in library_hessian_data:\n","  if item[0] == itr:\n","    hess = item[2]\n","    e, v = torch.symeig(hess)\n","    plt.hist(e, bins=150)\n","    plt.yscale('log')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47MhGyuPzy0P"},"source":["#MOFD Hessian.\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/node/models/model_'\n","                  + str(itr) + '.pt')\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')\n","  \n","double_model = model.double()\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","#Prepare loss for MOFD.\n","pred_y = model(z0.double()).double()\n","base_loss_func = nn.MSELoss()\n","base_loss = base_loss_func(pred_y, zN.double()).double()\n","\n","#Prepare shape information for MOFD.\n","shapes = []\n","for param in model.parameters():\n","  shapes.append(param.shape)\n","\n","#Create vector of parameters.\n","param_tensors = double_model.parameters()\n","params_vec = torch.tensor([]).to(device)\n","for param in param_tensors:\n","  vec = torch.reshape(param, (-1,)).to(device)\n","  params_vec = torch.cat((params_vec, vec))\n","\n","print(library_hessian[0,:10])\n","\n","w = len(params_vec)                  #Range of elements to examine.\n","print('Getting MOFD Hessian for iteration ' + str(itr) + '...')\n","counter = w*(w+1)/2\n","mofd_hessian = torch.zeros((w,w)).double()\n","for i in range(w):\n","  for k in range(w):\n","\n","    #Only calculate for k >= i, in the same way as get_mofd_hessian_element().\n","    #Failing to do so yields UnboundLocalError since local variable, grad2, is referenced before assignment.\n","    if k >= i:                     \n","      element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-5)\n","      mofd_hessian[i,k] = element.item()    #.item() is required to prevent RAM growth.\n","      mofd_hessian[k,i] = element.item()\n","      counter -= 1\n","      print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(\"{:.4e}\".format(element.item())), end = '')\n","print('')\n","\n","torch.save(mofd_hessian, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/' + exp_name + '/node'\n","                        + '/hessian_data/' + str(itr) + '_mofd_hessian_5.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYuCWEc-zmZL"},"source":["#Calculate summed difference between 2 Hessians.\n","difference = 0\n","differences = []\n","for i in range(w):\n","  for k in range(w):\n","    if k >= i:\n","      difference += torch.abs(mofd_hessian[i,k]-library_hessian[i,k]).item()\n","      differences.append((torch.abs(mofd_hessian[i,k]-library_hessian[i,k]).item()))\n","\n","print(difference)\n","print(np.amax(differences))"],"execution_count":null,"outputs":[]}]}