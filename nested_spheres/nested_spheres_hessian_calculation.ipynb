{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nested_spheres_hessian_calculation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HF15L8a7zFO8ZAJiO9zAl3U2919lFzsA","authorship_tag":"ABX9TyPb5IP62LrLZFwzTVFvG6TX"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"SQBS7KTR83Bw","executionInfo":{"status":"ok","timestamp":1616672673358,"user_tz":0,"elapsed":576,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","This file is used to calculate Hessian information for a model during training for the nested N-spheres task.\n","The analysis of these results is executed using the file nested_spheres_hessian_analysis.ipynb.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqZsIwjwmG2p","executionInfo":{"status":"ok","timestamp":1616672677806,"user_tz":0,"elapsed":5006,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","%%bash \n","pip install torchdiffeq"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iqOcAXt2wMy","executionInfo":{"status":"ok","timestamp":1616672680681,"user_tz":0,"elapsed":7876,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import os\n","import argparse\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4O95yfu3BLY","executionInfo":{"status":"ok","timestamp":1616675512780,"user_tz":0,"elapsed":412,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--tol', type=float, default=1e-3)\n","parser.add_argument('--adjoint', type=eval, default=False)\n","parser.add_argument('--visualise', type=eval, default=True)\n","parser.add_argument('--niters', type=int, default=600)\n","parser.add_argument('--lr', type=float, default=0.01)\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--extra_dim', type=int, default=0)\n","parser.add_argument('--data_dimension', type=int, default=2)\n","parser.add_argument('--npoints', type=int, default=50)\n","parser.add_argument('--ntest', type=int, default=10)\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","parser.add_argument('--library_hessian', type=eval, default = False)\n","parser.add_argument('--manual_hessian', type=eval, default = False)\n","parser.add_argument('--mofd_hessian', type=eval, default = False)\n","args = parser.parse_args(args=[])\n","\n","args.hessian_freq = 5\n","if args.adjoint:\n","    from torchdiffeq import odeint_adjoint as odeint\n","else:\n","    from torchdiffeq import odeint\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2TQOgZL-ncp","executionInfo":{"status":"ok","timestamp":1616672682065,"user_tz":0,"elapsed":1374,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEfunc(nn.Module):\n","    \"\"\"\n","    Neural network to parametrise the derivative of the state vector. Maps from [dim] to [dim] dimensions.\n","    \"\"\"\n","    def __init__(self, dim, nhidden):\n","        super(ODEfunc, self).__init__()\n","        self.elu = nn.ELU(inplace=True)\n","        self.fc1 = nn.Linear(dim, nhidden)\n","        self.fc2 = nn.Linear(nhidden, nhidden)\n","        self.fc3 = nn.Linear(nhidden, dim)\n","        self.nfe = 0\n","\n","    def forward(self, t, x):\n","        self.nfe += 1\n","        out = self.fc1(x)\n","        out = self.elu(out)\n","        out = self.fc2(out)\n","        out = self.elu(out)\n","        out = self.fc3(out)\n","        return out\n","    \n","\n","class ODEBlock(nn.Module):\n","    \"\"\"\n","    Defines the entire ODE block that acts on the state vector, i.e. it perfoms integration on the state vector\n","    with the derivative given by an ODEFunc() object, and interval given by [t0, tN].\n","    \"\"\"\n","    def __init__(self, odefunc, t0_, tN_):\n","        super(ODEBlock, self).__init__()\n","        self.odefunc = odefunc\n","        self.integration_times = torch.tensor([t0_, tN_]).float()\n","        \n","    def forward(self, x):\n","        out = odeint(self.odefunc, x, self.integration_times, rtol=args.tol, atol=args.tol)\n","        out = out[1]\n","        return out\n","\n","    @property\n","    def nfe(self):\n","        return self.odefunc.nfe\n","\n","    @nfe.setter\n","    def nfe(self, value):\n","        self.odefunc.nfe = value"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2sAPLRp7qBG","executionInfo":{"status":"ok","timestamp":1616672682066,"user_tz":0,"elapsed":1371,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Function that maps 2D output to a scalar (i.e. 1D vector). The output is then compared to the desired value\n","    (either 1 or -1).\n","    \"\"\"\n","    def __init__(self, in_dim, out_dim):          #out_dim = 1.\n","        super(Decoder, self).__init__()\n","        self.tanh = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n","        self.fc = nn.Linear(in_dim, out_dim)\n","\n","    def forward(self, z):\n","        out = self.fc(z)\n","        out = self.tanh(out)\n","        return out\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RAmyxWJF4lo","executionInfo":{"status":"ok","timestamp":1616672682067,"user_tz":0,"elapsed":1367,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","Hessian calculation techniques. These are designed to work with any data dimension and augmentation.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-T8RK37Iv2Q","executionInfo":{"status":"ok","timestamp":1616672682068,"user_tz":0,"elapsed":1364,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Network(nn.Module):\n","  \"\"\"\n","  Neural network that is used for Hessian calculation with library-function and MOFD approaches.\n","  \"\"\"\n","\n","  def __init__(self, a, b, c, d, e, f):\n","    super(Network, self).__init__()\n","    self.a = a\n","    self.b = b\n","    self.c = c\n","    self.d = d\n","    self.e = e\n","    self.f = f\n","\n","  def forward(self, t, y):\n","    m = nn.ELU(inplace=True)\n","    x = F.linear(y, self.a, self.b)\n","    x = m(x)\n","    x = F.linear(x, self.c, self.d)\n","    x = m(x)\n","    x = F.linear(x, self.e, self.f)\n","\n","    return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6FEuA8HdDML","executionInfo":{"status":"ok","timestamp":1616672682070,"user_tz":0,"elapsed":1362,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Integrator(nn.Module):\n","  \"\"\"\n","  ODE block that is used to calculate the Hessian via the library and MOFD approaches.\n","  \"\"\"\n","  def __init__(self, g, h, odefunc, t0, tN):\n","    super(Integrator, self).__init__()\n","    self.g = g\n","    self.h = h\n","    self.odefunc = odefunc\n","    self.integration_times = torch.tensor([t0, tN]).float()\n","\n","  def forward(self, y):\n","    m = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n","    x = odeint(self.odefunc, y, self.integration_times, rtol=args.tol, atol=args.tol)\n","    x = x[1]\n","    x = F.linear(x, self.g, self.h)\n","    x = m(x)\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"owLk1ZZtIyAV","executionInfo":{"status":"ok","timestamp":1616672682071,"user_tz":0,"elapsed":1359,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_loss(params_vector):\n","\n","  a = params_vector[:nhidden*dim].reshape([nhidden, dim])\n","  b = params_vector[nhidden*dim:nhidden*(dim+1)].reshape([nhidden])\n","  c = params_vector[nhidden*(dim+1):nhidden*(dim+1)+nhidden**2].reshape([nhidden, nhidden])\n","  d = params_vector[nhidden*(dim+1)+nhidden**2:nhidden*(dim+2)+nhidden**2].reshape([nhidden])\n","  e = params_vector[nhidden*(dim+2)+nhidden**2:nhidden*(2*dim+2)+nhidden**2].reshape([dim,nhidden])\n","  f = params_vector[nhidden*(2*dim+2)+nhidden**2:nhidden*(2*dim+2)+nhidden**2+dim].reshape([dim])\n","  g = params_vector[nhidden*(2*dim+2)+nhidden**2+dim:nhidden*(2*dim+2)+nhidden**2+2*dim].reshape([1,dim])\n","  h = params_vector[nhidden*(2*dim+2)+nhidden**2+2*dim:nhidden*(2*dim+2)+nhidden**2+2*dim+1].reshape([1])\n","  \n","  neural_net = Network(a, b, c, d, e, f).to(device)\n","  full_block = Integrator(g, h, neural_net, t0, tN)\n","  pred_z = full_block(z0)\n","  loss_func = nn.MSELoss()\n","  loss = loss_func(pred_z, zN)\n","  return loss\n","\n","def get_library_hessian(net):\n","  \"\"\"\n","  Obtains the Hessian of the NODE using the autograd.functional.hessian() function.\n","  Inputs: \n","        - net: the network for which the Hessian is to be calculated.\n","  NB: Each individual NODE architecture must be specified in the function get_loss(), such that\n","  the Hessian is calculated correctly.\n","  \"\"\"\n","\n","  param_tensors = net.parameters()\n","  params_vector = torch.tensor([]).to(device)\n","  for param in param_tensors:\n","    vec = torch.reshape(param, (-1,)).to(device)\n","    params_vector = torch.cat((params_vector, vec))\n","\n","  hessian = torch.autograd.functional.hessian(get_loss, params_vector)\n","  return hessian"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y77p15C1G7Sa","executionInfo":{"status":"ok","timestamp":1616672682072,"user_tz":0,"elapsed":1356,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_manual_hessian(grads, parameters, show_iters=True):\n","  \"\"\"\n","  Calculation of the Hessian using nested for loops.\n","  Inputs:   - grads:        tuple of gradient tensors. Created using something \n","                            like grads = torch.autograd.grad(loss, parameters, create_graph=True).\n","            - parameters:   List of parameter objects. Created using something \n","                            like parameters = optimizer.param_groups[0]['params'].\n","            - show_iters:   True or False, depending on if the iteration number is to be shown during training. \n","                            Note that the iteration updates are not provided every row, but instead periodically \n","                            (roughly according to the number of parameters in the system).\n","  \"\"\"\n","  start = time.time()        \n","\n","  n_params = 0\n","  for param in parameters:\n","    n_params += torch.numel(param)\n","  grads2 = torch.zeros(n_params,n_params)            #Create an matrix of zeros thas has the same shape as the Hessian.\n","\n","  y_counter = 0                             #y_direction refers to row number in the Hessian.\n","\n","  for grad in grads:\n","      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \n","\n","      for j, g in enumerate(grad):\n","        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\n","\n","        for l, param in enumerate(parameters):\n","          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\n","          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\n","          len = g2.shape[0]                       \n","          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\n","          x_counter += len\n","\n","      grads2 = grads2.to(device)\n","      y_counter += grad.shape[0]\n","\n","      if show_iters:\n","        print(\"Gradients calculated for row number \" + str(y_counter) + \".\")\n","  \n","  print('Time used was ', time.time() - start)\n","\n","  return grads2"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCHdK1WeI1Lv","executionInfo":{"status":"ok","timestamp":1616672682642,"user_tz":0,"elapsed":1922,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_mofd_hessian_element(p_vec, shapes, base_loss, i, k, h=1e-4):\n","  \"\"\"\n","  Calculates an individual element of the Hessian via the MOFD.\n","  Inputs: - p_vec:        the parameters of the network organized into a vector.\n","          - shapes:       a list of torch.Size() objects describing the shapes of each parameter group.\n","          - base_loss:    loss of the unperturbed system. Used in calculating diagonal Hessian elements.\n","          - h:            the size of the pertubation applied to each parameter.\n","          - i and k:      the indices of the element to be calculated.\n","          - show_iters:   True or False according to whether iteration number is to be displayed during calculation.\n","\n","  Returns: - 'grad2':     torch.tensor() object containing the Hessian element H[i,k] = H[k,i].\n","  \n","  NB: This function adapts to network architecture automatically.\n","  The code is designed to convert all floats to 64-bit automatically.\n","  \"\"\"\n","  loss_func = nn.MSELoss()\n","\n","  #List of integers detailing the number of elements in each parameter group.\n","  nels = [int(torch.prod(torch.tensor(shape))) for shape in shapes]\n","  nels = torch.tensor(nels)\n","  nels = torch.cumsum(nels, dim=0)\n","  nels = nels.tolist()\n","\n","  #Empty tensors to store mofd info and perturbed parameters.\n","  up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_pert_p_vec = torch.zeros_like(p_vec).double()\n","\n","  up_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  up_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","    \n","  #Versions of the parameter vector to be perturbed.\n","  for j in range(len(p_vec)):\n","    up_pert_p_vec[j] = p_vec[j]\n","    low_pert_p_vec[j] = p_vec[j]\n","    \n","  #Calculate the diagonal elements.\n","  if k == i:\n","    up_pert_p_vec[k] += h\n","    low_pert_p_vec[k] -= h\n","\n","    a_up = up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up = up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up = up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up = up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up = up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up = up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up = up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up = up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low = low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low = low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low = low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low = low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low = low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low = low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low = low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low = low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    neural_net_up = Network(a_up, b_up, c_up, d_up, e_up, f_up).to(device)\n","    full_block = Integrator(g_up, h_up, neural_net_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_up = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_low = Network(a_low, b_low, c_low, d_low, e_low, f_low).to(device)\n","    full_block = Integrator(g_low, h_low, neural_net_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_low = loss = loss_func(pred_z, zN.double())\n","    \n","    grad2 = ((pert_loss_up - 2*base_loss + pert_loss_low)/(h**2)).double()\n","\n","  #Calculate the off-diagonal elements.\n","  if k > i:\n","    \n","    #Vectors to be perturbed (there are 4 of these).\n","    #They must be created individually for each k so that previous iterations do not affect the parameter values.\n","    for l in range(len(p_vec)):\n","      up_up_pert_p_vec[l] = p_vec[l]\n","      up_low_pert_p_vec[l] = p_vec[l]\n","      low_up_pert_p_vec[l] = p_vec[l]\n","      low_low_pert_p_vec[l] = p_vec[l]\n","\n","    up_up_pert_p_vec[i] += h\n","    up_up_pert_p_vec[k] += h\n","\n","    up_low_pert_p_vec[i] += h\n","    up_low_pert_p_vec[k] -= h\n","\n","    low_up_pert_p_vec[i] -= h\n","    low_up_pert_p_vec[k] += h\n","\n","    low_low_pert_p_vec[i] -= h\n","    low_low_pert_p_vec[k] -= h\n","\n","    a_up_up = up_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_up = up_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_up = up_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_up = up_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up_up = up_up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up_up = up_up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up_up = up_up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up_up = up_up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_up_low = up_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_low = up_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_low = up_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_low = up_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_up_low = up_low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_up_low = up_low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_up_low = up_low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_up_low = up_low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low_up = low_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_up = low_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_up = low_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_up = low_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low_up = low_up_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low_up = low_up_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low_up = low_up_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low_up = low_up_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    a_low_low = low_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_low = low_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_low = low_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_low = low_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","    e_low_low = low_low_pert_p_vec[nels[3]:nels[4]].reshape(shapes[4])\n","    f_low_low = low_low_pert_p_vec[nels[4]:nels[5]].reshape(shapes[5])\n","    g_low_low = low_low_pert_p_vec[nels[5]:nels[6]].reshape(shapes[6])\n","    h_low_low = low_low_pert_p_vec[nels[6]:nels[7]].reshape(shapes[7])\n","\n","    neural_net_up_up = Network(a_up_up, b_up_up, c_up_up, d_up_up, e_up_up, f_up_up).to(device)\n","    full_block = Integrator(g_up_up, h_up_up, neural_net_up_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_up_up = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_up_low = Network(a_up_low, b_up_low, c_up_low, d_up_low, e_up_low, f_up_low).to(device)\n","    full_block = Integrator(g_up_low, h_up_low, neural_net_up_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_up_low = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_low_up = Network(a_low_up, b_low_up, c_low_up, d_low_up, e_low_up, f_low_up).to(device)\n","    full_block = Integrator(g_low_up, h_low_up, neural_net_low_up, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_low_up = loss = loss_func(pred_z, zN.double())\n","\n","    neural_net_low_low = Network(a_low_low, b_low_low, c_low_low, d_low_low, e_low_low, f_low_low).to(device)\n","    full_block = Integrator(g_low_low, h_low_low, neural_net_low_low, t0, tN)\n","    pred_z = full_block(z0.double())\n","    loss_func = nn.MSELoss()\n","    pert_loss_low_low = loss = loss_func(pred_z, zN.double())\n","    \n","    #MOFD formula to estimate second order gradient.\n","    grad2 = ((pert_loss_up_up - pert_loss_up_low - pert_loss_low_up + pert_loss_low_low)/(4*h**2)).double()\n","\n","  return grad2"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldCX1BeNF8Q5","executionInfo":{"status":"ok","timestamp":1616672682645,"user_tz":0,"elapsed":1920,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","Hessian calculation execution.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PedBgBcvZDGo","executionInfo":{"status":"ok","timestamp":1616686556035,"user_tz":0,"elapsed":934,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["#Download data\n","args.extra_dim = 0\n","name_in = str(args.data_dimension)+'din_'+str(args.npoints)+'_train.npy'        #Only use the training data.\n","name_out = str(args.data_dimension)+'dout_'+str(args.npoints)+'_train.npy'\n","folder_name = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/data/'\n","z0 = torch.tensor(np.load(folder_name+name_in)).float().to(device)\n","zN = torch.tensor(np.load(folder_name+name_out)).float().to(device)\n","\n","#Augment z0\n","zeros = torch.zeros(args.npoints, args.extra_dim).float()\n","z0 = torch.cat((z0, zeros), dim=1).to(device)\n","\n","dim = args.data_dimension + args.extra_dim\n","t0, tN = 0.0, 1.0\n","nhidden = 20\n","\n","#This code generates a model. Can be used instead of loading a pre-trained version.\n","#feature_layers = [ODEBlock(ODEfunc(dim, nhidden), t0, tN), Decoder(dim, 1)]\n","#model = nn.Sequential(*feature_layers).to(device)\n","\n","itr = 600       #Iteration to examine.\n","\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/node/models/model_'\n","                  + str(itr) + '.pt')\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1NzurBCvKWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616686576656,"user_tz":0,"elapsed":18773,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"d4874204-eb4a-4dd2-f184-f3094405a6dc"},"source":["#Get manual Hessian.\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","pred_y = model(z0)\n","base_loss_func = nn.MSELoss()\n","base_loss = base_loss_func(pred_y, zN)\n","grads = torch.autograd.grad(base_loss, model.parameters(), create_graph=True)\n","parameters = optimizer.param_groups[0]['params']\n","\n","print('Obtaining manual hessian...')\n","#manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\n","\n","#Get library hessian.\n","print('Obtaining library hessian...')\n","library_hessian = get_library_hessian(model)"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Obtaining manual hessian...\n","Obtaining library hessian...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"r8OPJaB79BzI","executionInfo":{"status":"ok","timestamp":1616686576891,"user_tz":0,"elapsed":15999,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"2dc85908-2c83-48bc-b338-88a3b5825cee"},"source":["e, v = torch.symeig(library_hessian)\n","plt.hist(e, bins=150, color='Orange')\n","plt.yscale('log')\n","plt.show()\n","\n","e, v = torch.symeig(manual_hessian)\n","plt.hist(e, bins=150)\n","plt.yscale('log')\n","plt.show()"],"execution_count":84,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"5QBxIueP9sh8","executionInfo":{"status":"ok","timestamp":1616685638307,"user_tz":0,"elapsed":4564,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"9a80c84b-69fb-4332-c8ad-b0bd8c04abff"},"source":["for item in library_hessian_data:\n","  if item[0] == 90:\n","    hess = item[2]\n","    e, v = torch.symeig(hess)\n","    plt.hist(e, bins=150)\n","    plt.yscale('log')\n","    plt.show()"],"execution_count":43,"outputs":[{"output_type":"stream","text":["getting hessian...\n","getting eigenvalues...\n","plotting...\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"VcNlBxu6NNxH","executionInfo":{"status":"error","timestamp":1616686141393,"user_tz":0,"elapsed":23291,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"275fb5db-1298-4e12-f34b-1dc3770721d4"},"source":["library_hessian_data = []\n","for itr in range(0, 605, 5):\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/node/models/model_'\n","                  + str(itr) + '.pt')\n","  model = model.to(device)\n","\n","  print('Obtaining library hessian for iteration ' + str(itr) + '...')\n","  library_start = time.time()\n","  library_hessian = get_library_hessian(model)                       #get hessian with library functions   \n","  library_end = time.time()\n","  print(\"Time taken was \" + str(round(library_end-library_start,2)) + \"s.\")\n","\n","  library_hessian_data.append((itr, library_end-library_start, library_hessian))\n","\n","#torch.save(library_hessian_data, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/node/hessian_data/library_hessian_data.pt')\n"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Obtaining library hessian for iteration 0...\n","Time taken was 5.16s.\n","Obtaining library hessian for iteration 5...\n","Time taken was 5.28s.\n","Obtaining library hessian for iteration 10...\n","Time taken was 7.48s.\n","Obtaining library hessian for iteration 15...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-0e2de538eb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Obtaining library hessian for iteration '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mlibrary_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mlibrary_hessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_library_hessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m#get hessian with library functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mlibrary_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken was \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlibrary_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"s.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-76ee26f38f1a>\u001b[0m in \u001b[0;36mget_library_hessian\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mparams_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tuple_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             vj = _autograd_grad((out.reshape(-1)[j],), inputs,\n\u001b[0;32m--> 570\u001b[0;31m                                 retain_graph=True, create_graph=create_graph)\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mel_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjac_i_el\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvj_el\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_el\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[0;32m--> 148\u001b[0;31m                                    create_graph=create_graph, retain_graph=retain_graph)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fill_in_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0m_is_legacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Frn2O7cfZRFd"},"source":["library_hessian_data = []\n","for itr in range(0, 605, 5):\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/anode(1)/models/model_'\n","                  + str(itr) + '.pt')\n","  model = model.to(device)\n","\n","  print('Obtaining library hessian for iteration ' + str(itr) + '...')\n","  library_start = time.time()\n","  library_hessian = get_library_hessian(model)                       #get hessian with library functions   \n","  library_end = time.time()\n","  print(\"Time taken was \" + str(round(library_end-library_start,2)) + \"s.\")\n","\n","  library_hessian_data.append((itr, library_end-library_start, library_hessian))\n","\n","torch.save(library_hessian_data, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/anode(1)/hessian_data/library_hessian_data.pt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47MhGyuPzy0P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616605990082,"user_tz":0,"elapsed":14797577,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"3cba0d9f-f9f1-41f8-8ae6-b603c2533ea2"},"source":["#MOFD Hessian.\n","if args.extra_dim == 0:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/node/models/model_'\n","                  + str(itr) + '.pt')\n","else:\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/experiment_2/anode('\n","                    +str(args.extra_dim)+')/models/model_'+ str(itr) + '.pt')\n","  \n","double_model = model.double()\n","optimizer = optim.Adam(model.parameters())\n","optimizer.zero_grad()\n","\n","#Prepare loss for MOFD.\n","pred_y = model(z0.double()).double()\n","base_loss_func = nn.MSELoss()\n","base_loss = base_loss_func(pred_y, zN.double()).double()\n","\n","#Prepare shape information for MOFD.\n","shapes = []\n","for param in model.parameters():\n","  shapes.append(param.shape)\n","\n","#Create vector of parameters.\n","param_tensors = double_model.parameters()\n","params_vec = torch.tensor([]).to(device)\n","for param in param_tensors:\n","  vec = torch.reshape(param, (-1,)).to(device)\n","  params_vec = torch.cat((params_vec, vec))\n","\n","print(library_hessian[0,:10])\n","\n","w = len(params_vec)                  #Range of elements to examine.\n","print('Getting MOFD Hessian for iteration ' + str(itr) + '...')\n","counter = w*(w+1)/2\n","mofd_hessian = torch.zeros((w,w)).double()\n","for i in range(w):\n","  for k in range(w):\n","\n","    #Only calculate for k >= i, in the same way as get_mofd_hessian_element().\n","    #Failing to do so yields UnboundLocalError since local variable, grad2, is referenced before assignment.\n","    if k >= i:                     \n","      element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-5)\n","      mofd_hessian[i,k] = element.item()    #.item() is required to prevent RAM growth.\n","      mofd_hessian[k,i] = element.item()\n","      counter -= 1\n","      print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(\"{:.4e}\".format(element.item())), end = '')\n","print('')\n","\n","torch.save(mofd_hessian, '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/nested_spheres/anode(1)'\n","                        + '/hessian_data/' + str(itr) + '_mofd_hessian_5.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([ 0.1515,  0.2081,  0.2966,  0.0526,  0.2258,  0.4120, -0.2956, -0.3247,\n","        -0.4472,  0.5801])\n","Getting MOFD Hessian for iteration 160...\n","Iterations remaining: 0, Element: 4.0000e-02\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LYuCWEc-zmZL"},"source":["#Calculate summed difference between 2 Hessians.\n","difference = 0\n","differences = []\n","for i in range(w):\n","  for k in range(w):\n","    if k >= i:\n","      difference += torch.abs(mofd_hessian[i,k]-library_hessian[i,k]).item()\n","      differences.append((torch.abs(mofd_hessian[i,k]-library_hessian[i,k]).item()))\n","\n","print(difference)\n","print(np.amax(differences))"],"execution_count":null,"outputs":[]}]}