{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sinusoidal_curve.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14wJa-DmpMcpY7Wt6DfuFbmNE1WYfJomu","authorship_tag":"ABX9TyOHUGVwFycU/a92X6xbMc7i"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SQBS7KTR83Bw"},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","This file is used to compute fit a pair of coupled 1D sinusoidal ODEs. It calculated the Hessian during this process using the library-function approach.\n","Hessian calculations via the \"manual\" approach and the MOFD were considered too lengthy to be part of the same file, and can instead be found in the file\n","hessians_sinusoidal.ipynb.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqZsIwjwmG2p"},"source":["%%capture\n","%%bash \n","pip install torchdiffeq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iqOcAXt2wMy"},"source":["import os\n","import argparse\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4O95yfu3BLY"},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n","parser.add_argument('--data_size', type=int, default=1000)\n","parser.add_argument('--batch_time', type=int, default=10)\n","parser.add_argument('--batch_size', type=int, default=20)\n","parser.add_argument('--niters', type=int, default=100)\n","parser.add_argument('--test_freq', type=int, default=20)\n","parser.add_argument('--viz', action='store_true')\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--adjoint', action='store_true')\n","parser.add_argument('--manual_hessian', action='store_true')\n","parser.add_argument('--library_hessian', action='store_true')\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","args = parser.parse_args(args=[])\n","\n","args.batch_size = 200\n","args.batch_time = 50\n","args.niters = 1000\n","args.test_freq = 100\n","args.library_hessian = False\n","args.manual_hessian = False\n","args.viz = True\n","args.hessian_freq = 100\n","args.method = 'dopri5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2TQOgZL-ncp"},"source":["#The technique only works when the adjoint method is not used. If it is used, the Hessian returned is a matrix of zeros.\n","adjoint = False\n","\n","if adjoint == True:\n","    from torchdiffeq import odeint_adjoint as odeint\n","if adjoint == False:\n","    from torchdiffeq import odeint\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","\n","true_y0 = torch.tensor([[2., 1.]]).to(device)\n","t = torch.linspace(0., 25., args.data_size).to(device)\n","f = 3.0\n","true_A = torch.tensor([[0.0, f], [-f, -0.0]]).to(device)\n","\n","class Lambda(nn.Module):\n","\n","    def forward(self, t, y):\n","        return torch.mm(y, true_A)\n","\n","#The true solution defines two sinusoidal curves.\n","with torch.no_grad():\n","    true_y = odeint(Lambda(), true_y0, t, method = args.method)\n","\n","def get_batch():\n","\n","    s = torch.from_numpy(np.random.choice(np.arange(args.data_size - args.batch_time, dtype=np.int64), args.batch_size, replace=False)) \n","    batch_y0 = true_y[s]  # (M, D) \n","    batch_t = t[:args.batch_time]  # (T) \n","    batch_y = torch.stack([true_y[s + i] for i in range(args.batch_time)], dim=0)  # (T, M, D) \n","    return batch_y0.to(device), batch_t.to(device), batch_y.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-3krz_a_bgU"},"source":["%%capture\n","def makedirs(dirname):\n","    if not os.path.exists(dirname):\n","        os.makedirs(dirname)\n","        \n","if args.viz:\n","    makedirs('png')\n","    import matplotlib.pyplot as plt\n","    fig = plt.figure(figsize=(12, 4), facecolor='white')    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ImySTI6ghqO"},"source":["def visualize(true_y, pred_y, odefunc, itr):\n","\n","  \"\"\"\n","  This slightly altered version of the function visualize() seems to work fine. The only change is that I have moved the plt.figure() part of the code\n","  inside the function itself, i.e. I am creating a new figure environment for every figure, instead of editing the same environment multiple times.\n","  \"\"\"\n","\n","  if args.viz:\n","\n","    fig = plt.figure(figsize=(12, 4), facecolor='white')\n","    ax_traj = fig.add_subplot(131, frameon=False)        \n","    ax_phase = fig.add_subplot(132, frameon=False)\n","    ax_vecfield = fig.add_subplot(133, frameon=False)\n","\n","    ax_traj.set_title('Trajectories')\n","    ax_traj.set_xlabel('t')\n","    ax_traj.set_ylabel('x,y')\n","    ax_traj.plot(t.cpu().numpy(), true_y.cpu().numpy()[:, 0, 0], t.cpu().numpy(), true_y.cpu().numpy()[:, 0, 1], 'g-')\n","    ax_traj.plot(t.cpu().numpy(), pred_y.cpu().numpy()[:, 0, 0], '--', t.cpu().numpy(), pred_y.cpu().numpy()[:, 0, 1], 'b--')\n","    ax_traj.set_xlim(t.cpu().min(), t.cpu().max())\n","    ax_traj.set_ylim(-2.5, 2.5)\n","\n","    ax_phase.set_title('Phase Portrait')\n","    ax_phase.set_xlabel('x')\n","    ax_phase.set_ylabel('y')\n","    ax_phase.plot(true_y.cpu().numpy()[:, 0, 0], true_y.cpu().numpy()[:, 0, 1], 'g-')\n","    ax_phase.plot(pred_y.cpu().numpy()[:, 0, 0], pred_y.cpu().numpy()[:, 0, 1], 'b--')\n","    ax_phase.set_xlim(-2.5, 2.5)\n","    ax_phase.set_ylim(-2.5, 2.5)\n","\n","    ax_vecfield.set_title('Learned Vector Field')\n","    ax_vecfield.set_xlabel('x')\n","    ax_vecfield.set_ylabel('y')\n","\n","    y, x = np.mgrid[-2:2:21j, -2:2:21j]\n","    dydt = odefunc(0, torch.Tensor(np.stack([x, y], -1).reshape(21 * 21, 2)).to(device)).cpu().detach().numpy()\n","    mag = np.sqrt(dydt[:, 0]**2 + dydt[:, 1]**2).reshape(-1, 1)\n","    dydt = (dydt / mag)\n","    dydt = dydt.reshape(21, 21, 2)\n","\n","    ax_vecfield.streamplot(x, y, dydt[:, :, 0], dydt[:, :, 1], color=\"black\")\n","    ax_vecfield.set_xlim(-2, 2)\n","    ax_vecfield.set_ylim(-2, 2)\n","\n","    fig.tight_layout()\n","    plt.savefig('png/{:03d}'.format(itr))\n","    plt.draw()\n","    plt.pause(0.001)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo8kpZybTYMh"},"source":["class ODEFunc(nn.Module):\n","    \"\"\"\n","    Defines a very simple neural net with a 1D latent space. It has 4 parameters (2 weights and 2 biases).\n","    There is a Tanh() activation function used on the hidden layer.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ODEFunc, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(2, 7),\n","            nn.Tanh(),\n","            nn.Linear(7, 2),\n","        )\n","\n","        for m in self.net.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, mean=0, std=0.1)\n","                nn.init.constant_(m.bias, val=0)\n","\n","    def forward(self, t, y):\n","        return self.net(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-T8RK37Iv2Q"},"source":["class Network(nn.Module):\n","  \"\"\"\n","  Neural network that is used for Hessian calculation with library-function and MOFD approaches.\n","  The parameter groups are chosen to match those of ODEFunc().\n","  \"\"\"\n","\n","  def __init__(self, a, b, c, d):\n","    super(Network, self).__init__()\n","    self.a = a\n","    self.b = b\n","    self.c = c\n","    self.d = d\n","\n","  def forward(self, t, y):\n","    x = F.linear(y, self.a, self.b)\n","    m = nn.Tanh()\n","    x = m(x)\n","    x = F.linear(x, self.c, self.d)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"owLk1ZZtIyAV"},"source":["def get_loss(params_vector):\n","\n","  a = params_vector[:14].reshape([7, 2])\n","  b = params_vector[14:21].reshape([7])\n","  c = params_vector[21:35].reshape([2, 7])\n","  d = params_vector[35:37].reshape([2])\n","  \n","  neural_net = Network(a, b, c, d).to(device)\n","  pred_y = odeint(neural_net, true_y0, t, method= args.method)\n","  loss = torch.mean(torch.abs(pred_y - true_y))\n","  return loss\n","\n","def get_library_hessian(net):\n","  \"\"\"\n","  Obtains the Hessian of the NODE using the autograd.functional.hessian() function.\n","  Inputs: \n","        - net: the network for which the Hessian is to be calculated.\n","  NB: Each individual NODE architecture must be specified in the function get_loss(), such that\n","  the Hessian is calculated correctly.\n","  \"\"\"\n","\n","  param_tensors = net.parameters()\n","  params_vector = torch.tensor([]).to(device)\n","  for param in param_tensors:\n","    vec = torch.reshape(param, (-1,)).to(device)\n","    params_vector = torch.cat((params_vector, vec))\n","\n","  hessian = torch.autograd.functional.hessian(get_loss, params_vector)\n","  return hessian"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GP337SbeTYl6"},"source":["if __name__ == '__main__':\n","    \"\"\"\n","    Executes the programme. This includes doing the following:\n","\n","      - Trains the network;\n","      - Outputs the results in a series of png files (if desired);\n","      - Outputs hessian matrix information in list form.\n","    \"\"\"\n","\n","    ii = 0\n","\n","    func = ODEFunc().to(device)\n","    \n","    optimizer = optim.RMSprop(func.parameters(), lr=3e-4) #func.parameters are the parameters to optimise.\n","    library_hessian_data = []   #Will be a list of tuples like (iteration number, time, loss, hessian data).\n","    loss_data = []\n","\n","    for itr in range(1, args.niters + 1):\n","  \n","        optimizer.zero_grad()                                 \n","        \n","        batch_y0, batch_t, batch_y = get_batch()             \n","        pred_y = odeint(func, batch_y0, batch_t, method = args.method)\n","        loss = torch.mean(torch.abs(pred_y - batch_y))     \n","\n","        loss.backward(create_graph=True)                                                                     \n","        \n","        if itr % args.hessian_freq == 0 or itr==1:\n","          if args.library_hessian:\n","            print('Obtaining library hessian...')\n","            library_start = time.time()\n","            library_hessian = get_library_hessian(func)                       #get hessian with library functions   \n","            library_end = time.time()\n","            print(\"Time taken for library-based approach was \" + str(round(library_end-library_start,2)) + \"s.\")\n","            library_hessian_data.append((itr, library_end-library_start, loss.item(), library_hessian))\n","\n","\n","        if itr % args.test_freq == 0 or itr == 1:\n","          ii += 1       \n","          with torch.no_grad():\n","              pred_y = odeint(func, true_y0, t, method= args.method)\n","              loss = torch.mean(torch.abs(pred_y - true_y))\n","              loss_data.append((itr, loss.item()))\n","              print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n","              visualize(true_y, pred_y, func, ii)\n","\n","              #torch.save(func,    '/content/drive/MyDrive/colab_notebooks/calculating_hessians/'\n","                    #+ 'testing_on_simple_nodes/sinusoidal_curve/more_developed_system/models/finesse/model_'\n","                    #+  str(itr) + '.pt' )          \n","\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fhfBXp5MOKoR"},"source":["#torch.save(library_hessian_data, '/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/'\n","                        #+ 'sinusoidal_curve/12000_iters/hessian_data/library_hessian_data.pt')\n","\n","torch.save(loss_data, '/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/'\n","                        + 'sinusoidal_curve/more_developed_system/finesse/loss_data.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVFB8t6HKxl_"},"source":["#Create a plot of the loss curve.\n","itrs = []\n","data = []\n","\n","for item in loss_data:\n","  itrs.append(item[0])\n","  data.append(item[1])\n","\n","plt.figure(figsize=(10,8))\n","plt.rcParams.update({'font.size': 14})\n","plt.plot(itrs, data)\n","plt.title('Loss function for more complex system\\nGradient Descent'\n","          + '\\nLearning Rate = 1e-6' )\n","plt.xlabel('Iterations')\n","plt.ylabel('Loss')\n","plt.savefig('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/'\n","                        + 'sinusoidal_curve/more_developed_system/finesse/loss_curve.png')\n","plt.show()"],"execution_count":null,"outputs":[]}]}