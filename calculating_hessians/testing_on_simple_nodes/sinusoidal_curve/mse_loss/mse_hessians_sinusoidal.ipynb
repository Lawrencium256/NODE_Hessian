{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mse_hessians_sinusoidal.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1EenAcBhTQX7J9N4iQVN5ZNeu3SkKoo5b","authorship_tag":"ABX9TyMh6yzluv3C8F7UH3tSEtGZ"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"SQBS7KTR83Bw","executionInfo":{"status":"ok","timestamp":1616150212762,"user_tz":0,"elapsed":589,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","This file is used to calculate Hessian information for a model during training to fit a 1D sinusoidal ODE.\n","The approach used differs to that used for a 1D exponential ODE, since it stores intermediate values as to ensure\n","that the calculation does not exceed RAM limitations.\n","It is designed to work for slightly larger systems (in particular, a NODE with a 7D latent space). For instance, it only calculates the \n","Hessian for the MOFD with 1 (carefully made) choice of pertubation parameter.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqZsIwjwmG2p","executionInfo":{"status":"ok","timestamp":1616150217074,"user_tz":0,"elapsed":4894,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","%%bash \n","pip install torchdiffeq"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iqOcAXt2wMy","executionInfo":{"status":"ok","timestamp":1616150219832,"user_tz":0,"elapsed":7648,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import os\n","import argparse\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4O95yfu3BLY","executionInfo":{"status":"ok","timestamp":1616150219834,"user_tz":0,"elapsed":7647,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n","parser.add_argument('--data_size', type=int, default=1000)\n","parser.add_argument('--batch_time', type=int, default=10)\n","parser.add_argument('--batch_size', type=int, default=20)\n","parser.add_argument('--niters', type=int, default=100)\n","parser.add_argument('--test_freq', type=int, default=20)\n","parser.add_argument('--viz', action='store_true')\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--adjoint', action='store_true')\n","parser.add_argument('--manual_hessian', action='store_true')\n","parser.add_argument('--library_hessian', action='store_true')\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","args = parser.parse_args(args=[])\n","\n","args.batch_size = 40\n","args.batch_time = 20\n","args.niters=1000\n","args.test_freq=20\n","args.library_hessian = True\n","args.manual_hessian = False\n","args.viz = True\n","args.hessian_freq = 100\n","args.method = 'dopri5'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2TQOgZL-ncp","executionInfo":{"status":"ok","timestamp":1616150222289,"user_tz":0,"elapsed":2452,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["#The technique only works when the adjoint method is not used. If it is used, the Hessian returned is a matrix of zeros.\n","adjoint = False\n","\n","if adjoint == True:\n","    from torchdiffeq import odeint_adjoint as odeint\n","if adjoint == False:\n","    from torchdiffeq import odeint\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","\n","true_y0 = torch.tensor([[2., 1.]]).to(device)\n","t = torch.linspace(0., 25., args.data_size).to(device)\n","f = 3.0\n","true_A = torch.tensor([[0.0, f], [-f, -0.0]]).to(device)\n","\n","class Lambda(nn.Module):\n","\n","    def forward(self, t, y):\n","        return torch.mm(y, true_A)\n","\n","#The true solution defines two sinusoidal curves.\n","with torch.no_grad():\n","    true_y = odeint(Lambda(), true_y0, t, method = args.method)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9lEoAsnP7cT","executionInfo":{"status":"ok","timestamp":1616150223862,"user_tz":0,"elapsed":471,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEFunc(nn.Module):\n","    \"\"\"\n","    Defines a very simple neural net with a 1D latent space. It has 4 parameters (2 weights and 2 biases).\n","    There is a Tanh() activation function used on the hidden layer.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ODEFunc, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(2, 8),\n","            nn.Tanh(),\n","            nn.Linear(8, 2),\n","        )\n","\n","        for m in self.net.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, mean=0, std=0.1)\n","                nn.init.constant_(m.bias, val=0)\n","\n","    def forward(self, t, y):\n","        return self.net(y)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-T8RK37Iv2Q"},"source":["class Network(nn.Module):\n","  \"\"\"\n","  Neural network that is used for Hessian calculation with library-function and MOFD approaches.\n","  The parameter groups must be chosen to match those of ODEFunc(), as defined in sinusoidal_curve.ipynb.\n","  \"\"\"\n","\n","  def __init__(self, a, b, c, d):\n","    super(Network, self).__init__()\n","    self.a = a\n","    self.b = b\n","    self.c = c\n","    self.d = d\n","\n","  def forward(self, t, y):\n","    x = F.linear(y, self.a, self.b)\n","    m = nn.Tanh()\n","    x = m(x)\n","    x = F.linear(x, self.c, self.d)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"owLk1ZZtIyAV","executionInfo":{"status":"ok","timestamp":1616150247170,"user_tz":0,"elapsed":547,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_loss(params_vector):\n","\n","  a = params_vector[:16].reshape([8, 2])\n","  b = params_vector[16:24].reshape([8])\n","  c = params_vector[24:40].reshape([2, 8])\n","  d = params_vector[40:42].reshape([2])\n","  \n","  neural_net = Network(a, b, c, d).to(device)\n","  pred_y = odeint(neural_net, true_y0, t, method= args.method)\n","  loss = torch.mean(torch.abs(pred_y - true_y))\n","  return loss\n","\n","def get_library_hessian(net):\n","  \"\"\"\n","  Obtains the Hessian of the NODE using the autograd.functional.hessian() function.\n","  Inputs: \n","        - net: the network for which the Hessian is to be calculated.\n","  NB: Each individual NODE architecture must be specified in the function get_loss(), such that\n","  the Hessian is calculated correctly.\n","  \"\"\"\n","\n","  param_tensors = net.parameters()\n","  params_vector = torch.tensor([]).to(device)\n","  for param in param_tensors:\n","    vec = torch.reshape(param, (-1,)).to(device)\n","    params_vector = torch.cat((params_vector, vec))\n","\n","  hessian = torch.autograd.functional.hessian(get_loss, params_vector)\n","  return hessian"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y77p15C1G7Sa","executionInfo":{"status":"ok","timestamp":1616150249353,"user_tz":0,"elapsed":459,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_manual_hessian(grads, parameters, show_iters=True):\n","  \"\"\"\n","  Calculation of the Hessian using nested for loops.\n","  Inputs:   - grads:        tuple of gradient tensors. Created using something \n","                            like grads = torch.autograd.grad(loss, parameters, create_graph=True).\n","            - parameters:   List of parameter objects. Created using something \n","                            like parameters = optimizer.param_groups[0]['params'].\n","            - show_iters:   True or False, depending on if the iteration number is to be shown during training. \n","                            Note that the iteration updates are not provided every row, but instead periodically \n","                            (roughly according to the number of parameters in the system).\n","  \"\"\"\n","  start = time.time()        \n","\n","  n_params = 0\n","  for param in parameters:\n","    n_params += torch.numel(param)\n","  grads2 = torch.zeros(n_params,n_params)            #Create an matrix of zeros thas has the same shape as the Hessian.\n","\n","  y_counter = 0                             #y_direction refers to row number in the Hessian.\n","\n","  for grad in grads:\n","      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \n","\n","      for j, g in enumerate(grad):\n","        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\n","\n","        for l, param in enumerate(parameters):\n","          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\n","          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\n","          len = g2.shape[0]                       \n","          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\n","          x_counter += len\n","\n","      grads2 = grads2.to(device)\n","      y_counter += grad.shape[0]\n","\n","      if show_iters:\n","        print(\"Gradients calculated for row number \" + str(y_counter) + \".\")\n","  \n","  print('Time used was ', time.time() - start)\n","\n","  return grads2"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCHdK1WeI1Lv","executionInfo":{"status":"ok","timestamp":1616150252946,"user_tz":0,"elapsed":743,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_mofd_hessian_element(p_vec, shapes, base_loss, i, k, h=1e-4):\n","  \"\"\"\n","  Calculates an individual element of the Hessian via the MOFD.\n","  Inputs: - p_vec:        the parameters of the network organized into a vector.\n","          - shapes:       a list of torch.Size() objects describing the shapes of each parameter group.\n","          - base_loss:    loss of the unperturbed system. Used in calculating diagonal Hessian elements.\n","          - h:            the size of the pertubation applied to each parameter.\n","          - i and k:      the indices of the element to be calculated.\n","          - show_iters:   True or False according to whether iteration number is to be displayed during calculation.\n","\n","  Returns: - 'grad2':     torch.tensor() object containing the Hessian element H[i,k] = H[k,i].\n","  \n","  NB: This function adapts to network architecture automatically.\n","  The code is designed to convert all floats to 64-bit automatically.\n","  \"\"\"\n","  #List of integers detailing the number of elements in each parameter group.\n","  nels = [int(torch.prod(torch.tensor(shape))) for shape in shapes]\n","  nels = torch.tensor(nels)\n","  nels = torch.cumsum(nels, dim=0)\n","  nels = nels.tolist()\n","\n","  #Empty tensors to store mofd info and perturbed parameters.\n","  up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_pert_p_vec = torch.zeros_like(p_vec).double()\n","\n","  up_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  up_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_up_pert_p_vec = torch.zeros_like(p_vec).double()\n","  low_low_pert_p_vec = torch.zeros_like(p_vec).double()\n","    \n","  #Versions of the parameter vector to be perturbed.\n","  for j in range(len(p_vec)):\n","    up_pert_p_vec[j] = p_vec[j]\n","    low_pert_p_vec[j] = p_vec[j]\n","    \n","  #Calculate the diagonal elements.\n","  if k == i:\n","    up_pert_p_vec[k] += h\n","    low_pert_p_vec[k] -= h\n","\n","    a_up = up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up = up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up = up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up = up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","\n","    a_low = low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low = low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low = low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low = low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","\n","    neural_net_up = Network(a_up, b_up, c_up, d_up).to(device)\n","    pred_y_up = odeint(neural_net_up, true_y0.double(), t.double(), method=args.method)\n","    pert_loss_up = torch.mean(torch.abs(pred_y_up - true_y.double())).double()\n","\n","    neural_net_low = Network(a_low, b_low, c_low, d_low).to(device)\n","    pred_y_low = odeint(neural_net_low, true_y0.double(), t.double(), method=args.method)\n","    pert_loss_low = torch.mean(torch.abs(pred_y_low - true_y.double())).double()\n","    \n","    grad2 = ((pert_loss_up - 2*base_loss + pert_loss_low)/(h**2)).double()\n","\n","  #Calculate the off-diagonal elements.\n","  if k > i:\n","    \n","    #Vectors to be perturbed (there are 4 of these).\n","    #They must be created individually for each k so that previous iterations do not affect the parameter values.\n","    for l in range(len(p_vec)):\n","      up_up_pert_p_vec[l] = p_vec[l]\n","      up_low_pert_p_vec[l] = p_vec[l]\n","      low_up_pert_p_vec[l] = p_vec[l]\n","      low_low_pert_p_vec[l] = p_vec[l]\n","\n","    up_up_pert_p_vec[i] += h\n","    up_up_pert_p_vec[k] += h\n","\n","    up_low_pert_p_vec[i] += h\n","    up_low_pert_p_vec[k] -= h\n","\n","    low_up_pert_p_vec[i] -= h\n","    low_up_pert_p_vec[k] += h\n","\n","    low_low_pert_p_vec[i] -= h\n","    low_low_pert_p_vec[k] -= h\n","\n","    a_up_up = up_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_up = up_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_up = up_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_up = up_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","\n","    a_up_low = up_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_up_low = up_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_up_low = up_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_up_low = up_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","\n","    a_low_up = low_up_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_up = low_up_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_up = low_up_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_up = low_up_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","\n","    a_low_low = low_low_pert_p_vec[:nels[0]].reshape(shapes[0])\n","    b_low_low = low_low_pert_p_vec[nels[0]:nels[1]].reshape(shapes[1])\n","    c_low_low = low_low_pert_p_vec[nels[1]:nels[2]].reshape(shapes[2])\n","    d_low_low = low_low_pert_p_vec[nels[2]:nels[3]].reshape(shapes[3])\n","\n","    neural_net_up_up = Network(a_up_up, b_up_up, c_up_up, d_up_up).to(device)\n","    pred_y_up_up = odeint(neural_net_up_up, true_y0.double(), t.double(), method=args.method)\n","    pert_loss_up_up = torch.mean(torch.abs(pred_y_up_up - true_y.double())).double()\n","\n","    neural_net_up_low = Network(a_up_low, b_up_low, c_up_low, d_up_low).to(device)\n","    pred_y_up_low = odeint(neural_net_up_low, true_y0.double(), t.double(), method=args.method)\n","    pert_loss_up_low = torch.mean(torch.abs(pred_y_up_low - true_y.double())).double()\n","\n","    neural_net_low_up = Network(a_low_up, b_low_up, c_low_up, d_low_up).to(device)\n","    pred_y_low_up = odeint(neural_net_low_up, true_y0.double(), t.double(), method=args.method)\n","    pert_loss_low_up = torch.mean(torch.abs(pred_y_low_up - true_y.double())).double()\n","\n","    neural_net_low_low = Network(a_low_low, b_low_low, c_low_low, d_low_low).to(device)\n","    pred_y_low_low = odeint(neural_net_low_low, true_y0.double(), t.double(), method=args.method)\n","    pert_loss_low_low = torch.mean(torch.abs(pred_y_low_low - true_y.double())).double()\n","    \n","    #MOFD formula to estimate second order gradient.\n","    grad2 = ((pert_loss_up_up - pert_loss_up_low - pert_loss_low_up + pert_loss_low_low)/(4*h**2)).double()\n","\n","  return grad2"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyGc6-DTUapU","executionInfo":{"status":"ok","timestamp":1616150258222,"user_tz":0,"elapsed":673,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------\n","The following code is used for Hessian analysis.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSkjzi3xr6WV","colab":{"base_uri":"https://localhost:8080/","height":412},"executionInfo":{"status":"error","timestamp":1616150485868,"user_tz":0,"elapsed":685,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"59ede4fe-60d7-4f83-ad2f-175683a1681f"},"source":["#Calculate the Hessian for all saved models during training.\n","#The models were saved with different test frequencies at different stages. The analysis below reflects this.\n","\n","library_hessian_data = [] \n","\n","#################################################################################\n","\n","itr = 1\n","\n","model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/calculating_hessians'\n","                  + '/testing_on_simple_nodes/sinusoidal_curve/mse_loss'\n","                  + '/8_dims/models/model_' + str(itr) + '.pt', \n","                   map_location=device)\n","\n","model = model.to(device)\n","\n","print('Obtaining library hessian for iteration ' + str(itr) + '...')\n","library_start = time.time()\n","library_hessian = get_library_hessian(model)                       #get hessian with library functions   \n","library_end = time.time()\n","print(\"Time taken was \" + str(round(library_end-library_start,2)) + \"s.\")\n","\n","library_hessian_data.append((itr, library_end-library_start, library_hessian))\n","\n","#################################################################################\n","\n","for itr in range(20, 1520, 20):\n","\n","  model = torch.load('/content/drive/MyDrive/colab_notebooks/NODE_Hessian/calculating_hessians'\n","                    + '/testing_on_simple_nodes/sinusoidal_curve/mse_loss'\n","                    + '/8_dims/models/model_' + str(itr) + '.pt', \n","                    map_location=device)\n","\n","  model = model.to(device)\n","\n","  print('Obtaining library hessian for iteration ' + str(itr) + '...')\n","  library_start = time.time()\n","  library_hessian = get_library_hessian(model)                       #get hessian with library functions   \n","  library_end = time.time()\n","  print(\"Time taken was \" + str(round(library_end-library_start,2)) + \"s.\")\n","\n","  library_hessian_data.append((itr, library_end-library_start, library_hessian))"],"execution_count":13,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-6e26e6a433e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;34m+\u001b[0m \u001b[0;34m'/testing_on_simple_nodes/sinusoidal_curve/mse_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   \u001b[0;34m+\u001b[0m \u001b[0;34m'/8_dims/models/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                    map_location=device)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/calculating_hessians/testing_on_simple_nodes/sinusoidal_curve/mse_loss/8_dims/models/model_1.pt'"]}]},{"cell_type":"code","metadata":{"id":"UeI_4sxptzLS"},"source":["for item in library_hessian_data:\n","  e, v = torch.symeig(item[2])\n","  plt.hist(e, bins = 150)\n","  plt.title('Iterations: ' + str(item[0]))\n","  plt.xlabel('Eigenvalue')\n","  plt.ylabel('Density')\n","  #plt.savefig('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes'\n","                  #+ '/sinusoidal_curve/more_developed_system/experiments/eigenvalue_density_plots/'\n","                  #+ 'eigenvalue_density_' + str(item[0]) + '.png')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFEO209FmJTB"},"source":["itr = 4100\n","\n","for item in library_hessian_data:\n","  if item[0] == itr:\n","    library_hessian = item[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1NzurBCvKWJ"},"source":["#Get manual Hessian for a given iteration.\n","\n","itr = 4100\n","\n","model = torch.load('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes'\n","                  + '/sinusoidal_curve/more_developed_system/experiments/models/model_'\n","                  + str(itr) + '.pt', map_location=device)\n","\n","optimizer = optim.RMSprop(model.parameters())\n","optimizer.zero_grad()\n","\n","pred_y = odeint(model, true_y0, t, method=args.method)\n","base_loss = torch.mean(torch.abs(pred_y-true_y))\n","grads = torch.autograd.grad(base_loss, model.parameters(), create_graph=True)\n","parameters = optimizer.param_groups[0]['params']\n","\n","print('Obtaining manual hessian...')\n","manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\n","\n","torch.save(manual_hessian, '/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/'\n","                        + 'sinusoidal_curve/more_developed_system/experiments/hessian_data/'\n","                        + str(itr) + '_manual_hessian.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47MhGyuPzy0P"},"source":["#Get MOFD Hessian for a given model.\n","\n","itr = 4100\n","\n","model = torch.load('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes'\n","                  + '/sinusoidal_curve/more_developed_system/experiments/models/model_'\n","                  + str(itr) + '.pt', map_location = device)\n","model = model.to(device)\n","\n","double_model = model.double()\n","optimizer = optim.RMSprop(model.parameters())\n","optimizer.zero_grad()\n","\n","#Prepare loss for MOFD.\n","pred_y = odeint(double_model, true_y0.double(), t.double(), method=args.method).double()\n","base_loss = torch.mean(torch.abs(pred_y-true_y.double()))\n","\n","#Prepare shape information for MOFD.\n","shapes = []\n","for param in model.parameters():\n","  shapes.append(param.shape)\n","\n","#Create vector of parameters.\n","param_tensors = double_model.parameters()\n","params_vec = torch.tensor([]).to(device)\n","for param in param_tensors:\n","  vec = torch.reshape(param, (-1,)).to(device)\n","  params_vec = torch.cat((params_vec, vec))\n","\n","w = len(params_vec)\n","print('Getting Hessian with h = 1e-7')\n","counter = w*(w+1)/2\n","mofd_hessian = torch.zeros((w,w)).double()\n","for i in range(len(params_vec)):\n","  for k in range(len(params_vec)):\n","\n","    #Only calculate for k >= i, in the same way as get_mofd_hessian_element().\n","    #Failing to do so yields UnboundLocalError since local variable, grad2, is referenced before assignment.\n","    if k >= i:                     \n","      element = get_mofd_hessian_element(params_vec, shapes, base_loss, i, k, h=1e-7)\n","      mofd_hessian[i,k] = element.item()    #.item() is required to prevent RAM growth.\n","      mofd_hessian[k,i] = element.item()\n","      counter -= 1\n","      print(\"\\rIterations remaining: \" + str(int(counter)) + ', Element: ' + str(element.item()), end = '')\n","print('')\n","\n","torch.save(mofd_hessian, '/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/'\n","                        + 'sinusoidal_curve/more_developed_system/experiments/hessian_data/'\n","                        + str(itr) + '_mofd_hessian_7.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-X2bwLf-SIS"},"source":["e_l, v_l = torch.symeig(library_hessian)\n","plt.hist(e_l.cpu().detach().numpy(), bins=150, color = 'Orange')\n","plt.title('Comparison of Hessian calculation approaches\\nIteration ' + str(itr) + ', Library Approach')\n","plt.xlabel('Eigenvalue')\n","plt.ylabel('Density')\n","plt.savefig('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/sinusoidal_curve'\n","            + '/more_developed_system/experiments/eigenvalue_density_plots_comparisons/' + str(itr)\n","            + '_lib_eigenvalue_density.png')\n","plt.show()\n","\n","e_ma, v_ma = torch.symeig(manual_hessian)\n","plt.hist(e_ma.cpu().detach().numpy(), bins=150, color = 'Green')\n","plt.title('Comparison of Hessian calculation approaches\\nIteration ' + str(itr) + ', Manual Approach')\n","plt.xlabel('Eigenvalue')\n","plt.ylabel('Density')\n","plt.savefig('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/sinusoidal_curve'\n","            + '/more_developed_system/experiments/eigenvalue_density_plots_comparisons/' + str(itr)\n","            + '_man_eigenvalue_density.png')\n","plt.show()\n","\n","h = 1e-7\n","e_mo, v_mo = torch.symeig(mofd_hessian)\n","plt.hist(e_mo.cpu().detach().numpy(), bins=150)\n","plt.title('Comparison of Hessian calculation approaches\\nIteration ' + str(itr) + ', MOFD, h = ' + str(h))\n","plt.xlabel('Eigenvalue')\n","plt.ylabel('Density')\n","plt.savefig('/content/drive/MyDrive/colab_notebooks/calculating_hessians/testing_on_simple_nodes/sinusoidal_curve'\n","            + '/more_developed_system/experiments/eigenvalue_density_plots_comparisons/' + str(itr)\n","            + '_mofd_7_eigenvalue_density.png')\n","plt.show()"],"execution_count":null,"outputs":[]}]}