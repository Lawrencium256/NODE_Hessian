{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"original_paper_node_with_both_hessians.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1rLLYAB1Mvk0XMaJC_WhOW7koaqHwPi14","authorship_tag":"ABX9TyPcVnjYIB45lldmuyTLcn16"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SQBS7KTR83Bw"},"source":["%%capture\n","\"\"\"\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","This file is used to compute the hessian during training for fitting a simple spiral ODE. \n","It contains functionality to do so by using either \"manual\" or library-based approaches.\n","-----------------------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqZsIwjwmG2p"},"source":["%%capture\n","%%bash \n","pip install torchdiffeq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iqOcAXt2wMy"},"source":["import os\n","import argparse\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4O95yfu3BLY"},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n","parser.add_argument('--data_size', type=int, default=1000)\n","parser.add_argument('--batch_time', type=int, default=10)\n","parser.add_argument('--batch_size', type=int, default=20)\n","parser.add_argument('--niters', type=int, default=100)\n","parser.add_argument('--test_freq', type=int, default=20)\n","parser.add_argument('--viz', action='store_true')\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--adjoint', action='store_true')\n","parser.add_argument('--manual_hessian', action='store_true')\n","parser.add_argument('--library_hessian', action='store_true')\n","parser.add_argument('--hessian_freq', type=int, default=20)\n","args = parser.parse_args(args=[])\n","\n","args.viz = True\n","args.niters = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2TQOgZL-ncp"},"source":["#The technique only works when the adjoint method is not used. If it is used, the Hessian returned is a matrix of zeros.\n","adjoint = False\n","\n","if adjoint == True:\n","    from torchdiffeq import odeint_adjoint as odeint\n","if adjoint == False:\n","    from torchdiffeq import odeint\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","\n","true_y0 = torch.tensor([[2., 0.]]).to(device)\n","t = torch.linspace(0., 25., args.data_size).to(device)\n","true_A = torch.tensor([[-0.1, 2.0], [-2.0, -0.1]]).to(device)\n","\n","class Lambda(nn.Module):\n","\n","    def forward(self, t, y):\n","        return torch.mm(y**3, true_A)\n","\n","#The true_y solution defines a spiral in the x-y plane.\n","with torch.no_grad():\n","    true_y = odeint(Lambda(), true_y0, t, method='dopri5')\n","\n","def get_batch():\n","\n","    s = torch.from_numpy(np.random.choice(np.arange(args.data_size - args.batch_time, dtype=np.int64), args.batch_size, replace=False)) \n","    \n","    batch_y0 = true_y[s]  # (M, D)\n","    batch_t = t[:args.batch_time]  # (T)\n","    batch_y = torch.stack([true_y[s + i] for i in range(args.batch_time)], dim=0)  # (T, M, D)\n","    return batch_y0.to(device), batch_t.to(device), batch_y.to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-3krz_a_bgU"},"source":["%%capture\n","def makedirs(dirname):\n","    if not os.path.exists(dirname):\n","        os.makedirs(dirname)\n","\n","if args.viz:\n","    makedirs('png')\n","    import matplotlib.pyplot as plt\n","    fig = plt.figure(figsize=(12, 4), facecolor='white') \n","    ax_traj = fig.add_subplot(131, frameon=False)        \n","    ax_phase = fig.add_subplot(132, frameon=False)\n","    ax_vecfield = fig.add_subplot(133, frameon=False)\n","    #plt.show(block=False)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CT3q5POMuWKs"},"source":["def visualize_3(true_y, pred_y, odefunc, itr):\n","\n","  \"\"\"\n","  This slightly altered version of the function visualize() seems to work fine. The only change is that I have moved the plt.figure() part of the code\n","  inside the function itself, i.e. I am creating a new figure environment for every figure, instead of editing the same environment multiple times.\n","  \"\"\"\n","\n","  if args.viz:\n","\n","    fig = plt.figure(figsize=(12, 4), facecolor='white')  #'facecolor is the background colour.\n","    ax_traj = fig.add_subplot(131, frameon=False)         #add axes to the figure as part of the subplot arrangement.\n","    ax_phase = fig.add_subplot(132, frameon=False)\n","    ax_vecfield = fig.add_subplot(133, frameon=False)\n","\n","    ax_traj.set_title('Trajectories')\n","    ax_traj.set_xlabel('t')\n","    ax_traj.set_ylabel('x,y')\n","    ax_traj.plot(t.cpu().numpy(), true_y.cpu().numpy()[:, 0, 0], t.cpu().numpy(), true_y.cpu().numpy()[:, 0, 1], 'g-')\n","    ax_traj.plot(t.cpu().numpy(), pred_y.cpu().numpy()[:, 0, 0], '--', t.cpu().numpy(), pred_y.cpu().numpy()[:, 0, 1], 'b--')\n","    ax_traj.set_xlim(t.cpu().min(), t.cpu().max())\n","    ax_traj.set_ylim(-2, 2)\n","\n","    ax_phase.set_title('Phase Portrait')\n","    ax_phase.set_xlabel('x')\n","    ax_phase.set_ylabel('y')\n","    ax_phase.plot(true_y.cpu().numpy()[:, 0, 0], true_y.cpu().numpy()[:, 0, 1], 'g-')\n","    ax_phase.plot(pred_y.cpu().numpy()[:, 0, 0], pred_y.cpu().numpy()[:, 0, 1], 'b--')\n","    ax_phase.set_xlim(-2, 2)\n","    ax_phase.set_ylim(-2, 2)\n","\n","    ax_vecfield.set_title('Learned Vector Field')\n","    ax_vecfield.set_xlabel('x')\n","    ax_vecfield.set_ylabel('y')\n","\n","    y, x = np.mgrid[-2:2:21j, -2:2:21j]\n","    dydt = odefunc(0, torch.Tensor(np.stack([x, y], -1).reshape(21 * 21, 2)).to(device)).cpu().detach().numpy()\n","    mag = np.sqrt(dydt[:, 0]**2 + dydt[:, 1]**2).reshape(-1, 1)\n","    dydt = (dydt / mag)\n","    dydt = dydt.reshape(21, 21, 2)\n","\n","    ax_vecfield.streamplot(x, y, dydt[:, :, 0], dydt[:, :, 1], color=\"black\")\n","    ax_vecfield.set_xlim(-2, 2)\n","    ax_vecfield.set_ylim(-2, 2)\n","\n","    fig.tight_layout()\n","    plt.savefig('png/{:03d}'.format(itr))\n","    plt.draw()\n","    plt.pause(0.001)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo8kpZybTYMh"},"source":["class ODEFunc(nn.Module):\n","\n","    def __init__(self):\n","        super(ODEFunc, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(2, 50),\n","            nn.Tanh(),\n","            nn.Linear(50, 2),\n","        )\n","\n","        for m in self.net.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, mean=0, std=0.1)\n","                nn.init.constant_(m.bias, val=0)\n","\n","    def forward(self, t, y):\n","        return self.net(y**3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXOq7FquTYbd"},"source":["class RunningAverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self, momentum=0.99):\n","        self.momentum = momentum\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = None\n","        self.avg = 0\n","\n","    def update(self, val):\n","        if self.val is None:\n","            self.avg = val\n","        else:\n","            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n","        self.val = val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y77p15C1G7Sa"},"source":["def get_manual_hessian(grads, parameters):\n","  \"\"\"\n","  Calculation of the Hessian using nested for loops.\n","  Inputs: \n","    grads:      tuple of gradient tensors. Created using something like grads = torch.autograd.grad(loss, parameters, create_graph=True).\n","    parameters: list of parameter objects. Created using something like parameters = optimizer.param_groups[0]['params'].\n","  \"\"\"\n","  start = time.time()                       #Begin timer.\n","\n","  n_params = 0\n","  for param in parameters:\n","    n_params += torch.numel(param)\n","  grads2 = torch.zeros(n_params,n_params)             #Create an matrix of zeros thas has the same shape as the Hessian.\n","\n","  y_counter = 0                             #y_direction refers to row number in the Hessian.\n","\n","  for grad in grads:\n","      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \n","\n","      for j, g in enumerate(grad):\n","        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\n","\n","        for l, param in enumerate(parameters):\n","          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\n","          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\n","          len = g2.shape[0]                       \n","          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\n","          x_counter += len\n","\n","      grads2 = grads2.to(device)\n","      y_counter += grad.shape[0]\n","      print(\"Gradients calculated for row number \" + str(y_counter) + \".\")\n","  \n","  print('Time used was ', time.time() - start)\n","\n","  return grads2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fn4lPrpagmOx"},"source":["class Network(nn.Module):\n","\n","  def __init__(self, a, b, c, d):\n","    super(Network, self).__init__()\n","    self.a = a\n","    self.b = b\n","    self.c = c\n","    self.d = d\n","\n","  def forward(self, t, y):\n","    x = F.linear(y**3, self.a, self.b)\n","    m = nn.Tanh()\n","    x = m(x)\n","    x = F.linear(x, self.c, self.d)\n","    return x\n","\n","\n","def get_loss_square(params_vector):\n","\n","  a = params_vector[:100].reshape([50, 2])\n","  b = params_vector[100:150].reshape([50])\n","  c = params_vector[150:250].reshape([2, 50])\n","  d = params_vector[250:252].reshape([2])\n","  \n","  neural_net = Network(a, b, c, d).to(device)\n","  pred_y = odeint(neural_net, batch_y0, batch_t)\n","  \n","  loss = torch.mean(torch.abs(pred_y - batch_y))\n","  return loss\n","\n","def get_library_hessian(net):\n","\n","  param_tensors = net.parameters()\n","  params_vector = torch.tensor([]).to(device)\n","  for param in param_tensors:\n","    vec = torch.reshape(param, (-1,)).to(device)\n","    params_vector = torch.cat((params_vector, vec))\n","\n","  hessian = torch.autograd.functional.hessian(get_loss_square, params_vector)\n","  return hessian"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GP337SbeTYl6"},"source":["if __name__ == '__main__':\n","    \"\"\"\n","    Executes the programme. This includes doing the following:\n","\n","      - Trains the network;\n","      - Outputs the results in a series of png files (if desired);\n","      - Outputs hessian matrix information in list form.\n","    \"\"\"\n","\n","    ii = 0\n","\n","    func = ODEFunc().to(device)\n","    \n","    optimizer = optim.RMSprop(func.parameters(), lr=1e-3) #func.parameters are the parameters to optimise.\n","    end = time.time()\n","\n","    time_meter = RunningAverageMeter(0.97)\n","    \n","    loss_meter = RunningAverageMeter(0.97)\n","\n","    #Lists in which to store hessian data.\n","    #These will be lists of tuples like (iteration number, time, loss, hessian data).\n","    manual_hessian_data = []\n","    library_hessian_data = []\n","    loss_data = []\n","\n","    for itr in range(1, args.niters + 1):\n","        optimizer.zero_grad()                                 \n","        batch_y0, batch_t, batch_y = get_batch()             \n","        pred_y = odeint(func, batch_y0, batch_t).to(device)   \n","        loss = torch.mean(torch.abs(pred_y - batch_y))        \n","        loss.backward(create_graph=True)                                                                     \n","\n","        time_meter.update(time.time() - end)\n","        loss_meter.update(loss.item())\n","\n","        if itr % args.hessian_freq == 0 or itr==1:\n","          if args.library_hessian:\n","            print('Obtaining library hessian...')\n","            library_start = time.time()\n","            library_hessian = get_library_hessian(func)                       #get hessian with library functions   \n","            library_end = time.time()\n","            print(\"Time taken for library-based approach was \" + str(round(library_end-library_start,2)) + \"s.\")\n","            library_hessian_data.append((itr, library_end-library_start, loss.item(), library_hessian))\n","\n","          if args.manual_hessian:\n","            print('Obtaining manual hessian...')\n","            manual_start = time.time()\n","            parameters = optimizer.param_groups[0]['params']\n","            grads = [0,0,0,0] \n","            for counter, param in enumerate(func.parameters()):\n","              grads[counter] = param.grad\n","            grads = tuple(grads)\n","          \n","            manual_hessian = get_manual_hessian(grads, parameters)           #get hessian with manual approach.\n","            manual_end = time.time()\n","            print(\"Time taken for manual approach was \" + str(round(manual_end-manual_start,2)) + \"s.\")\n","            manual_hessian_data.append((itr, manual_end-manual_start, loss.item(), manual_hessian))\n","\n","        if itr % args.test_freq == 0:        \n","          with torch.no_grad():\n","              pred_y = odeint(func, true_y0, t)\n","              loss = torch.mean(torch.abs(pred_y - true_y))\n","              loss_data.append((itr, loss.item()))\n","              print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n","              visualize_3(true_y, pred_y, func, ii)\n","              ii += 1\n","\n","        optimizer.step()\n","        print(str(itr))\n","\n","        end = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9NnTpUziWVa"},"source":["library_hessian_data = library_hessian_data\n","\n","time_data = []\n","itrs = []\n","losses = []\n","for data in library_hessian_data:\n","  itrs.append(data[0])\n","  time_data.append(data[1])\n","\n","loss_data = loss_data\n","for item in loss_data:\n","  losses.append(item[1])\n","\n","\n","plt.plot(itrs[1:], losses, color=[1.0, 0.5, 0.3])\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XoV123eXtXaz"},"source":["func = ODEFunc().to(device)\n","\n","batch_y0, batch_t, batch_y = get_batch()             \n","pred_y = odeint(func, batch_y0, batch_t).to(device)"],"execution_count":null,"outputs":[]}]}