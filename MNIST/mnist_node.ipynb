{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist_node.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1sLUaZ_DEMKH30zwclvQKQ2FNZUI_mF3K","authorship_tag":"ABX9TyPcyCLDteDUeOs03JfQdmb8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"sWmsXi5BIAtb","executionInfo":{"status":"ok","timestamp":1617965636705,"user_tz":-60,"elapsed":3803,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%capture\n","%%bash\n","pip install torchdiffeq"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"H353RG8fIDd3","executionInfo":{"status":"ok","timestamp":1617965639560,"user_tz":-60,"elapsed":6489,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["import os\n","import argparse\n","import logging\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')\n","parser.add_argument('--tol', type=float, default=1e-3)\n","parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])\n","parser.add_argument('--downsampling-method', type=str, default='conv', choices=['conv', 'res'])\n","parser.add_argument('--nepochs', type=int, default=120)\n","parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])\n","parser.add_argument('--lr', type=float, default=0.1)\n","parser.add_argument('--batch_size', type=int, default=128)\n","parser.add_argument('--test_batch_size', type=int, default=1000)\n","\n","parser.add_argument('--save', type=str, default='./experiment_node1')\n","parser.add_argument('--gpu', type=int, default=0)\n","parser.add_argument('--debug', action='store_true')\n","args = parser.parse_args(args=[])\n","\n","args.save = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/experiment_node1'\n","\n","if args.adjoint:\n","    from torchdiffeq import odeint_adjoint as odeint\n","else:\n","    from torchdiffeq import odeint"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"agpZtaKwIKnA","executionInfo":{"status":"ok","timestamp":1617965639567,"user_tz":-60,"elapsed":6348,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","def norm(dim):\n","    return nn.GroupNorm(min(32, dim), dim)\n","\n","\n","class ResBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(ResBlock, self).__init__()\n","        self.norm1 = norm(inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.norm2 = norm(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","    def forward(self, x):\n","        shortcut = x\n","\n","        out = self.relu(self.norm1(x))\n","\n","        if self.downsample is not None:\n","            shortcut = self.downsample(out)\n","\n","        out = self.conv1(out)\n","        out = self.norm2(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","\n","        return out + shortcut\n","\n","\n","class ConcatConv2d(nn.Module):\n","\n","    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):\n","        super(ConcatConv2d, self).__init__()\n","        module = nn.ConvTranspose2d if transpose else nn.Conv2d\n","        self._layer = module(\n","            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n","            bias=bias\n","        )\n","\n","    def forward(self, t, x):\n","        tt = torch.ones_like(x[:, :1, :, :]) * t\n","        ttx = torch.cat([tt, x], 1)\n","        return self._layer(ttx)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-rlM_3sI-1k","executionInfo":{"status":"ok","timestamp":1617965639568,"user_tz":-60,"elapsed":6172,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class ODEfunc(nn.Module):\n","\n","    def __init__(self, dim):\n","        super(ODEfunc, self).__init__()\n","        self.norm1 = norm(dim)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n","        self.norm2 = norm(dim)\n","        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n","        self.norm3 = norm(dim)\n","        self.nfe = 0\n","\n","    def forward(self, t, x):\n","        self.nfe += 1\n","        out = self.norm1(x)\n","        out = self.relu(out)\n","        out = self.conv1(t, out)\n","        out = self.norm2(out)\n","        out = self.relu(out)\n","        out = self.conv2(t, out)\n","        out = self.norm3(out)\n","        return out\n","\n","\n","class ODEBlock(nn.Module):\n","\n","    def __init__(self, odefunc):\n","        super(ODEBlock, self).__init__()\n","        self.odefunc = odefunc\n","        self.integration_time = torch.tensor([0, 1]).float()\n","\n","    def forward(self, x):\n","        self.integration_time = self.integration_time.type_as(x)\n","        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)\n","        return out[1]\n","\n","    @property\n","    def nfe(self):\n","        return self.odefunc.nfe\n","\n","    @nfe.setter\n","    def nfe(self, value):\n","        self.odefunc.nfe = value"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhFiCzNaJC0x","executionInfo":{"status":"ok","timestamp":1617965639570,"user_tz":-60,"elapsed":6060,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["class Flatten(nn.Module):\n","\n","    def __init__(self):\n","        super(Flatten, self).__init__()\n","\n","    def forward(self, x):\n","        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n","        return x.view(-1, shape)\n","\n","\n","class RunningAverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self, momentum=0.99):\n","        self.momentum = momentum\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = None\n","        self.avg = 0\n","\n","    def update(self, val):\n","        if self.val is None:\n","            self.avg = val\n","        else:\n","            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n","        self.val = val"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltcgl1RIJG7U","executionInfo":{"status":"ok","timestamp":1617965640246,"user_tz":-60,"elapsed":6577,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_mnist_loaders(data_aug=False, batch_size=128, test_batch_size=1000, perc=1.0):\n","    if data_aug:\n","        transform_train = transforms.Compose([\n","            transforms.RandomCrop(28, padding=4),\n","            transforms.ToTensor(),\n","        ])\n","    else:\n","        transform_train = transforms.Compose([\n","            transforms.ToTensor(),\n","        ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","    ])\n","\n","    train_loader = DataLoader(\n","        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_train), batch_size=batch_size,\n","        shuffle=True, num_workers=2, drop_last=True\n","    )\n","\n","    train_eval_loader = DataLoader(\n","        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_test),\n","        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\n","    )\n","\n","    test_loader = DataLoader(\n","        datasets.MNIST(root='.data/mnist', train=False, download=True, transform=transform_test),\n","        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\n","    )\n","\n","    return train_loader, test_loader, train_eval_loader\n","\n","\n","def inf_generator(iterable):\n","    \"\"\"Allows training with DataLoaders in a single infinite loop:\n","        for i, (x, y) in enumerate(inf_generator(train_loader)):\n","    \"\"\"\n","    iterator = iterable.__iter__()\n","    while True:\n","        try:\n","            yield iterator.__next__()\n","        except StopIteration:\n","            iterator = iterable.__iter__()\n","\n","\n","def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n","    initial_learning_rate = args.lr * batch_size / batch_denom\n","\n","    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n","    vals = [initial_learning_rate * decay for decay in decay_rates]\n","\n","    def learning_rate_fn(itr):\n","        lt = [itr < b for b in boundaries] + [True]\n","        i = np.argmax(lt)\n","        return vals[i]\n","\n","    return learning_rate_fn\n","\n","\n","def one_hot(x, K):\n","    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n","\n","\n","def accuracy(model, dataset_loader):\n","    total_correct = 0\n","    for x, y in dataset_loader:\n","        x = x.to(device)\n","        y = one_hot(np.array(y.numpy()), 10)\n","\n","        target_class = np.argmax(y, axis=1)\n","        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n","        total_correct += np.sum(predicted_class == target_class)\n","    return total_correct / len(dataset_loader.dataset)\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def makedirs(dirname):\n","    if not os.path.exists(dirname):\n","        os.makedirs(dirname)\n","\n","\n","def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):\n","    logger = logging.getLogger()\n","    if debug:\n","        level = logging.DEBUG\n","    else:\n","        level = logging.INFO\n","    logger.setLevel(level)\n","    if saving:\n","        info_file_handler = logging.FileHandler(logpath, mode=\"a\")\n","        info_file_handler.setLevel(level)\n","        logger.addHandler(info_file_handler)\n","    if displaying:\n","        console_handler = logging.StreamHandler()\n","        console_handler.setLevel(level)\n","        logger.addHandler(console_handler)\n","    logger.info(filepath)\n","    with open(filepath, \"r\") as f:\n","        logger.info(f.read())\n","\n","    for f in package_files:\n","        logger.info(f)\n","        with open(f, \"r\") as package_f:\n","            logger.info(package_f.read())\n","\n","    return logger\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":939},"id":"42RIwJ37JKQr","executionInfo":{"status":"error","timestamp":1617965648740,"user_tz":-60,"elapsed":14934,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}},"outputId":"1aaf2bb1-ee38-4c9c-bf3f-c2cd78a30ce2"},"source":["if __name__ == '__main__':\n","    __file__ = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb'\n","    makedirs(args.save)\n","    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\n","    logger.info(args)\n","\n","    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","\n","    is_odenet = args.network == 'odenet'\n","\n","    if args.downsampling_method == 'conv':\n","        downsampling_layers = [\n","            nn.Conv2d(1, 64, 3, 1),\n","            norm(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, 4, 2, 1),\n","            norm(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, 4, 2, 1),\n","        ]\n","    elif args.downsampling_method == 'res':\n","        downsampling_layers = [\n","            nn.Conv2d(1, 64, 3, 1),\n","            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n","            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n","        ]\n","\n","    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\n","    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n","\n","    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n","\n","    logger.info(model)\n","    logger.info('Number of parameters: {}'.format(count_parameters(model)))\n","\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    train_loader, test_loader, train_eval_loader = get_mnist_loaders(\n","        args.data_aug, args.batch_size, args.test_batch_size\n","    )\n","\n","    data_gen = inf_generator(train_loader)\n","    batches_per_epoch = len(train_loader)\n","\n","    lr_fn = learning_rate_with_decay(\n","        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n","        decay_rates=[1, 0.1, 0.01, 0.001]\n","    )\n","\n","    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n","\n","    best_acc = 0\n","    batch_time_meter = RunningAverageMeter()\n","    f_nfe_meter = RunningAverageMeter()\n","    b_nfe_meter = RunningAverageMeter()\n","    end = time.time()\n","    \n","    epoch_arr = []\n","    time_val_arr = []\n","    time_avg_arr = []\n","    nfe_f_arr = []\n","    nfe_b_arr = []\n","    train_acc_arr = []\n","    test_acc_arr = []\n","\n","    for itr in range(args.nepochs * batches_per_epoch):\n","\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr_fn(itr)\n","\n","        optimizer.zero_grad()\n","        x, y = data_gen.__next__()\n","        x = x.to(device)\n","        y = y.to(device)\n","        logits = model(x)\n","        loss = criterion(logits, y)\n","\n","        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n","        parameters = optimizer.param_groups[0]['params']\n","\n","        print('Obtaining manual hessian...')\n","        manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\n","\n","        if is_odenet:\n","            nfe_forward = feature_layers[0].nfe\n","            feature_layers[0].nfe = 0\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if is_odenet:\n","            nfe_backward = feature_layers[0].nfe\n","            feature_layers[0].nfe = 0\n","\n","        batch_time_meter.update(time.time() - end)\n","        if is_odenet:\n","            f_nfe_meter.update(nfe_forward)\n","            b_nfe_meter.update(nfe_backward)\n","        end = time.time()\n","\n","        if itr % batches_per_epoch == 0:\n","            with torch.no_grad():\n","                train_acc = accuracy(model, train_eval_loader)\n","                val_acc = accuracy(model, test_loader)\n","                if val_acc > best_acc:\n","                    torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n","                    best_acc = val_acc\n","                logger.info(\n","                    \"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | \"\n","                    \"Train Acc {:.4f} | Test Acc {:.4f}\".format(\n","                        itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,\n","                        b_nfe_meter.avg, train_acc, val_acc\n","                    )\n","                )\n","                epoch_arr += [itr // batches_per_epoch]\n","                time_val_arr += [batch_time_meter.val]\n","                time_avg_arr += [batch_time_meter.avg]\n","                nfe_f_arr += [f_nfe_meter.avg]\n","                nfe_b_arr += [b_nfe_meter.avg]\n","                train_acc_arr += [train_acc]\n","                test_acc_arr += [val_acc]\n","                    \n","    epoch_arr = np.asarray(epoch_arr)\n","    time_val_arr = np.asarray(time_val_arr)\n","    time_avg_arr = np.asarray(time_avg_arr)\n","    nfe_f_arr = np.asarray(nfe_f_arr)\n","    nfe_b_arr = np.asarray(nfe_b_arr)\n","    train_acc_arr = np.asarray(train_acc_arr)\n","    test_acc_arr = np.asarray(test_acc_arr)\n","    \n","    np.save(os.path.join(args.save, 'epoch_arr.npy'), epoch_arr)\n","    np.save(os.path.join(args.save, 'time_val_arr.npy'), time_val_arr)\n","    np.save(os.path.join(args.save, 'time_avg_arr.npy'), time_avg_arr)\n","    np.save(os.path.join(args.save, 'nfe_f_arr.npy'), nfe_f_arr)\n","    np.save(os.path.join(args.save, 'nfe_b_arr.npy'), nfe_b_arr)\n","    np.save(os.path.join(args.save, 'train_acc_arr.npy'), train_acc_arr)\n","    np.save(os.path.join(args.save, 'test_acc_arr.npy'), test_acc_arr)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\n","{\"nbformat\":4,\"nbformat_minor\":0,\"metadata\":{\"colab\":{\"name\":\"mnist_node.ipynb\",\"provenance\":[],\"collapsed_sections\":[],\"mount_file_id\":\"1sLUaZ_DEMKH30zwclvQKQ2FNZUI_mF3K\",\"authorship_tag\":\"ABX9TyPcyCLDteDUeOs03JfQdmb8\"},\"kernelspec\":{\"name\":\"python3\",\"display_name\":\"Python 3\"},\"language_info\":{\"name\":\"python\"}},\"cells\":[{\"cell_type\":\"code\",\"metadata\":{\"id\":\"sWmsXi5BIAtb\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965469256,\"user_tz\":-60,\"elapsed\":3337,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"%%capture\\n\",\"%%bash\\n\",\"pip install torchdiffeq\"],\"execution_count\":2,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"H353RG8fIDd3\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965472807,\"user_tz\":-60,\"elapsed\":6734,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"import os\\n\",\"import argparse\\n\",\"import logging\\n\",\"import time\\n\",\"import numpy as np\\n\",\"import torch\\n\",\"import torch.nn as nn\\n\",\"from torch.utils.data import DataLoader\\n\",\"import torchvision.datasets as datasets\\n\",\"import torchvision.transforms as transforms\\n\",\"\\n\",\"\\n\",\"parser = argparse.ArgumentParser()\\n\",\"parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')\\n\",\"parser.add_argument('--tol', type=float, default=1e-3)\\n\",\"parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])\\n\",\"parser.add_argument('--downsampling-method', type=str, default='conv', choices=['conv', 'res'])\\n\",\"parser.add_argument('--nepochs', type=int, default=120)\\n\",\"parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])\\n\",\"parser.add_argument('--lr', type=float, default=0.1)\\n\",\"parser.add_argument('--batch_size', type=int, default=128)\\n\",\"parser.add_argument('--test_batch_size', type=int, default=1000)\\n\",\"\\n\",\"parser.add_argument('--save', type=str, default='./experiment_node1')\\n\",\"parser.add_argument('--gpu', type=int, default=0)\\n\",\"parser.add_argument('--debug', action='store_true')\\n\",\"args = parser.parse_args(args=[])\\n\",\"\\n\",\"args.save = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/experiment_node1'\\n\",\"\\n\",\"if args.adjoint:\\n\",\"    from torchdiffeq import odeint_adjoint as odeint\\n\",\"else:\\n\",\"    from torchdiffeq import odeint\"],\"execution_count\":3,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"agpZtaKwIKnA\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965472811,\"user_tz\":-60,\"elapsed\":6577,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"def conv3x3(in_planes, out_planes, stride=1):\\n\",\"    \\\"\\\"\\\"3x3 convolution with padding\\\"\\\"\\\"\\n\",\"    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\\n\",\"\\n\",\"\\n\",\"def conv1x1(in_planes, out_planes, stride=1):\\n\",\"    \\\"\\\"\\\"1x1 convolution\\\"\\\"\\\"\\n\",\"    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\\n\",\"\\n\",\"\\n\",\"def norm(dim):\\n\",\"    return nn.GroupNorm(min(32, dim), dim)\\n\",\"\\n\",\"\\n\",\"class ResBlock(nn.Module):\\n\",\"    expansion = 1\\n\",\"\\n\",\"    def __init__(self, inplanes, planes, stride=1, downsample=None):\\n\",\"        super(ResBlock, self).__init__()\\n\",\"        self.norm1 = norm(inplanes)\\n\",\"        self.relu = nn.ReLU(inplace=True)\\n\",\"        self.downsample = downsample\\n\",\"        self.conv1 = conv3x3(inplanes, planes, stride)\\n\",\"        self.norm2 = norm(planes)\\n\",\"        self.conv2 = conv3x3(planes, planes)\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        shortcut = x\\n\",\"\\n\",\"        out = self.relu(self.norm1(x))\\n\",\"\\n\",\"        if self.downsample is not None:\\n\",\"            shortcut = self.downsample(out)\\n\",\"\\n\",\"        out = self.conv1(out)\\n\",\"        out = self.norm2(out)\\n\",\"        out = self.relu(out)\\n\",\"        out = self.conv2(out)\\n\",\"\\n\",\"        return out + shortcut\\n\",\"\\n\",\"\\n\",\"class ConcatConv2d(nn.Module):\\n\",\"\\n\",\"    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):\\n\",\"        super(ConcatConv2d, self).__init__()\\n\",\"        module = nn.ConvTranspose2d if transpose else nn.Conv2d\\n\",\"        self._layer = module(\\n\",\"            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\\n\",\"            bias=bias\\n\",\"        )\\n\",\"\\n\",\"    def forward(self, t, x):\\n\",\"        tt = torch.ones_like(x[:, :1, :, :]) * t\\n\",\"        ttx = torch.cat([tt, x], 1)\\n\",\"        return self._layer(ttx)\"],\"execution_count\":4,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"1-rlM_3sI-1k\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965472812,\"user_tz\":-60,\"elapsed\":6439,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"class ODEfunc(nn.Module):\\n\",\"\\n\",\"    def __init__(self, dim):\\n\",\"        super(ODEfunc, self).__init__()\\n\",\"        self.norm1 = norm(dim)\\n\",\"        self.relu = nn.ReLU(inplace=True)\\n\",\"        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\\n\",\"        self.norm2 = norm(dim)\\n\",\"        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\\n\",\"        self.norm3 = norm(dim)\\n\",\"        self.nfe = 0\\n\",\"\\n\",\"    def forward(self, t, x):\\n\",\"        self.nfe += 1\\n\",\"        out = self.norm1(x)\\n\",\"        out = self.relu(out)\\n\",\"        out = self.conv1(t, out)\\n\",\"        out = self.norm2(out)\\n\",\"        out = self.relu(out)\\n\",\"        out = self.conv2(t, out)\\n\",\"        out = self.norm3(out)\\n\",\"        return out\\n\",\"\\n\",\"\\n\",\"class ODEBlock(nn.Module):\\n\",\"\\n\",\"    def __init__(self, odefunc):\\n\",\"        super(ODEBlock, self).__init__()\\n\",\"        self.odefunc = odefunc\\n\",\"        self.integration_time = torch.tensor([0, 1]).float()\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        self.integration_time = self.integration_time.type_as(x)\\n\",\"        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)\\n\",\"        return out[1]\\n\",\"\\n\",\"    @property\\n\",\"    def nfe(self):\\n\",\"        return self.odefunc.nfe\\n\",\"\\n\",\"    @nfe.setter\\n\",\"    def nfe(self, value):\\n\",\"        self.odefunc.nfe = value\"],\"execution_count\":5,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"xhFiCzNaJC0x\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965472813,\"user_tz\":-60,\"elapsed\":6236,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"class Flatten(nn.Module):\\n\",\"\\n\",\"    def __init__(self):\\n\",\"        super(Flatten, self).__init__()\\n\",\"\\n\",\"    def forward(self, x):\\n\",\"        shape = torch.prod(torch.tensor(x.shape[1:])).item()\\n\",\"        return x.view(-1, shape)\\n\",\"\\n\",\"\\n\",\"class RunningAverageMeter(object):\\n\",\"    \\\"\\\"\\\"Computes and stores the average and current value\\\"\\\"\\\"\\n\",\"\\n\",\"    def __init__(self, momentum=0.99):\\n\",\"        self.momentum = momentum\\n\",\"        self.reset()\\n\",\"\\n\",\"    def reset(self):\\n\",\"        self.val = None\\n\",\"        self.avg = 0\\n\",\"\\n\",\"    def update(self, val):\\n\",\"        if self.val is None:\\n\",\"            self.avg = val\\n\",\"        else:\\n\",\"            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\\n\",\"        self.val = val\"],\"execution_count\":6,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"ltcgl1RIJG7U\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965473748,\"user_tz\":-60,\"elapsed\":922,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"def get_mnist_loaders(data_aug=False, batch_size=128, test_batch_size=1000, perc=1.0):\\n\",\"    if data_aug:\\n\",\"        transform_train = transforms.Compose([\\n\",\"            transforms.RandomCrop(28, padding=4),\\n\",\"            transforms.ToTensor(),\\n\",\"        ])\\n\",\"    else:\\n\",\"        transform_train = transforms.Compose([\\n\",\"            transforms.ToTensor(),\\n\",\"        ])\\n\",\"\\n\",\"    transform_test = transforms.Compose([\\n\",\"        transforms.ToTensor(),\\n\",\"    ])\\n\",\"\\n\",\"    train_loader = DataLoader(\\n\",\"        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_train), batch_size=batch_size,\\n\",\"        shuffle=True, num_workers=2, drop_last=True\\n\",\"    )\\n\",\"\\n\",\"    train_eval_loader = DataLoader(\\n\",\"        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_test),\\n\",\"        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\\n\",\"    )\\n\",\"\\n\",\"    test_loader = DataLoader(\\n\",\"        datasets.MNIST(root='.data/mnist', train=False, download=True, transform=transform_test),\\n\",\"        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\\n\",\"    )\\n\",\"\\n\",\"    return train_loader, test_loader, train_eval_loader\\n\",\"\\n\",\"\\n\",\"def inf_generator(iterable):\\n\",\"    \\\"\\\"\\\"Allows training with DataLoaders in a single infinite loop:\\n\",\"        for i, (x, y) in enumerate(inf_generator(train_loader)):\\n\",\"    \\\"\\\"\\\"\\n\",\"    iterator = iterable.__iter__()\\n\",\"    while True:\\n\",\"        try:\\n\",\"            yield iterator.__next__()\\n\",\"        except StopIteration:\\n\",\"            iterator = iterable.__iter__()\\n\",\"\\n\",\"\\n\",\"def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\\n\",\"    initial_learning_rate = args.lr * batch_size / batch_denom\\n\",\"\\n\",\"    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\\n\",\"    vals = [initial_learning_rate * decay for decay in decay_rates]\\n\",\"\\n\",\"    def learning_rate_fn(itr):\\n\",\"        lt = [itr < b for b in boundaries] + [True]\\n\",\"        i = np.argmax(lt)\\n\",\"        return vals[i]\\n\",\"\\n\",\"    return learning_rate_fn\\n\",\"\\n\",\"\\n\",\"def one_hot(x, K):\\n\",\"    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\\n\",\"\\n\",\"\\n\",\"def accuracy(model, dataset_loader):\\n\",\"    total_correct = 0\\n\",\"    for x, y in dataset_loader:\\n\",\"        x = x.to(device)\\n\",\"        y = one_hot(np.array(y.numpy()), 10)\\n\",\"\\n\",\"        target_class = np.argmax(y, axis=1)\\n\",\"        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)\\n\",\"        total_correct += np.sum(predicted_class == target_class)\\n\",\"    return total_correct / len(dataset_loader.dataset)\\n\",\"\\n\",\"\\n\",\"def count_parameters(model):\\n\",\"    return sum(p.numel() for p in model.parameters() if p.requires_grad)\\n\",\"\\n\",\"\\n\",\"def makedirs(dirname):\\n\",\"    if not os.path.exists(dirname):\\n\",\"        os.makedirs(dirname)\\n\",\"\\n\",\"\\n\",\"def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):\\n\",\"    logger = logging.getLogger()\\n\",\"    if debug:\\n\",\"        level = logging.DEBUG\\n\",\"    else:\\n\",\"        level = logging.INFO\\n\",\"    logger.setLevel(level)\\n\",\"    if saving:\\n\",\"        info_file_handler = logging.FileHandler(logpath, mode=\\\"a\\\")\\n\",\"        info_file_handler.setLevel(level)\\n\",\"        logger.addHandler(info_file_handler)\\n\",\"    if displaying:\\n\",\"        console_handler = logging.StreamHandler()\\n\",\"        console_handler.setLevel(level)\\n\",\"        logger.addHandler(console_handler)\\n\",\"    logger.info(filepath)\\n\",\"    with open(filepath, \\\"r\\\") as f:\\n\",\"        logger.info(f.read())\\n\",\"\\n\",\"    for f in package_files:\\n\",\"        logger.info(f)\\n\",\"        with open(f, \\\"r\\\") as package_f:\\n\",\"            logger.info(package_f.read())\\n\",\"\\n\",\"    return logger\\n\"],\"execution_count\":7,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":232},\"id\":\"42RIwJ37JKQr\",\"executionInfo\":{\"status\":\"error\",\"timestamp\":1617965618625,\"user_tz\":-60,\"elapsed\":746,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}},\"outputId\":\"b88040a4-5d98-4598-9959-01f561aa3c13\"},\"source\":[\"if __name__ == '__main__':\\n\",\"    __file__ = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb'\\n\",\"    makedirs(args.save)\\n\",\"    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\\n\",\"    logger.info(args)\\n\",\"\\n\",\"    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\\n\",\"\\n\",\"    is_odenet = args.network == 'odenet'\\n\",\"\\n\",\"    if args.downsampling_method == 'conv':\\n\",\"        downsampling_layers = [\\n\",\"            nn.Conv2d(1, 64, 3, 1),\\n\",\"            norm(64),\\n\",\"            nn.ReLU(inplace=True),\\n\",\"            nn.Conv2d(64, 64, 4, 2, 1),\\n\",\"            norm(64),\\n\",\"            nn.ReLU(inplace=True),\\n\",\"            nn.Conv2d(64, 64, 4, 2, 1),\\n\",\"        ]\\n\",\"    elif args.downsampling_method == 'res':\\n\",\"        downsampling_layers = [\\n\",\"            nn.Conv2d(1, 64, 3, 1),\\n\",\"            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\\n\",\"            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\\n\",\"        ]\\n\",\"\\n\",\"    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\\n\",\"    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\\n\",\"\\n\",\"    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\\n\",\"\\n\",\"    logger.info(model)\\n\",\"    logger.info('Number of parameters: {}'.format(count_parameters(model)))\\n\",\"\\n\",\"    criterion = nn.CrossEntropyLoss().to(device)\\n\",\"\\n\",\"    train_loader, test_loader, train_eval_loader = get_mnist_loaders(\\n\",\"        args.data_aug, args.batch_size, args.test_batch_size\\n\",\"    )\\n\",\"\\n\",\"    data_gen = inf_generator(train_loader)\\n\",\"    batches_per_epoch = len(train_loader)\\n\",\"\\n\",\"    lr_fn = learning_rate_with_decay(\\n\",\"        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\\n\",\"        decay_rates=[1, 0.1, 0.01, 0.001]\\n\",\"    )\\n\",\"\\n\",\"    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\\n\",\"\\n\",\"    best_acc = 0\\n\",\"    batch_time_meter = RunningAverageMeter()\\n\",\"    f_nfe_meter = RunningAverageMeter()\\n\",\"    b_nfe_meter = RunningAverageMeter()\\n\",\"    end = time.time()\\n\",\"    \\n\",\"    epoch_arr = []\\n\",\"    time_val_arr = []\\n\",\"    time_avg_arr = []\\n\",\"    nfe_f_arr = []\\n\",\"    nfe_b_arr = []\\n\",\"    train_acc_arr = []\\n\",\"    test_acc_arr = []\\n\",\"\\n\",\"    for itr in range(args.nepochs * batches_per_epoch):\\n\",\"\\n\",\"        for param_group in optimizer.param_groups:\\n\",\"            param_group['lr'] = lr_fn(itr)\\n\",\"\\n\",\"        optimizer.zero_grad()\\n\",\"        x, y = data_gen.__next__()\\n\",\"        x = x.to(device)\\n\",\"        y = y.to(device)\\n\",\"        logits = model(x)\\n\",\"        loss = criterion(logits, y)\\n\",\"\\n\",\"        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\\n\",\"        parameters = optimizer.param_groups[0]['params']\\n\",\"\\n\",\"        print('Obtaining manual hessian...')\\n\",\"        manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\\n\",\"\\n\",\"        if is_odenet:\\n\",\"            nfe_forward = feature_layers[0].nfe\\n\",\"            feature_layers[0].nfe = 0\\n\",\"\\n\",\"        loss.backward()\\n\",\"        optimizer.step()\\n\",\"\\n\",\"        if is_odenet:\\n\",\"            nfe_backward = feature_layers[0].nfe\\n\",\"            feature_layers[0].nfe = 0\\n\",\"\\n\",\"        batch_time_meter.update(time.time() - end)\\n\",\"        if is_odenet:\\n\",\"            f_nfe_meter.update(nfe_forward)\\n\",\"            b_nfe_meter.update(nfe_backward)\\n\",\"        end = time.time()\\n\",\"\\n\",\"        if itr % batches_per_epoch == 0:\\n\",\"            with torch.no_grad():\\n\",\"                train_acc = accuracy(model, train_eval_loader)\\n\",\"                val_acc = accuracy(model, test_loader)\\n\",\"                if val_acc > best_acc:\\n\",\"                    torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\\n\",\"                    best_acc = val_acc\\n\",\"                logger.info(\\n\",\"                    \\\"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | \\\"\\n\",\"                    \\\"Train Acc {:.4f} | Test Acc {:.4f}\\\".format(\\n\",\"                        itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,\\n\",\"                        b_nfe_meter.avg, train_acc, val_acc\\n\",\"                    )\\n\",\"                )\\n\",\"                epoch_arr += [itr // batches_per_epoch]\\n\",\"                time_val_arr += [batch_time_meter.val]\\n\",\"                time_avg_arr += [batch_time_meter.avg]\\n\",\"                nfe_f_arr += [f_nfe_meter.avg]\\n\",\"                nfe_b_arr += [b_nfe_meter.avg]\\n\",\"                train_acc_arr += [train_acc]\\n\",\"                test_acc_arr += [val_acc]\\n\",\"                    \\n\",\"    epoch_arr = np.asarray(epoch_arr)\\n\",\"    time_val_arr = np.asarray(time_val_arr)\\n\",\"    time_avg_arr = np.asarray(time_avg_arr)\\n\",\"    nfe_f_arr = np.asarray(nfe_f_arr)\\n\",\"    nfe_b_arr = np.asarray(nfe_b_arr)\\n\",\"    train_acc_arr = np.asarray(train_acc_arr)\\n\",\"    test_acc_arr = np.asarray(test_acc_arr)\\n\",\"    \\n\",\"    np.save(os.path.join(args.save, 'epoch_arr.npy'), epoch_arr)\\n\",\"    np.save(os.path.join(args.save, 'time_val_arr.npy'), time_val_arr)\\n\",\"    np.save(os.path.join(args.save, 'time_avg_arr.npy'), time_avg_arr)\\n\",\"    np.save(os.path.join(args.save, 'nfe_f_arr.npy'), nfe_f_arr)\\n\",\"    np.save(os.path.join(args.save, 'nfe_b_arr.npy'), nfe_b_arr)\\n\",\"    np.save(os.path.join(args.save, 'train_acc_arr.npy'), train_acc_arr)\\n\",\"    np.save(os.path.join(args.save, 'test_acc_arr.npy'), test_acc_arr)\"],\"execution_count\":2,\"outputs\":[{\"output_type\":\"error\",\"ename\":\"NameError\",\"evalue\":\"ignored\",\"traceback\":[\"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\"\\u001b[0;31mNameError\\u001b[0m                                 Traceback (most recent call last)\",\"\\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m      1\\u001b[0m \\u001b[0;32mif\\u001b[0m \\u001b[0m__name__\\u001b[0m \\u001b[0;34m==\\u001b[0m \\u001b[0;34m'__main__'\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      2\\u001b[0m     \\u001b[0m__file__\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m'/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb'\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 3\\u001b[0;31m     \\u001b[0mmakedirs\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msave\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m      4\\u001b[0m     \\u001b[0mlogger\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mget_logger\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mlogpath\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mos\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpath\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mjoin\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msave\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m'logs'\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mfilepath\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mos\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpath\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mabspath\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0m__file__\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      5\\u001b[0m     \\u001b[0mlogger\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0minfo\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\"\\u001b[0;31mNameError\\u001b[0m: name 'makedirs' is not defined\"]}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"Ner61Yv1L9ZC\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617964389098,\"user_tz\":-60,\"elapsed\":1452,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"%%bash\\n\",\"rm -r /content/experiment_node1\"],\"execution_count\":58,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"gl0nftCJOgzw\"},\"source\":[\"\\\"\\\"\\\"\\n\",\"--------------------------------------------------------------------------------------------------------------------------------------------\\n\",\"The code for Hessian analysis.\\n\",\"--------------------------------------------------------------------------------------------------------------------------------------------\\n\",\"\\\"\\\"\\\"\"],\"execution_count\":null,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"m75L8B4eOjXq\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1617965493846,\"user_tz\":-60,\"elapsed\":445,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}}},\"source\":[\"def get_manual_hessian(grads, parameters, show_iters=True):\\n\",\"  \\\"\\\"\\\"\\n\",\"  Calculation of the Hessian using nested for loops.\\n\",\"  Inputs:   - grads:        tuple of gradient tensors. Created using something \\n\",\"                            like grads = torch.autograd.grad(loss, parameters, create_graph=True).\\n\",\"            - parameters:   List of parameter objects. Created using something \\n\",\"                            like parameters = optimizer.param_groups[0]['params'].\\n\",\"            - show_iters:   True or False, depending on if the iteration number is to be shown during training. \\n\",\"                            Note that the iteration updates are not provided every row, but instead periodically \\n\",\"                            (roughly according to the number of parameters in the system).\\n\",\"  \\\"\\\"\\\"\\n\",\"  start = time.time()        \\n\",\"\\n\",\"  n_params = 0\\n\",\"  for param in parameters:\\n\",\"    n_params += torch.numel(param)\\n\",\"  grads2 = torch.zeros(n_params,n_params)            #Create an matrix of zeros thas has the same shape as the Hessian.\\n\",\"\\n\",\"  y_counter = 0                             #y_direction refers to row number in the Hessian.\\n\",\"\\n\",\"  for grad in grads:\\n\",\"      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \\n\",\"\\n\",\"      for j, g in enumerate(grad):\\n\",\"        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\\n\",\"\\n\",\"        for l, param in enumerate(parameters):\\n\",\"          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\\n\",\"          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\\n\",\"          len = g2.shape[0]                       \\n\",\"          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\\n\",\"          x_counter += len\\n\",\"\\n\",\"      grads2 = grads2.to(device)\\n\",\"      y_counter += grad.shape[0]\\n\",\"\\n\",\"      if show_iters:\\n\",\"        print(\\\"Gradients calculated for row number \\\" + str(y_counter) + \\\".\\\")\\n\",\"  \\n\",\"  print('Time used was ', time.time() - start)\\n\",\"\\n\",\"  return grads2\"],\"execution_count\":9,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":232},\"id\":\"-QPba5QNQx6V\",\"executionInfo\":{\"status\":\"error\",\"timestamp\":1617965601039,\"user_tz\":-60,\"elapsed\":1139,\"user\":{\"displayName\":\"L. Atkins\",\"photoUrl\":\"\",\"userId\":\"13582269488947613307\"}},\"outputId\":\"008f10c7-272a-431f-a1bd-c9dfbfc275ef\"},\"source\":[\"__file__ = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb'\\n\",\"makedirs(args.save)\\n\",\"logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\\n\",\"logger.info(args)\\n\",\"\\n\",\"device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\\n\",\"\\n\",\"is_odenet = args.network == 'odenet'\\n\",\"\\n\",\"if args.downsampling_method == 'conv':\\n\",\"    downsampling_layers = [\\n\",\"        nn.Conv2d(1, 64, 3, 1),\\n\",\"        norm(64),\\n\",\"        nn.ReLU(inplace=True),\\n\",\"        nn.Conv2d(64, 64, 4, 2, 1),\\n\",\"        norm(64),\\n\",\"        nn.ReLU(inplace=True),\\n\",\"        nn.Conv2d(64, 64, 4, 2, 1),\\n\",\"    ]\\n\",\"elif args.downsampling_method == 'res':\\n\",\"    downsampling_layers = [\\n\",\"        nn.Conv2d(1, 64, 3, 1),\\n\",\"        ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\\n\",\"        ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\\n\",\"    ]\\n\",\"\\n\",\"feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\\n\",\"fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\\n\",\"\\n\",\"model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\\n\",\"\\n\",\"logger.info(model)\\n\",\"logger.info('Number of parameters: {}'.format(count_parameters(model)))\\n\",\"\\n\",\"criterion = nn.CrossEntropyLoss().to(device)\\n\",\"\\n\",\"train_loader, test_loader, train_eval_loader = get_mnist_loaders(\\n\",\"    args.data_aug, args.batch_size, args.test_batch_size\\n\",\")\\n\",\"\\n\",\"data_gen = inf_generator(train_loader)\\n\",\"batches_per_epoch = len(train_loader)\\n\",\"\\n\",\"lr_fn = learning_rate_with_decay(\\n\",\"    args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\\n\",\"    decay_rates=[1, 0.1, 0.01, 0.001]\\n\",\")\\n\",\"\\n\",\"optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\\n\",\"\\n\",\"best_acc = 0\\n\",\"batch_time_meter = RunningAverageMeter()\\n\",\"f_nfe_meter = RunningAverageMeter()\\n\",\"b_nfe_meter = RunningAverageMeter()\\n\",\"end = time.time()\\n\",\"\\n\",\"epoch_arr = []\\n\",\"time_val_arr = []\\n\",\"time_avg_arr = []\\n\",\"nfe_f_arr = []\\n\",\"nfe_b_arr = []\\n\",\"train_acc_arr = []\\n\",\"test_acc_arr = []\\n\",\"\\n\",\"for param_group in optimizer.param_groups:\\n\",\"    param_group['lr'] = lr_fn(itr)\\n\",\"\\n\",\"optimizer.zero_grad()\\n\",\"x, y = data_gen.__next__()\\n\",\"x = x.to(device)\\n\",\"y = y.to(device)\\n\",\"logits = model(x)\\n\",\"loss = criterion(logits, y)\\n\",\"\\n\",\"grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\\n\",\"parameters = optimizer.param_groups[0]['params']\\n\",\"\\n\",\"print('Obtaining manual hessian...')\\n\",\"manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian.\"],\"execution_count\":1,\"outputs\":[{\"output_type\":\"error\",\"ename\":\"NameError\",\"evalue\":\"ignored\",\"traceback\":[\"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\"\\u001b[0;31mNameError\\u001b[0m                                 Traceback (most recent call last)\",\"\\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m      1\\u001b[0m \\u001b[0m__file__\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m'/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb'\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 2\\u001b[0;31m \\u001b[0mmakedirs\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msave\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m      3\\u001b[0m \\u001b[0mlogger\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mget_logger\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mlogpath\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mos\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpath\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mjoin\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msave\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m'logs'\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mfilepath\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mos\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpath\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mabspath\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0m__file__\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      4\\u001b[0m \\u001b[0mlogger\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0minfo\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      5\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\"\\u001b[0;31mNameError\\u001b[0m: name 'makedirs' is not defined\"]}]}]}\n","Namespace(adjoint=False, batch_size=128, data_aug=True, debug=False, downsampling_method='conv', gpu=0, lr=0.1, nepochs=120, network='odenet', save='/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/experiment_node1', test_batch_size=1000, tol=0.001)\n","Sequential(\n","  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n","  (2): ReLU(inplace=True)\n","  (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","  (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n","  (5): ReLU(inplace=True)\n","  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","  (7): ODEBlock(\n","    (odefunc): ODEfunc(\n","      (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv1): ConcatConv2d(\n","        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n","      (conv2): ConcatConv2d(\n","        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (norm3): GroupNorm(32, 64, eps=1e-05, affine=True)\n","    )\n","  )\n","  (8): GroupNorm(32, 64, eps=1e-05, affine=True)\n","  (9): ReLU(inplace=True)\n","  (10): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (11): Flatten()\n","  (12): Linear(in_features=64, out_features=10, bias=True)\n",")\n","Number of parameters: 208266\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatches_per_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_eval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(model, dataset_loader)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mtotal_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modefunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# trigger both. (i.e. interleaving them would be wrong.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runge_kutta_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtableau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# dtypes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# y1.dtype == self.y0.dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mperturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UncheckedAssign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mttx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mttx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Ner61Yv1L9ZC","executionInfo":{"status":"ok","timestamp":1617964389098,"user_tz":-60,"elapsed":1452,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["%%bash\n","rm -r /content/experiment_node1"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"gl0nftCJOgzw"},"source":["\"\"\"\n","--------------------------------------------------------------------------------------------------------------------------------------------\n","The code for Hessian analysis.\n","--------------------------------------------------------------------------------------------------------------------------------------------\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m75L8B4eOjXq","executionInfo":{"status":"ok","timestamp":1617965653332,"user_tz":-60,"elapsed":763,"user":{"displayName":"L. Atkins","photoUrl":"","userId":"13582269488947613307"}}},"source":["def get_manual_hessian(grads, parameters, show_iters=True):\n","  \"\"\"\n","  Calculation of the Hessian using nested for loops.\n","  Inputs:   - grads:        tuple of gradient tensors. Created using something \n","                            like grads = torch.autograd.grad(loss, parameters, create_graph=True).\n","            - parameters:   List of parameter objects. Created using something \n","                            like parameters = optimizer.param_groups[0]['params'].\n","            - show_iters:   True or False, depending on if the iteration number is to be shown during training. \n","                            Note that the iteration updates are not provided every row, but instead periodically \n","                            (roughly according to the number of parameters in the system).\n","  \"\"\"\n","  start = time.time()        \n","\n","  n_params = 0\n","  for param in parameters:\n","    n_params += torch.numel(param)\n","  grads2 = torch.zeros(n_params,n_params)            #Create an matrix of zeros thas has the same shape as the Hessian.\n","\n","  y_counter = 0                             #y_direction refers to row number in the Hessian.\n","\n","  for grad in grads:\n","      grad = torch.reshape(grad, [-1])                                  #Rearrange the gradient information into a vector.        \n","\n","      for j, g in enumerate(grad):\n","        x_counter = 0                                                   #x_direction refers to column number in the Hessian.\n","\n","        for l, param in enumerate(parameters):\n","          g2 = torch.autograd.grad(g, param, retain_graph=True)[0]      #Calculate the gradient of an element of the gradient wrt one layer's parameters.\n","          g2 = torch.reshape(g2, [-1])                                  #Reshape this into a vector.\n","          len = g2.shape[0]                       \n","          grads2[j+y_counter, x_counter:x_counter+len] = g2             #Indexing ensures that the second order derivatives are placed in the correct positions.\n","          x_counter += len\n","\n","      grads2 = grads2.to(device)\n","      y_counter += grad.shape[0]\n","\n","      if show_iters:\n","        print(\"Gradients calculated for row number \" + str(y_counter) + \".\")\n","  \n","  print('Time used was ', time.time() - start)\n","\n","  return grads2"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QPba5QNQx6V"},"source":["__file__ = '/content/drive/MyDrive/colab_notebooks/NODE_Hessian/MNIST/mnist_node.ipynb'\n","makedirs(args.save)\n","logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\n","logger.info(args)\n","\n","device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n","\n","is_odenet = args.network == 'odenet'\n","\n","if args.downsampling_method == 'conv':\n","    downsampling_layers = [\n","        nn.Conv2d(1, 64, 3, 1),\n","        norm(64),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(64, 64, 4, 2, 1),\n","        norm(64),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(64, 64, 4, 2, 1),\n","    ]\n","elif args.downsampling_method == 'res':\n","    downsampling_layers = [\n","        nn.Conv2d(1, 64, 3, 1),\n","        ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n","        ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n","    ]\n","\n","feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\n","fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n","\n","model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n","\n","logger.info(model)\n","logger.info('Number of parameters: {}'.format(count_parameters(model)))\n","\n","criterion = nn.CrossEntropyLoss().to(device)\n","\n","train_loader, test_loader, train_eval_loader = get_mnist_loaders(\n","    args.data_aug, args.batch_size, args.test_batch_size\n",")\n","\n","data_gen = inf_generator(train_loader)\n","batches_per_epoch = len(train_loader)\n","\n","lr_fn = learning_rate_with_decay(\n","    args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n","    decay_rates=[1, 0.1, 0.01, 0.001]\n",")\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n","\n","best_acc = 0\n","batch_time_meter = RunningAverageMeter()\n","f_nfe_meter = RunningAverageMeter()\n","b_nfe_meter = RunningAverageMeter()\n","end = time.time()\n","\n","epoch_arr = []\n","time_val_arr = []\n","time_avg_arr = []\n","nfe_f_arr = []\n","nfe_b_arr = []\n","train_acc_arr = []\n","test_acc_arr = []\n","\n","for param_group in optimizer.param_groups:\n","    param_group['lr'] = lr_fn(itr)\n","\n","optimizer.zero_grad()\n","x, y = data_gen.__next__()\n","x = x.to(device)\n","y = y.to(device)\n","logits = model(x)\n","loss = criterion(logits, y)\n","\n","grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n","parameters = optimizer.param_groups[0]['params']\n","\n","print('Obtaining manual hessian...')\n","manual_hessian = get_manual_hessian(grads, parameters)           #get manual hessian."],"execution_count":null,"outputs":[]}]}